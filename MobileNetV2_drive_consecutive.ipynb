{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e80c9d3-adba-4600-9e59-27ddc0211936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:36.722660Z",
     "iopub.status.busy": "2021-06-11T04:09:36.722660Z",
     "iopub.status.idle": "2021-06-11T04:09:45.041475Z",
     "shell.execute_reply": "2021-06-11T04:09:45.040477Z",
     "shell.execute_reply.started": "2021-06-11T04:09:36.722660Z"
    },
    "id": "e039f65a-4b32-405a-a4ae-95afdc2e8eb1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d6eaf2-46ce-4bf2-8b37-9435129517bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.043472Z",
     "iopub.status.busy": "2021-06-11T04:09:45.042478Z",
     "iopub.status.idle": "2021-06-11T04:09:45.057476Z",
     "shell.execute_reply": "2021-06-11T04:09:45.056478Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.043472Z"
    },
    "id": "e17e0443-a109-4fb8-a5f1-d25e2d4d53a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import imgaug as ia\n",
    "# from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914fa10d-d3be-49bb-b2df-e3e9930763fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.059474Z",
     "iopub.status.busy": "2021-06-11T04:09:45.058476Z",
     "iopub.status.idle": "2021-06-11T04:09:45.121481Z",
     "shell.execute_reply": "2021-06-11T04:09:45.120478Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.059474Z"
    },
    "id": "330dfc9b-4e7e-4262-91c0-0baec3158880",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f6f662-4bf4-479f-8f5b-f038a9f11aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.123478Z",
     "iopub.status.busy": "2021-06-11T04:09:45.122485Z",
     "iopub.status.idle": "2021-06-11T04:09:45.153485Z",
     "shell.execute_reply": "2021-06-11T04:09:45.152488Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.123478Z"
    },
    "id": "iQBpiIhqjVk6"
   },
   "outputs": [],
   "source": [
    "# attention\n",
    "am_I_using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8dd5b1-d863-4b21-962e-8116485e2266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.154492Z",
     "iopub.status.busy": "2021-06-11T04:09:45.154492Z",
     "iopub.status.idle": "2021-06-11T04:09:45.185486Z",
     "shell.execute_reply": "2021-06-11T04:09:45.184495Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.154492Z"
    },
    "id": "4d9436d0-fb2f-496d-840f-c5a0a4e1eac9"
   },
   "outputs": [],
   "source": [
    "# if am_I_using_colab:\n",
    "#     !pip install -U tensorflow-addons\n",
    "    \n",
    "# import tensorflow_addons as tfa\n",
    "# import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05172f42-8dfb-4095-85bf-30f1e686072f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.186490Z",
     "iopub.status.busy": "2021-06-11T04:09:45.185486Z",
     "iopub.status.idle": "2021-06-11T04:09:45.231491Z",
     "shell.execute_reply": "2021-06-11T04:09:45.231491Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.186490Z"
    },
    "id": "3dd459d4-e3e1-4601-aa6e-7d4a01a0e594",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.ioff()  # interactive mode off\n",
    "# plt.ion()  # interactive mode on\n",
    "\n",
    "# %pylab inline\n",
    "\n",
    "np.random.seed(1728)\n",
    "# ia.random.seed(1728)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c26251-dd33-4889-8ab6-a67ba0c75229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.233494Z",
     "iopub.status.busy": "2021-06-11T04:09:45.233494Z",
     "iopub.status.idle": "2021-06-11T04:09:45.264490Z",
     "shell.execute_reply": "2021-06-11T04:09:45.263491Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.233494Z"
    },
    "id": "S04tKXrZieAG",
    "outputId": "128332fe-95fd-4a94-91d1-88de817b672c"
   },
   "outputs": [],
   "source": [
    "if am_I_using_colab:\n",
    "    ###\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    print(os.getcwd())\n",
    "    print(os.listdir())\n",
    "\n",
    "    ###\n",
    "    temp_dir = '/content/temp'\n",
    "    try:\n",
    "        os.mkdir(temp_dir)\n",
    "    except:\n",
    "        pass\n",
    "    print(os.listdir(temp_dir))\n",
    "\n",
    "    ###\n",
    "    dataset_filepath = f'{temp_dir:s}/dataset_v1.7z'\n",
    "    import gdown\n",
    "    gdown.download(\n",
    "        r'https://drive.google.com/uc?id=15kAUrJvaJy54xoXIwPZqtkBQGccjOR5k',\n",
    "        output=dataset_filepath,\n",
    "        quiet=False,\n",
    "        )\n",
    "\n",
    "    ###\n",
    "    !pip install py7zr\n",
    "    import py7zr\n",
    "    with py7zr.SevenZipFile(dataset_filepath, 'r') as archive:\n",
    "        archive.extractall(path=\"./dataset_v1\")\n",
    "\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1020d8af-f630-4c51-a75e-a567350e7422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.266493Z",
     "iopub.status.busy": "2021-06-11T04:09:45.265493Z",
     "iopub.status.idle": "2021-06-11T04:09:45.407522Z",
     "shell.execute_reply": "2021-06-11T04:09:45.406518Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.266493Z"
    },
    "id": "5a98c5bd-a334-447c-89ea-b7080052ceb2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "(107.01 ms) == (0m:0s)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def mulai_hitung_waktu():\n",
    "    global waktu_mulai\n",
    "    waktu_mulai = time.time()\n",
    "\n",
    "def cetak_lama_waktu():\n",
    "    global waktu_mulai\n",
    "    hasil_detik = abs(waktu_mulai - time.time())\n",
    "    hasil_milidetik = hasil_detik * 1000\n",
    "    \n",
    "    menit = hasil_detik / 60\n",
    "    detik = hasil_detik % 60\n",
    "    \n",
    "    menit_detik = str(int(menit)) + 'm' + ':' + str(int(detik)) + 's'\n",
    "    \n",
    "    print('-----\\n(%.2f ms) == (%s)\\n-----' % (hasil_milidetik, menit_detik))\n",
    "    del waktu_mulai\n",
    "\n",
    "\n",
    "# cara pakai\n",
    "# ----------\n",
    "mulai_hitung_waktu()  ###\n",
    "\n",
    "time.sleep(100/1000)  # time-consuming computing here\n",
    "\n",
    "cetak_lama_waktu()  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bea47c-8d25-41bc-9640-aa4731477663",
   "metadata": {
    "id": "d78a19da-d950-4997-9909-955a088a8e1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec964260-d13f-4253-8b90-3e6b76a4de1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:45.410518Z",
     "iopub.status.busy": "2021-06-11T04:09:45.410518Z",
     "iopub.status.idle": "2021-06-11T04:09:46.404593Z",
     "shell.execute_reply": "2021-06-11T04:09:46.403588Z",
     "shell.execute_reply.started": "2021-06-11T04:09:45.410518Z"
    },
    "id": "530dc6d4-fdac-4a36-bcc1-829b7788007f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(\"Num GPUs Available: %d Physical GPUs, %d Logical GPU\" % (len(gpus), len(logical_gpus)))\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509ff40-d6ad-4d3a-989d-881e72419ca3",
   "metadata": {
    "id": "n_eonvAiKs1J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a331ed47-dc1e-453e-8d19-d8f7aafae383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.406589Z",
     "iopub.status.busy": "2021-06-11T04:09:46.405589Z",
     "iopub.status.idle": "2021-06-11T04:09:46.468596Z",
     "shell.execute_reply": "2021-06-11T04:09:46.467599Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.405589Z"
    },
    "id": "6187d76c-a4e2-4d62-b29f-b2e57ae5b86f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints\n",
      "exist\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models\n",
      "exist\n",
      "current work dir:\n",
      "D:\\MaskTheFace\\datasets\\_temp\n",
      "\n",
      "listdir WORK_DIR:\n",
      "['Augmented Images - Masked',\n",
      " 'Augmented Images - Masked.zip',\n",
      " 'Augmented Images - Unmasked',\n",
      " 'Augmented Images - Unmasked.zip',\n",
      " 'checkpoints',\n",
      " 'main, train set - crop masked resized',\n",
      " 'main, train set - crop masked resized.zip',\n",
      " 'main, train set - crop resized',\n",
      " 'main, train set - crop resized.zip',\n",
      " 'Model tracking and summary.xlsx',\n",
      " 'note.txt',\n",
      " 'thumbnails - augmented masked.zip',\n",
      " 'thumbnails - augmented unmasked.zip',\n",
      " 'verbose.mobilenetv2_1.00_128-16-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_128-imagenet128-16-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_128-imagenet128-16-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_128-imagenet128-32-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-16-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-64-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-64-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-imagenet224-16-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-imagenet224-32-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_32-imagenet224-64-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_64-16-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_64-64-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_64-imagenet224-64-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_64-imagenet224-64-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_96-16-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_96-imagenet96-16-fc12.txt',\n",
      " 'verbose.mobilenetv2_1.00_96-imagenet96-64-12.txt',\n",
      " 'verbose.mobilenetv2_1.00_96-imagenet96-64-fc12.txt',\n",
      " 'weights and models',\n",
      " '_mobilenetv2_1.00_32-imagenet224-32-fc12.txt',\n",
      " '_v1',\n",
      " '_v1 - test only',\n",
      " '_v1.7z',\n",
      " '_verbose.mobilenetv2_1.00_128-16-12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-32-12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-32-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-64-12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-64-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-imagenet128-32-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-imagenet128-64-12.txt',\n",
      " '_verbose.mobilenetv2_1.00_128-imagenet128-64-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_32-16-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_32-imagenet224-16-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_32-imagenet224-32-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_32-imagenet224-64-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_64-64-fc12.txt',\n",
      " '_verbose.mobilenetv2_1.00_96-16-12.txt',\n",
      " '_verbose.mobilenetv2_1.00_96-64-fc12.txt',\n",
      " '~$Model tracking and summary.xlsx']\n"
     ]
    }
   ],
   "source": [
    "if am_I_using_colab:\n",
    "    WORK_DIR = '/content'\n",
    "    TRAIN_SET_PATH = f'{WORK_DIR}/dataset_v1'\n",
    "    # TEST_SET_PATH = f''\n",
    "\n",
    "    DRIVE_DIR = '/content/drive/MyDrive/MyNotebook/MySkripsi'\n",
    "    CHECKPOINTS_DIR = f'{WORK_DIR}/checkpoints'\n",
    "    FINAL_EPOCH_DIR = f'{WORK_DIR}/weights and models'\n",
    "\n",
    "else:\n",
    "    WORK_DIR = r'D:\\MaskTheFace\\datasets\\_temp'\n",
    "    TRAIN_SET_PATH = r'D:\\MaskTheFace\\datasets\\_temp\\_v1'\n",
    "    TEST_SET_PATH = r'D:\\MaskTheFace\\datasets\\_temp\\_v1 - test only'\n",
    "\n",
    "    CHECKPOINTS_DIR = r'D:\\MaskTheFace\\datasets\\_temp\\checkpoints'\n",
    "    FINAL_EPOCH_DIR = r'D:\\MaskTheFace\\datasets\\_temp\\weights and models'\n",
    "\n",
    "directories = [\n",
    "    CHECKPOINTS_DIR,\n",
    "    FINAL_EPOCH_DIR\n",
    "]\n",
    "\n",
    "for dir in directories:\n",
    "    print(dir)\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "        print('success')\n",
    "    except FileExistsError:\n",
    "        print('exist')\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "print('current work dir:')\n",
    "print(os.getcwd())\n",
    "print()\n",
    "print('listdir WORK_DIR:')\n",
    "pprint(os.listdir('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae40f73-260f-4e91-8c49-35c04cf4981e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.469598Z",
     "iopub.status.busy": "2021-06-11T04:09:46.469598Z",
     "iopub.status.idle": "2021-06-11T04:09:46.516601Z",
     "shell.execute_reply": "2021-06-11T04:09:46.515604Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.469598Z"
    },
    "id": "f209a709-9670-4587-9fa6-6ca058507fd2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Andhika': 1260,\n",
       " 'Ardiyan': 1260,\n",
       " 'Artik': 1260,\n",
       " 'Ballya': 1260,\n",
       " 'Bina': 1260,\n",
       " 'Buyung': 1260,\n",
       " 'Kresna': 1260,\n",
       " 'Mhartian': 1260,\n",
       " 'RaihanA': 1260,\n",
       " 'Syifa': 1260,\n",
       " 'Taufik': 1260,\n",
       " 'Yandi': 1260}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1260\n",
      "min: 1260\n",
      "total: 15120\n"
     ]
    }
   ],
   "source": [
    "names = os.listdir(TRAIN_SET_PATH)\n",
    "\n",
    "length_dict = {}\n",
    "for name in names:\n",
    "    samples = f'{TRAIN_SET_PATH:s}/{name:s}'\n",
    "    length_dict[name] = len(os.listdir(samples))\n",
    "\n",
    "n_min = min(length_dict.values())\n",
    "n_max = max(length_dict.values())\n",
    "n_sum = sum(length_dict.values())\n",
    "\n",
    "print(f'{len(names):d} names')\n",
    "display(length_dict)\n",
    "print(f\"max: {n_min:d}\")\n",
    "print(f\"min: {n_max:d}\")\n",
    "print(f\"total: {n_sum:d}\")\n",
    "\n",
    "# del n_min, n_max, n_sum, length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844887a1-37d8-4c42-a569-604c8f08591b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.517605Z",
     "iopub.status.busy": "2021-06-11T04:09:46.517605Z",
     "iopub.status.idle": "2021-06-11T04:09:46.531602Z",
     "shell.execute_reply": "2021-06-11T04:09:46.531602Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.517605Z"
    },
    "id": "7655a9f1-f6bf-4b82-ab75-bae523e19cc6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images: 9072\n",
      "validation images: 6048\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.4\n",
    "total_train = round(n_sum * (1 - validation_split))\n",
    "total_val = n_sum - total_train\n",
    "\n",
    "print(f'train images: {total_train:d}')\n",
    "print(f'validation images: {total_val:d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a12cd0-5e37-4338-81bd-b4a29c218ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9faa8601-76be-466f-9d09-5bbe348cbda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.533606Z",
     "iopub.status.busy": "2021-06-11T04:09:46.533606Z",
     "iopub.status.idle": "2021-06-11T04:09:46.564604Z",
     "shell.execute_reply": "2021-06-11T04:09:46.563605Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.533606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_model(input_size, batch_size, weights=None, dense=False):\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        weights=weights,  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(input_size, input_size, 3),  # recommended  because trained in (224, 224, 3) ImageNet\n",
    "        alpha=1.0,  # network width multiplier, default 1.0 in the MobileNetV2 paper\n",
    "        include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        base_model.trainable = False  # freeze the base model.\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "\n",
    "    # Create a new model on top.\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "    # We make sure that the base_model is running in inference mode here,\n",
    "    # by passing `training=False`.\n",
    "    # This is important for fine-tuning, as you will learn in a few paragraphs.\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        x = base_model(inputs, training=False)  # freeze the base model.\n",
    "    else:\n",
    "        x = base_model(inputs, training=True)\n",
    "\n",
    "    # Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if bool(dense) == True:\n",
    "        # Regularize with dropout\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "        x = keras.layers.Dense(256,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "        x = keras.layers.Dense(256,activation='relu')(x) #dense layer 2\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "        x = keras.layers.Dense(128,activation='relu')(x) #dense layer 3\n",
    "        x = keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "    else:\n",
    "        # Regularize with dropout\n",
    "        x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # A Dense classifier with a single unit (binary classification)\n",
    "    outputs = keras.layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        if input_size in [96, 128, 192, 224]:\n",
    "            name = f'mobilenetv2_1.00_{input_size:d}-imagenet{input_size:d}-{batch_size:d}'\n",
    "        else:\n",
    "            name = f'mobilenetv2_1.00_{input_size:d}-imagenet224-{batch_size:d}'\n",
    "    else:\n",
    "        name = f'mobilenetv2_1.00_{input_size:d}-{batch_size:d}'\n",
    "\n",
    "    if bool(dense) == True:\n",
    "        name = f'{name:s}-fc12'\n",
    "    else:\n",
    "        name = f'{name:s}-12'\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
    "    print(model.name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e0704-10c6-49c1-97b8-9d08c7ce89b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d427f24b-4d05-4f5b-87f7-933fc0434d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.565604Z",
     "iopub.status.busy": "2021-06-11T04:09:46.565604Z",
     "iopub.status.idle": "2021-06-11T04:09:46.643609Z",
     "shell.execute_reply": "2021-06-11T04:09:46.642610Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.565604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consecutiveModelTraining(\n",
    "    input_size,  # [32, 64, 96, 128] or divisible by 32\n",
    "    batch_size,  # [16, 32, 64] or power of \n",
    "    weights,     # [None, 'imagenet']\n",
    "    dense):      # [True, False]\n",
    "    \n",
    "    \n",
    "    ### create train/val generator\n",
    "    image_generator = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=1.05,\n",
    "        height_shift_range=1.05,\n",
    "        brightness_range=(0.75, 1.25),\n",
    "        shear_range = 0.075,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode = 'nearest',\n",
    "        horizontal_flip=True,\n",
    "        # vertical_flip=True,\n",
    "        validation_split=validation_split,\n",
    "        # preprocessing_function=seq.augment_image\n",
    "    )\n",
    "    train_data_gen = image_generator.flow_from_directory(\n",
    "        seed=1728,\n",
    "        subset='training',\n",
    "        batch_size=batch_size,\n",
    "        directory=TRAIN_SET_PATH,\n",
    "        shuffle=True,\n",
    "        target_size=(input_size, input_size),\n",
    "        interpolation='bicubic',\n",
    "        class_mode='categorical')\n",
    "\n",
    "    val_data_gen = image_generator.flow_from_directory(\n",
    "        seed=1728,\n",
    "        subset='validation',\n",
    "        batch_size=batch_size,\n",
    "        directory=TRAIN_SET_PATH,\n",
    "        shuffle=True,\n",
    "        target_size=(input_size, input_size),\n",
    "        interpolation='bicubic',\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    \n",
    "    ### create model\n",
    "    model = new_model(input_size=input_size, batch_size=batch_size, weights=weights, dense=dense)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    ### model optimizer, loss fn, metrics\n",
    "    # Optimizer's scheduler: ExponentialDecay\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    loss_fn = 'categorical_crossentropy'\n",
    "    metrics=[\n",
    "        'categorical_accuracy',\n",
    "        keras.metrics.TopKCategoricalAccuracy(k=3, name='top-3'),\n",
    "        keras.metrics.AUC(name='ROC-AUC', curve='ROC'),\n",
    "        keras.metrics.AUC(name='PR-AUC', curve='PR'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.TruePositives(name='TP'),\n",
    "        keras.metrics.TrueNegatives(name='TN'),\n",
    "        keras.metrics.FalsePositives(name='FP'),\n",
    "        keras.metrics.FalseNegatives(name='FN'),]\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_fn,\n",
    "        metrics=metrics)\n",
    "    \n",
    "    model.summary()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    params = {\n",
    "        'total_train' : total_train,\n",
    "        'total_val' : total_val,\n",
    "        'batch_size' : batch_size,\n",
    "        'steps_per_epoch' : total_train//batch_size,\n",
    "        'validation_steps' : total_val//batch_size,\n",
    "        'epochs' : epochs}\n",
    "\n",
    "    pprint(params)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    ### create model callbacks save dir and post-train save dir\n",
    "    dir1 = f'{CHECKPOINTS_DIR}/{model.name}'\n",
    "    dir2 = f'{FINAL_EPOCH_DIR}/{model.name}'\n",
    "\n",
    "    for dir in [dir1, dir2]:\n",
    "        print(dir)\n",
    "        try:\n",
    "            os.mkdir(dir)\n",
    "            print('success')\n",
    "        except FileExistsError:\n",
    "            print('!!! exist')\n",
    "        except:\n",
    "            print('~~~ error')\n",
    "        print()\n",
    "\n",
    "        \n",
    "    print()\n",
    "    ### model callbacks save dir\n",
    "    if am_I_using_colab:\n",
    "        epoch5_filepath = '%s/%s/%s.weights.{epoch:03d}.hdf5' % (CHECKPOINTS_DIR, model.name, model.name)\n",
    "        monitor_filepath = '%s/%s/%s.weights.{epoch:03d}_{val_categorical_accuracy:.4f}_{val_loss:.4f}.hdf5' %\n",
    "                            (CHECKPOINTS_DIR, model.name, model.name)\n",
    "        tensorboard_dir = '%s/%s/%s.tensorboard' % (CHECKPOINTS_DIR, model.name, model.name)\n",
    "    else:\n",
    "        epoch5_filepath = '%s/%s/%s.weights.{epoch:03d}.hdf5' % (CHECKPOINTS_DIR, model.name, model.name)\n",
    "        monitor_filepath = '%s/%s/%s.weights.{epoch:03d}_{val_categorical_accuracy:.4f}_{val_loss:.4f}.hdf5' %\n",
    "                            (CHECKPOINTS_DIR, model.name, model.name)\n",
    "        tensorboard_dir = '%s/%s/%s.tensorboard' % (CHECKPOINTS_DIR, model.name, model.name)\n",
    "\n",
    "    # Model's callback: ModelCheckpoint\n",
    "    epoch_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=epoch5_filepath,\n",
    "        monitor='val_loss',\n",
    "        save_weights_only=True,\n",
    "        save_freq=int(5 * params['steps_per_epoch'])\n",
    "        )\n",
    "\n",
    "    acc_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=monitor_filepath,\n",
    "        monitor='val_categorical_accuracy',\n",
    "        # verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto',\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch'\n",
    "        )\n",
    "\n",
    "    loss_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=monitor_filepath,\n",
    "        monitor='val_loss',\n",
    "        # verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto',\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch'\n",
    "        )\n",
    "\n",
    "    # initialize tqdm callback with default parameters\n",
    "    # tqdm_callback = tfa.callbacks.TQDMProgressBar(\n",
    "    #     metrics_separator=', '\n",
    "    #     )\n",
    "\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir=tensorboard_dir,\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "        )\n",
    "\n",
    "    callbacks = [\n",
    "        epoch_checkpoint,\n",
    "        acc_checkpoint,\n",
    "        loss_checkpoint,\n",
    "        # tqdm_callback,\n",
    "        tensorboard_callback\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    ### model.fit() verbosity\n",
    "    if am_I_using_colab:\n",
    "        verbosity = 2  # end of epoch\n",
    "    else:\n",
    "        verbosity = 1  # every step in epoch\n",
    "        \n",
    "        \n",
    "    ### model.fit()\n",
    "    print(model.name)\n",
    "    mulai_hitung_waktu()  ###\n",
    "\n",
    "    training_history = model.fit(\n",
    "        train_data_gen,\n",
    "        shuffle=True,\n",
    "        verbose=verbosity,  # 0 nope, 1 realtime, 2 epoch end\n",
    "        steps_per_epoch=total_train // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=total_val // batch_size,\n",
    "        callbacks=callbacks,\n",
    "        workers=0\n",
    "        )\n",
    "\n",
    "    cetak_lama_waktu()  ###\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    ### post-train save\n",
    "    history_df = pd.DataFrame(training_history.history)\n",
    "\n",
    "    history_savepath = f'{FINAL_EPOCH_DIR}/{model.name}/history.{model.name}.csv'\n",
    "    weights_savepath = f'{FINAL_EPOCH_DIR}/{model.name}/weights.{model.name}.h5'\n",
    "    model_savepath = f'{FINAL_EPOCH_DIR}/{model.name}/model.{model.name}.h5'\n",
    "\n",
    "\n",
    "    # save to csv: \n",
    "    with open(history_savepath, mode='w') as f:\n",
    "        history_df.to_csv(\n",
    "            f,\n",
    "            header=True,\n",
    "            index=False\n",
    "            )\n",
    "\n",
    "    model.save_weights(\n",
    "        filepath=weights_savepath,\n",
    "        overwrite=True,\n",
    "        save_format='h5'\n",
    "        )\n",
    "\n",
    "    model.save(\n",
    "        filepath=model_savepath,\n",
    "        overwrite=True,\n",
    "        include_optimizer=True,\n",
    "        save_format='h5'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    ### rechecking save dir\n",
    "    _checkpoints_listdir = os.listdir(f'{CHECKPOINTS_DIR}/{model.name}')\n",
    "    print(len(_checkpoints_listdir))\n",
    "    pprint(_checkpoints_listdir)\n",
    "    \n",
    "    _final_epoch_listdir = os.listdir(f'{FINAL_EPOCH_DIR}/{model.name}')\n",
    "    print(len(_final_epoch_listdir))\n",
    "    pprint(_final_epoch_listdir)\n",
    "    \n",
    "    if am_I_using_colab:\n",
    "        !cp -fRv \"/content/checkpoints\" \"/content/drive/MyDrive/MyNotebook/MySkripsi\"\n",
    "        print()\n",
    "        !cp -fRv \"/content/weights and models\" \"/content/drive/MyDrive/MyNotebook/MySkripsi\"\n",
    "        print()\n",
    "        print('copy success')\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    print()\n",
    "    print()\n",
    "    if _checkpoints_listdir and _final_epoch_listdir:\n",
    "        print('all process done, please recheck before terminating runtime session')\n",
    "    else:\n",
    "        print('WARNING : some files failed to save')\n",
    "    print()\n",
    "    print('''don't forget to save the model.fit() verbose output''')\n",
    "    \n",
    "    \n",
    "    keyvalpairs = {\n",
    "        'name' : model.name,\n",
    "        'history_df' : history_df,\n",
    "        'model' : model,\n",
    "        'checkpoints_listdir' : _checkpoints_listdir,\n",
    "        'final_epoch_listdir' : _final_epoch_listdir\n",
    "    }\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print('Returned values using %d bytes of memory now' % (sys.getsizeof(keyvalpairs),))\n",
    "    return keyvalpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732232a-952c-4cda-963f-369fd928aa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1600be5-b242-4a6c-874b-3cd276819fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.644612Z",
     "iopub.status.busy": "2021-06-11T04:09:46.644612Z",
     "iopub.status.idle": "2021-06-11T04:09:46.675610Z",
     "shell.execute_reply": "2021-06-11T04:09:46.674613Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.644612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global variable\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f31abe3-acab-4df8-b8a9-fb08ed7ad4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.676608Z",
     "iopub.status.busy": "2021-06-11T04:09:46.676608Z",
     "iopub.status.idle": "2021-06-11T04:09:46.707618Z",
     "shell.execute_reply": "2021-06-11T04:09:46.706622Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.676608Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_size,  # [32, 64, 96, 128] or divisible by 32\n",
    "# batch_size,  # [16, 32, 64] or power of \n",
    "# weights,     # [None, 'imagenet']\n",
    "# dense        # [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4461d-bd2a-49bc-b323-15359a0f25f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d8943e-c39b-4c10-a62e-818f7a907d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T04:09:46.708616Z",
     "iopub.status.busy": "2021-06-11T04:09:46.708616Z",
     "iopub.status.idle": "2021-06-11T06:33:42.335953Z",
     "shell.execute_reply": "2021-06-11T06:33:42.334958Z",
     "shell.execute_reply.started": "2021-06-11T04:09:46.708616Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_96-64-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_96-64-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 2,239,244\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 141,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 94}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_96-64-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_96-64-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_96-64-12\n",
      "Epoch 1/50\n",
      "  1/141 [..............................] - ETA: 0s - loss: 2.7440 - categorical_accuracy: 0.1094 - top-3: 0.3125 - ROC-AUC: 0.5257 - PR-AUC: 0.0922 - precision: 0.0000e+00 - recall: 0.0000e+00 - TP: 0.0000e+00 - TN: 704.0000 - FP: 0.0000e+00 - FN: 64.0000WARNING:tensorflow:From X:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "141/141 [==============================] - 479s 3s/step - loss: 1.3918 - categorical_accuracy: 0.5818 - top-3: 0.7948 - ROC-AUC: 0.9198 - PR-AUC: 0.6761 - precision: 0.8063 - recall: 0.4782 - TP: 4308.0000 - TN: 98053.0000 - FP: 1035.0000 - FN: 4700.0000 - val_loss: 0.3041 - val_categorical_accuracy: 0.9029 - val_top-3: 0.9895 - val_ROC-AUC: 0.9930 - val_PR-AUC: 0.9631 - val_precision: 0.9195 - val_recall: 0.8883 - val_TP: 5344.0000 - val_TN: 65708.0000 - val_FP: 468.0000 - val_FN: 672.0000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 171s 1s/step - loss: 0.2578 - categorical_accuracy: 0.9195 - top-3: 0.9915 - ROC-AUC: 0.9944 - PR-AUC: 0.9693 - precision: 0.9300 - recall: 0.9105 - TP: 8202.0000 - TN: 98471.0000 - FP: 617.0000 - FN: 806.0000 - val_loss: 0.1234 - val_categorical_accuracy: 0.9604 - val_top-3: 0.9948 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9914 - val_precision: 0.9648 - val_recall: 0.9569 - val_TP: 5757.0000 - val_TN: 65966.0000 - val_FP: 210.0000 - val_FN: 259.0000\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 168s 1s/step - loss: 0.1270 - categorical_accuracy: 0.9590 - top-3: 0.9974 - ROC-AUC: 0.9978 - PR-AUC: 0.9901 - precision: 0.9627 - recall: 0.9563 - TP: 8614.0000 - TN: 98754.0000 - FP: 334.0000 - FN: 394.0000 - val_loss: 0.1793 - val_categorical_accuracy: 0.9498 - val_top-3: 0.9935 - val_ROC-AUC: 0.9951 - val_PR-AUC: 0.9808 - val_precision: 0.9568 - val_recall: 0.9471 - val_TP: 5698.0000 - val_TN: 65919.0000 - val_FP: 257.0000 - val_FN: 318.0000\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 168s 1s/step - loss: 0.1069 - categorical_accuracy: 0.9697 - top-3: 0.9962 - ROC-AUC: 0.9978 - PR-AUC: 0.9913 - precision: 0.9742 - recall: 0.9673 - TP: 8713.0000 - TN: 98857.0000 - FP: 231.0000 - FN: 295.0000 - val_loss: 0.0759 - val_categorical_accuracy: 0.9764 - val_top-3: 0.9968 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9952 - val_precision: 0.9804 - val_recall: 0.9747 - val_TP: 5864.0000 - val_TN: 66059.0000 - val_FP: 117.0000 - val_FN: 152.0000\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0844 - categorical_accuracy: 0.9762 - top-3: 0.9972 - ROC-AUC: 0.9983 - PR-AUC: 0.9941 - precision: 0.9797 - recall: 0.9735 - TP: 8769.0000 - TN: 98906.0000 - FP: 182.0000 - FN: 239.0000 - val_loss: 0.0717 - val_categorical_accuracy: 0.9799 - val_top-3: 0.9975 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9957 - val_precision: 0.9813 - val_recall: 0.9779 - val_TP: 5883.0000 - val_TN: 66064.0000 - val_FP: 112.0000 - val_FN: 133.0000\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.1107 - categorical_accuracy: 0.9666 - top-3: 0.9969 - ROC-AUC: 0.9978 - PR-AUC: 0.9914 - precision: 0.9699 - recall: 0.9629 - TP: 8674.0000 - TN: 98819.0000 - FP: 269.0000 - FN: 334.0000 - val_loss: 0.1180 - val_categorical_accuracy: 0.9641 - val_top-3: 0.9953 - val_ROC-AUC: 0.9971 - val_PR-AUC: 0.9904 - val_precision: 0.9674 - val_recall: 0.9623 - val_TP: 5789.0000 - val_TN: 65981.0000 - val_FP: 195.0000 - val_FN: 227.0000\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 167s 1s/step - loss: 0.0673 - categorical_accuracy: 0.9797 - top-3: 0.9983 - ROC-AUC: 0.9988 - PR-AUC: 0.9957 - precision: 0.9819 - recall: 0.9778 - TP: 8808.0000 - TN: 98926.0000 - FP: 162.0000 - FN: 200.0000 - val_loss: 0.0590 - val_categorical_accuracy: 0.9850 - val_top-3: 0.9970 - val_ROC-AUC: 0.9984 - val_PR-AUC: 0.9957 - val_precision: 0.9860 - val_recall: 0.9842 - val_TP: 5921.0000 - val_TN: 66092.0000 - val_FP: 84.0000 - val_FN: 95.0000\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0491 - categorical_accuracy: 0.9861 - top-3: 0.9990 - ROC-AUC: 0.9989 - PR-AUC: 0.9961 - precision: 0.9877 - recall: 0.9845 - TP: 8868.0000 - TN: 98978.0000 - FP: 110.0000 - FN: 140.0000 - val_loss: 0.0717 - val_categorical_accuracy: 0.9811 - val_top-3: 0.9977 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9966 - val_precision: 0.9846 - val_recall: 0.9771 - val_TP: 5878.0000 - val_TN: 66084.0000 - val_FP: 92.0000 - val_FN: 138.0000\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0495 - categorical_accuracy: 0.9856 - top-3: 0.9991 - ROC-AUC: 0.9993 - PR-AUC: 0.9975 - precision: 0.9869 - recall: 0.9847 - TP: 8870.0000 - TN: 98970.0000 - FP: 118.0000 - FN: 138.0000 - val_loss: 0.0860 - val_categorical_accuracy: 0.9721 - val_top-3: 0.9983 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9937 - val_precision: 0.9753 - val_recall: 0.9709 - val_TP: 5841.0000 - val_TN: 66028.0000 - val_FP: 148.0000 - val_FN: 175.0000\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0396 - categorical_accuracy: 0.9868 - top-3: 0.9991 - ROC-AUC: 0.9995 - PR-AUC: 0.9982 - precision: 0.9883 - recall: 0.9855 - TP: 8877.0000 - TN: 98983.0000 - FP: 105.0000 - FN: 131.0000 - val_loss: 0.0308 - val_categorical_accuracy: 0.9902 - val_top-3: 0.9995 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9985 - val_precision: 0.9910 - val_recall: 0.9895 - val_TP: 5953.0000 - val_TN: 66122.0000 - val_FP: 54.0000 - val_FN: 63.0000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 168s 1s/step - loss: 0.0340 - categorical_accuracy: 0.9900 - top-3: 0.9993 - ROC-AUC: 0.9994 - PR-AUC: 0.9982 - precision: 0.9912 - recall: 0.9893 - TP: 8912.0000 - TN: 99009.0000 - FP: 79.0000 - FN: 96.0000 - val_loss: 0.0280 - val_categorical_accuracy: 0.9917 - val_top-3: 0.9993 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9986 - val_precision: 0.9930 - val_recall: 0.9909 - val_TP: 5961.0000 - val_TN: 66134.0000 - val_FP: 42.0000 - val_FN: 55.0000\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0194 - categorical_accuracy: 0.9943 - top-3: 0.9998 - ROC-AUC: 0.9997 - PR-AUC: 0.9988 - precision: 0.9948 - recall: 0.9938 - TP: 8952.0000 - TN: 99041.0000 - FP: 47.0000 - FN: 56.0000 - val_loss: 0.0106 - val_categorical_accuracy: 0.9962 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 0.9999 - val_precision: 0.9965 - val_recall: 0.9958 - val_TP: 5991.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 25.0000\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0535 - categorical_accuracy: 0.9846 - top-3: 0.9990 - ROC-AUC: 0.9989 - PR-AUC: 0.9965 - precision: 0.9860 - recall: 0.9838 - TP: 8862.0000 - TN: 98962.0000 - FP: 126.0000 - FN: 146.0000 - val_loss: 0.0400 - val_categorical_accuracy: 0.9889 - val_top-3: 0.9990 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9982 - val_precision: 0.9912 - val_recall: 0.9877 - val_TP: 5942.0000 - val_TN: 66123.0000 - val_FP: 53.0000 - val_FN: 74.0000\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 168s 1s/step - loss: 0.0123 - categorical_accuracy: 0.9959 - top-3: 0.9997 - ROC-AUC: 1.0000 - PR-AUC: 0.9999 - precision: 0.9963 - recall: 0.9954 - TP: 8967.0000 - TN: 99055.0000 - FP: 33.0000 - FN: 41.0000 - val_loss: 0.0051 - val_categorical_accuracy: 0.9983 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9983 - val_recall: 0.9982 - val_TP: 6005.0000 - val_TN: 66166.0000 - val_FP: 10.0000 - val_FN: 11.0000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0220 - categorical_accuracy: 0.9944 - top-3: 0.9999 - ROC-AUC: 0.9996 - PR-AUC: 0.9986 - precision: 0.9948 - recall: 0.9941 - TP: 8955.0000 - TN: 99041.0000 - FP: 47.0000 - FN: 53.0000 - val_loss: 0.0289 - val_categorical_accuracy: 0.9905 - val_top-3: 0.9997 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9994 - val_precision: 0.9918 - val_recall: 0.9894 - val_TP: 5952.0000 - val_TN: 66127.0000 - val_FP: 49.0000 - val_FN: 64.0000\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0414 - categorical_accuracy: 0.9869 - top-3: 0.9990 - ROC-AUC: 0.9995 - PR-AUC: 0.9983 - precision: 0.9883 - recall: 0.9863 - TP: 8885.0000 - TN: 98983.0000 - FP: 105.0000 - FN: 123.0000 - val_loss: 0.0293 - val_categorical_accuracy: 0.9892 - val_top-3: 0.9992 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9992 - val_precision: 0.9905 - val_recall: 0.9890 - val_TP: 5950.0000 - val_TN: 66119.0000 - val_FP: 57.0000 - val_FN: 66.0000\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0306 - categorical_accuracy: 0.9903 - top-3: 0.9989 - ROC-AUC: 0.9994 - PR-AUC: 0.9983 - precision: 0.9913 - recall: 0.9890 - TP: 8909.0000 - TN: 99010.0000 - FP: 78.0000 - FN: 99.0000 - val_loss: 0.0359 - val_categorical_accuracy: 0.9889 - val_top-3: 0.9983 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9981 - val_precision: 0.9905 - val_recall: 0.9885 - val_TP: 5947.0000 - val_TN: 66119.0000 - val_FP: 57.0000 - val_FN: 69.0000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 170s 1s/step - loss: 0.0598 - categorical_accuracy: 0.9815 - top-3: 0.9991 - ROC-AUC: 0.9991 - PR-AUC: 0.9965 - precision: 0.9830 - recall: 0.9805 - TP: 8832.0000 - TN: 98935.0000 - FP: 153.0000 - FN: 176.0000 - val_loss: 0.0272 - val_categorical_accuracy: 0.9914 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9989 - val_precision: 0.9917 - val_recall: 0.9910 - val_TP: 5962.0000 - val_TN: 66126.0000 - val_FP: 50.0000 - val_FN: 54.0000\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0338 - categorical_accuracy: 0.9908 - top-3: 0.9993 - ROC-AUC: 0.9996 - PR-AUC: 0.9985 - precision: 0.9910 - recall: 0.9901 - TP: 8919.0000 - TN: 99007.0000 - FP: 81.0000 - FN: 89.0000 - val_loss: 0.0132 - val_categorical_accuracy: 0.9965 - val_top-3: 0.9995 - val_ROC-AUC: 1.0000 - val_PR-AUC: 0.9999 - val_precision: 0.9973 - val_recall: 0.9957 - val_TP: 5990.0000 - val_TN: 66160.0000 - val_FP: 16.0000 - val_FN: 26.0000\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0169 - categorical_accuracy: 0.9950 - top-3: 0.9998 - ROC-AUC: 0.9997 - PR-AUC: 0.9991 - precision: 0.9953 - recall: 0.9947 - TP: 8960.0000 - TN: 99046.0000 - FP: 42.0000 - FN: 48.0000 - val_loss: 0.0156 - val_categorical_accuracy: 0.9965 - val_top-3: 0.9997 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9982 - val_precision: 0.9965 - val_recall: 0.9962 - val_TP: 5993.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 23.0000\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0521 - categorical_accuracy: 0.9843 - top-3: 0.9992 - ROC-AUC: 0.9991 - PR-AUC: 0.9965 - precision: 0.9859 - recall: 0.9835 - TP: 8859.0000 - TN: 98961.0000 - FP: 127.0000 - FN: 149.0000 - val_loss: 0.0230 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9998 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9985 - val_precision: 0.9935 - val_recall: 0.9924 - val_TP: 5970.0000 - val_TN: 66137.0000 - val_FP: 39.0000 - val_FN: 46.0000\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0241 - categorical_accuracy: 0.9935 - top-3: 1.0000 - ROC-AUC: 0.9994 - PR-AUC: 0.9983 - precision: 0.9940 - recall: 0.9933 - TP: 8948.0000 - TN: 99034.0000 - FP: 54.0000 - FN: 60.0000 - val_loss: 0.0310 - val_categorical_accuracy: 0.9900 - val_top-3: 0.9995 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9984 - val_precision: 0.9907 - val_recall: 0.9889 - val_TP: 5949.0000 - val_TN: 66120.0000 - val_FP: 56.0000 - val_FN: 67.0000\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0392 - categorical_accuracy: 0.9887 - top-3: 0.9993 - ROC-AUC: 0.9991 - PR-AUC: 0.9971 - precision: 0.9902 - recall: 0.9877 - TP: 8897.0000 - TN: 99000.0000 - FP: 88.0000 - FN: 111.0000 - val_loss: 0.0111 - val_categorical_accuracy: 0.9958 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 0.9999 - val_precision: 0.9962 - val_recall: 0.9958 - val_TP: 5991.0000 - val_TN: 66153.0000 - val_FP: 23.0000 - val_FN: 25.0000\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0152 - categorical_accuracy: 0.9954 - top-3: 0.9997 - ROC-AUC: 0.9998 - PR-AUC: 0.9993 - precision: 0.9962 - recall: 0.9950 - TP: 8963.0000 - TN: 99054.0000 - FP: 34.0000 - FN: 45.0000 - val_loss: 0.0072 - val_categorical_accuracy: 0.9973 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9998 - val_precision: 0.9977 - val_recall: 0.9973 - val_TP: 6000.0000 - val_TN: 66162.0000 - val_FP: 14.0000 - val_FN: 16.0000\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 168s 1s/step - loss: 0.0123 - categorical_accuracy: 0.9963 - top-3: 0.9997 - ROC-AUC: 0.9999 - PR-AUC: 0.9996 - precision: 0.9966 - recall: 0.9960 - TP: 8972.0000 - TN: 99057.0000 - FP: 31.0000 - FN: 36.0000 - val_loss: 0.0122 - val_categorical_accuracy: 0.9965 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9994 - val_precision: 0.9965 - val_recall: 0.9960 - val_TP: 5992.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 24.0000\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0161 - categorical_accuracy: 0.9944 - top-3: 0.9998 - ROC-AUC: 0.9999 - PR-AUC: 0.9995 - precision: 0.9950 - recall: 0.9941 - TP: 8955.0000 - TN: 99043.0000 - FP: 45.0000 - FN: 53.0000 - val_loss: 0.0335 - val_categorical_accuracy: 0.9900 - val_top-3: 0.9995 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9982 - val_precision: 0.9904 - val_recall: 0.9897 - val_TP: 5954.0000 - val_TN: 66118.0000 - val_FP: 58.0000 - val_FN: 62.0000\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0202 - categorical_accuracy: 0.9944 - top-3: 0.9998 - ROC-AUC: 0.9996 - PR-AUC: 0.9989 - precision: 0.9950 - recall: 0.9938 - TP: 8952.0000 - TN: 99043.0000 - FP: 45.0000 - FN: 56.0000 - val_loss: 0.0149 - val_categorical_accuracy: 0.9950 - val_top-3: 1.0000 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9993 - val_precision: 0.9953 - val_recall: 0.9950 - val_TP: 5986.0000 - val_TN: 66148.0000 - val_FP: 28.0000 - val_FN: 30.0000\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0347 - categorical_accuracy: 0.9916 - top-3: 0.9993 - ROC-AUC: 0.9992 - PR-AUC: 0.9975 - precision: 0.9929 - recall: 0.9907 - TP: 8924.0000 - TN: 99024.0000 - FP: 64.0000 - FN: 84.0000 - val_loss: 0.0192 - val_categorical_accuracy: 0.9937 - val_top-3: 0.9990 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9948 - val_recall: 0.9934 - val_TP: 5976.0000 - val_TN: 66145.0000 - val_FP: 31.0000 - val_FN: 40.0000\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 167s 1s/step - loss: 0.0246 - categorical_accuracy: 0.9920 - top-3: 0.9997 - ROC-AUC: 0.9996 - PR-AUC: 0.9985 - precision: 0.9932 - recall: 0.9918 - TP: 8934.0000 - TN: 99027.0000 - FP: 61.0000 - FN: 74.0000 - val_loss: 0.0262 - val_categorical_accuracy: 0.9929 - val_top-3: 0.9993 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9986 - val_precision: 0.9937 - val_recall: 0.9922 - val_TP: 5969.0000 - val_TN: 66138.0000 - val_FP: 38.0000 - val_FN: 47.0000\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0154 - categorical_accuracy: 0.9951 - top-3: 0.9997 - ROC-AUC: 0.9999 - PR-AUC: 0.9996 - precision: 0.9954 - recall: 0.9946 - TP: 8959.0000 - TN: 99047.0000 - FP: 41.0000 - FN: 49.0000 - val_loss: 0.0067 - val_categorical_accuracy: 0.9977 - val_top-3: 0.9998 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9980 - val_recall: 0.9973 - val_TP: 6000.0000 - val_TN: 66164.0000 - val_FP: 12.0000 - val_FN: 16.0000\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0075 - categorical_accuracy: 0.9981 - top-3: 0.9998 - ROC-AUC: 0.9998 - PR-AUC: 0.9995 - precision: 0.9983 - recall: 0.9979 - TP: 8989.0000 - TN: 99073.0000 - FP: 15.0000 - FN: 19.0000 - val_loss: 0.0023 - val_categorical_accuracy: 0.9995 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9995 - val_recall: 0.9995 - val_TP: 6013.0000 - val_TN: 66173.0000 - val_FP: 3.0000 - val_FN: 3.0000\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0283 - categorical_accuracy: 0.9926 - top-3: 0.9996 - ROC-AUC: 0.9993 - PR-AUC: 0.9976 - precision: 0.9933 - recall: 0.9922 - TP: 8938.0000 - TN: 99028.0000 - FP: 60.0000 - FN: 70.0000 - val_loss: 0.1103 - val_categorical_accuracy: 0.9674 - val_top-3: 0.9983 - val_ROC-AUC: 0.9971 - val_PR-AUC: 0.9893 - val_precision: 0.9691 - val_recall: 0.9658 - val_TP: 5810.0000 - val_TN: 65991.0000 - val_FP: 185.0000 - val_FN: 206.0000\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0481 - categorical_accuracy: 0.9862 - top-3: 0.9991 - ROC-AUC: 0.9990 - PR-AUC: 0.9963 - precision: 0.9874 - recall: 0.9851 - TP: 8874.0000 - TN: 98975.0000 - FP: 113.0000 - FN: 134.0000 - val_loss: 0.0657 - val_categorical_accuracy: 0.9789 - val_top-3: 0.9985 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9958 - val_precision: 0.9820 - val_recall: 0.9772 - val_TP: 5879.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 137.0000\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0282 - categorical_accuracy: 0.9918 - top-3: 0.9997 - ROC-AUC: 0.9996 - PR-AUC: 0.9987 - precision: 0.9926 - recall: 0.9911 - TP: 8928.0000 - TN: 99021.0000 - FP: 67.0000 - FN: 80.0000 - val_loss: 0.0265 - val_categorical_accuracy: 0.9922 - val_top-3: 1.0000 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9974 - val_precision: 0.9922 - val_recall: 0.9919 - val_TP: 5967.0000 - val_TN: 66129.0000 - val_FP: 47.0000 - val_FN: 49.0000\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0314 - categorical_accuracy: 0.9913 - top-3: 0.9993 - ROC-AUC: 0.9995 - PR-AUC: 0.9984 - precision: 0.9917 - recall: 0.9903 - TP: 8921.0000 - TN: 99013.0000 - FP: 75.0000 - FN: 87.0000 - val_loss: 0.0045 - val_categorical_accuracy: 0.9987 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9988 - val_recall: 0.9985 - val_TP: 6007.0000 - val_TN: 66169.0000 - val_FP: 7.0000 - val_FN: 9.0000\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0055 - categorical_accuracy: 0.9982 - top-3: 1.0000 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - precision: 0.9982 - recall: 0.9981 - TP: 8991.0000 - TN: 99072.0000 - FP: 16.0000 - FN: 17.0000 - val_loss: 0.0179 - val_categorical_accuracy: 0.9942 - val_top-3: 1.0000 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9942 - val_recall: 0.9938 - val_TP: 5979.0000 - val_TN: 66141.0000 - val_FP: 35.0000 - val_FN: 37.0000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0566 - categorical_accuracy: 0.9858 - top-3: 0.9991 - ROC-AUC: 0.9985 - PR-AUC: 0.9951 - precision: 0.9869 - recall: 0.9843 - TP: 8867.0000 - TN: 98970.0000 - FP: 118.0000 - FN: 141.0000 - val_loss: 0.0032 - val_categorical_accuracy: 0.9990 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9993 - val_recall: 0.9990 - val_TP: 6010.0000 - val_TN: 66172.0000 - val_FP: 4.0000 - val_FN: 6.0000\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0230 - categorical_accuracy: 0.9923 - top-3: 0.9997 - ROC-AUC: 0.9997 - PR-AUC: 0.9990 - precision: 0.9929 - recall: 0.9921 - TP: 8937.0000 - TN: 99024.0000 - FP: 64.0000 - FN: 71.0000 - val_loss: 0.0405 - val_categorical_accuracy: 0.9885 - val_top-3: 0.9978 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9979 - val_precision: 0.9905 - val_recall: 0.9869 - val_TP: 5937.0000 - val_TN: 66119.0000 - val_FP: 57.0000 - val_FN: 79.0000\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0149 - categorical_accuracy: 0.9953 - top-3: 0.9998 - ROC-AUC: 0.9999 - PR-AUC: 0.9996 - precision: 0.9958 - recall: 0.9948 - TP: 8961.0000 - TN: 99050.0000 - FP: 38.0000 - FN: 47.0000 - val_loss: 0.0142 - val_categorical_accuracy: 0.9953 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 0.9999 - val_precision: 0.9953 - val_recall: 0.9950 - val_TP: 5986.0000 - val_TN: 66148.0000 - val_FP: 28.0000 - val_FN: 30.0000\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0120 - categorical_accuracy: 0.9968 - top-3: 0.9999 - ROC-AUC: 0.9997 - PR-AUC: 0.9991 - precision: 0.9970 - recall: 0.9964 - TP: 8976.0000 - TN: 99061.0000 - FP: 27.0000 - FN: 32.0000 - val_loss: 0.0092 - val_categorical_accuracy: 0.9978 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9993 - val_precision: 0.9980 - val_recall: 0.9975 - val_TP: 6001.0000 - val_TN: 66164.0000 - val_FP: 12.0000 - val_FN: 15.0000\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0104 - categorical_accuracy: 0.9967 - top-3: 0.9994 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - precision: 0.9971 - recall: 0.9964 - TP: 8976.0000 - TN: 99062.0000 - FP: 26.0000 - FN: 32.0000 - val_loss: 0.0088 - val_categorical_accuracy: 0.9967 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9967 - val_recall: 0.9967 - val_TP: 5996.0000 - val_TN: 66156.0000 - val_FP: 20.0000 - val_FN: 20.0000\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0135 - categorical_accuracy: 0.9962 - top-3: 0.9998 - ROC-AUC: 0.9998 - PR-AUC: 0.9995 - precision: 0.9967 - recall: 0.9959 - TP: 8971.0000 - TN: 99058.0000 - FP: 30.0000 - FN: 37.0000 - val_loss: 0.0083 - val_categorical_accuracy: 0.9977 - val_top-3: 0.9997 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9995 - val_precision: 0.9978 - val_recall: 0.9975 - val_TP: 6001.0000 - val_TN: 66163.0000 - val_FP: 13.0000 - val_FN: 15.0000\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0356 - categorical_accuracy: 0.9908 - top-3: 0.9992 - ROC-AUC: 0.9993 - PR-AUC: 0.9979 - precision: 0.9921 - recall: 0.9903 - TP: 8921.0000 - TN: 99017.0000 - FP: 71.0000 - FN: 87.0000 - val_loss: 0.0244 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9997 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9987 - val_precision: 0.9933 - val_recall: 0.9922 - val_TP: 5969.0000 - val_TN: 66136.0000 - val_FP: 40.0000 - val_FN: 47.0000\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0243 - categorical_accuracy: 0.9943 - top-3: 0.9997 - ROC-AUC: 0.9996 - PR-AUC: 0.9984 - precision: 0.9947 - recall: 0.9936 - TP: 8950.0000 - TN: 99040.0000 - FP: 48.0000 - FN: 58.0000 - val_loss: 0.0335 - val_categorical_accuracy: 0.9897 - val_top-3: 1.0000 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9977 - val_precision: 0.9903 - val_recall: 0.9887 - val_TP: 5948.0000 - val_TN: 66118.0000 - val_FP: 58.0000 - val_FN: 68.0000\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0201 - categorical_accuracy: 0.9940 - top-3: 0.9998 - ROC-AUC: 0.9996 - PR-AUC: 0.9988 - precision: 0.9946 - recall: 0.9935 - TP: 8949.0000 - TN: 99039.0000 - FP: 49.0000 - FN: 59.0000 - val_loss: 0.0056 - val_categorical_accuracy: 0.9983 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9983 - val_recall: 0.9980 - val_TP: 6004.0000 - val_TN: 66166.0000 - val_FP: 10.0000 - val_FN: 12.0000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0148 - categorical_accuracy: 0.9960 - top-3: 0.9997 - ROC-AUC: 0.9996 - PR-AUC: 0.9991 - precision: 0.9964 - recall: 0.9958 - TP: 8970.0000 - TN: 99056.0000 - FP: 32.0000 - FN: 38.0000 - val_loss: 0.0060 - val_categorical_accuracy: 0.9982 - val_top-3: 0.9998 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9982 - val_recall: 0.9978 - val_TP: 6003.0000 - val_TN: 66165.0000 - val_FP: 11.0000 - val_FN: 13.0000\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 163s 1s/step - loss: 0.0017 - categorical_accuracy: 0.9993 - top-3: 1.0000 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - precision: 0.9993 - recall: 0.9993 - TP: 9002.0000 - TN: 99082.0000 - FP: 6.0000 - FN: 6.0000 - val_loss: 0.0028 - val_categorical_accuracy: 0.9992 - val_top-3: 1.0000 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9993 - val_recall: 0.9990 - val_TP: 6010.0000 - val_TN: 66172.0000 - val_FP: 4.0000 - val_FN: 6.0000\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 164s 1s/step - loss: 0.0025 - categorical_accuracy: 0.9992 - top-3: 1.0000 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - precision: 0.9992 - recall: 0.9990 - TP: 8999.0000 - TN: 99081.0000 - FP: 7.0000 - FN: 9.0000 - val_loss: 0.0049 - val_categorical_accuracy: 0.9988 - val_top-3: 1.0000 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9996 - val_precision: 0.9988 - val_recall: 0.9987 - val_TP: 6008.0000 - val_TN: 66169.0000 - val_FP: 7.0000 - val_FN: 8.0000\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 165s 1s/step - loss: 0.0162 - categorical_accuracy: 0.9953 - top-3: 0.9999 - ROC-AUC: 0.9999 - PR-AUC: 0.9996 - precision: 0.9956 - recall: 0.9950 - TP: 8963.0000 - TN: 99048.0000 - FP: 40.0000 - FN: 45.0000 - val_loss: 0.0198 - val_categorical_accuracy: 0.9947 - val_top-3: 0.9998 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9981 - val_precision: 0.9952 - val_recall: 0.9938 - val_TP: 5979.0000 - val_TN: 66147.0000 - val_FP: 29.0000 - val_FN: 37.0000\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 166s 1s/step - loss: 0.0206 - categorical_accuracy: 0.9939 - top-3: 0.9996 - ROC-AUC: 0.9995 - PR-AUC: 0.9984 - precision: 0.9944 - recall: 0.9931 - TP: 8946.0000 - TN: 99038.0000 - FP: 50.0000 - FN: 62.0000 - val_loss: 0.0085 - val_categorical_accuracy: 0.9973 - val_top-3: 0.9998 - val_ROC-AUC: 1.0000 - val_PR-AUC: 1.0000 - val_precision: 0.9978 - val_recall: 0.9965 - val_TP: 5995.0000 - val_TN: 66163.0000 - val_FP: 13.0000 - val_FN: 21.0000\n",
      "-----\n",
      "(8631482.04 ms) == (143m:51s)\n",
      "-----\n",
      "\n",
      "\n",
      "21\n",
      "['mobilenetv2_1.00_96-64-12.tensorboard',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.001_0.9029_0.3041.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.002_0.9604_0.1234.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.004_0.9764_0.0759.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.005_0.9799_0.0717.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.007_0.9850_0.0590.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.010_0.9902_0.0308.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.011_0.9917_0.0280.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.012_0.9962_0.0106.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.014_0.9983_0.0051.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.031_0.9995_0.0023.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_96-64-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_96-64-12.csv',\n",
      " 'model.mobilenetv2_1.00_96-64-12.h5',\n",
      " 'weights.mobilenetv2_1.00_96-64-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_96-64-12\n",
    "model_14 = consecutiveModelTraining(\n",
    "    input_size=96,\n",
    "    batch_size=64,\n",
    "    weights=None,\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890106c1-75af-4497-84e1-93c99de4053e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T06:33:42.336955Z",
     "iopub.status.busy": "2021-06-11T06:33:42.336955Z",
     "iopub.status.idle": "2021-06-11T06:33:42.415969Z",
     "shell.execute_reply": "2021-06-11T06:33:42.414960Z",
     "shell.execute_reply.started": "2021-06-11T06:33:42.336955Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.980500</td>\n",
       "      <td>0.995049</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.986164</td>\n",
       "      <td>0.977460</td>\n",
       "      <td>8804.960000</td>\n",
       "      <td>98978.080000</td>\n",
       "      <td>109.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988128</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>0.997090</td>\n",
       "      <td>0.989524</td>\n",
       "      <td>0.987068</td>\n",
       "      <td>5938.200000</td>\n",
       "      <td>66113.520000</td>\n",
       "      <td>62.480000</td>\n",
       "      <td>77.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.195863</td>\n",
       "      <td>0.058963</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.028310</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>661.500982</td>\n",
       "      <td>166.849418</td>\n",
       "      <td>166.849418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>0.018359</td>\n",
       "      <td>110.447328</td>\n",
       "      <td>81.905431</td>\n",
       "      <td>81.905431</td>\n",
       "      <td>110.447328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.581816</td>\n",
       "      <td>0.794849</td>\n",
       "      <td>0.919784</td>\n",
       "      <td>0.676088</td>\n",
       "      <td>0.806289</td>\n",
       "      <td>0.478242</td>\n",
       "      <td>4308.000000</td>\n",
       "      <td>98053.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902926</td>\n",
       "      <td>0.989528</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.963066</td>\n",
       "      <td>0.919477</td>\n",
       "      <td>0.888298</td>\n",
       "      <td>5344.000000</td>\n",
       "      <td>65708.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.986151</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>0.996640</td>\n",
       "      <td>0.987507</td>\n",
       "      <td>0.984791</td>\n",
       "      <td>8871.000000</td>\n",
       "      <td>98975.750000</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988863</td>\n",
       "      <td>0.998629</td>\n",
       "      <td>0.999380</td>\n",
       "      <td>0.997774</td>\n",
       "      <td>0.990387</td>\n",
       "      <td>0.987907</td>\n",
       "      <td>5943.250000</td>\n",
       "      <td>66118.250000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>20.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.993054</td>\n",
       "      <td>0.991952</td>\n",
       "      <td>8935.500000</td>\n",
       "      <td>99025.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992769</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.993592</td>\n",
       "      <td>0.992271</td>\n",
       "      <td>5969.500000</td>\n",
       "      <td>66137.500000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>46.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.048854</td>\n",
       "      <td>0.995282</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>8960.750000</td>\n",
       "      <td>99047.750000</td>\n",
       "      <td>112.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.997588</td>\n",
       "      <td>0.996634</td>\n",
       "      <td>5995.750000</td>\n",
       "      <td>66161.500000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>72.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.391766</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>9002.000000</td>\n",
       "      <td>99082.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>6013.000000</td>\n",
       "      <td>66173.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.065536              0.980500   0.995049   0.997692   0.990837   \n",
       "std     0.195863              0.058963   0.028922   0.011279   0.045653   \n",
       "min     0.001726              0.581816   0.794849   0.919784   0.676088   \n",
       "25%     0.015568              0.986151   0.999112   0.999103   0.996640   \n",
       "50%     0.026385              0.992174   0.999556   0.999540   0.998422   \n",
       "75%     0.048854              0.995282   0.999778   0.999752   0.999267   \n",
       "max     1.391766              0.999334   1.000000   1.000000   0.999999   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.986164   0.977460  8804.960000  98978.080000   109.920000  ...   \n",
       "std     0.028310   0.073435   661.500982    166.849418   166.849418  ...   \n",
       "min     0.806289   0.478242  4308.000000  98053.000000     6.000000  ...   \n",
       "25%     0.987507   0.984791  8871.000000  98975.750000    40.250000  ...   \n",
       "50%     0.993054   0.991952  8935.500000  99025.500000    62.500000  ...   \n",
       "75%     0.995529   0.994755  8960.750000  99047.750000   112.250000  ...   \n",
       "max     0.999334   0.999334  9002.000000  99082.000000  1035.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.988128   0.998906     0.999245    0.997090   \n",
       "std                    0.016416   0.001974     0.001284    0.006008   \n",
       "min                    0.902926   0.989528     0.993000    0.963066   \n",
       "25%                    0.988863   0.998629     0.999380    0.997774   \n",
       "50%                    0.992769   0.999668     0.999639    0.998812   \n",
       "75%                    0.997174   1.000000     0.999908    0.999691   \n",
       "max                    0.999501   1.000000     1.000000    0.999999   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.989524    0.987068  5938.200000  66113.520000   62.480000   \n",
       "std         0.013939    0.018359   110.447328     81.905431   81.905431   \n",
       "min         0.919477    0.888298  5344.000000  65708.000000    3.000000   \n",
       "25%         0.990387    0.987907  5943.250000  66118.250000   14.500000   \n",
       "50%         0.993592    0.992271  5969.500000  66137.500000   38.500000   \n",
       "75%         0.997588    0.996634  5995.750000  66161.500000   57.750000   \n",
       "max         0.999501    0.999501  6013.000000  66173.000000  468.000000   \n",
       "\n",
       "           val_FN  \n",
       "count   50.000000  \n",
       "mean    77.800000  \n",
       "std    110.447328  \n",
       "min      3.000000  \n",
       "25%     20.250000  \n",
       "50%     46.500000  \n",
       "75%     72.750000  \n",
       "max    672.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_14['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e19b5-ca0f-4713-9852-35494303fa98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4eeebfd-85ba-441f-8bb7-d827ed436742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T06:33:42.417964Z",
     "iopub.status.busy": "2021-06-11T06:33:42.416963Z",
     "iopub.status.idle": "2021-06-11T08:48:24.479406Z",
     "shell.execute_reply": "2021-06-11T08:48:24.479406Z",
     "shell.execute_reply.started": "2021-06-11T06:33:42.417964Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_64-16-fc12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_64-16-fc12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_64 (Functio (None, 2, 2, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,686,156\n",
      "Trainable params: 2,652,044\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_64-16-fc12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_64-16-fc12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_64-16-fc12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 56:10 - loss: 10.0585 - categorical_accuracy: 0.0312 - top-3: 0.1562 - ROC-AUC: 0.4767 - PR-AUC: 0.0748 - precision: 0.0000e+00 - recall: 0.0000e+00 - TP: 0.0000e+00 - TN: 336.0000 - FP: 16.0000 - FN: 32.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2120s vs `on_train_batch_end` time: 11.7150s). Check your callbacks.\n",
      "567/567 [==============================] - 177s 312ms/step - loss: 2.2085 - categorical_accuracy: 0.1741 - top-3: 0.4654 - ROC-AUC: 0.7256 - PR-AUC: 0.1918 - precision: 0.4527 - recall: 0.0195 - TP: 177.0000 - TN: 99578.0000 - FP: 214.0000 - FN: 8895.0000 - val_loss: 1.7152 - val_categorical_accuracy: 0.2814 - val_top-3: 0.7088 - val_ROC-AUC: 0.8582 - val_PR-AUC: 0.3201 - val_precision: 0.5841 - val_recall: 0.0109 - val_TP: 66.0000 - val_TN: 66481.0000 - val_FP: 47.0000 - val_FN: 5982.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 1.7826 - categorical_accuracy: 0.2935 - top-3: 0.6865 - ROC-AUC: 0.8413 - PR-AUC: 0.3072 - precision: 0.5313 - recall: 0.0515 - TP: 467.0000 - TN: 99380.0000 - FP: 412.0000 - FN: 8605.0000 - val_loss: 1.5874 - val_categorical_accuracy: 0.3750 - val_top-3: 0.7493 - val_ROC-AUC: 0.8803 - val_PR-AUC: 0.4054 - val_precision: 0.7714 - val_recall: 0.0536 - val_TP: 324.0000 - val_TN: 66432.0000 - val_FP: 96.0000 - val_FN: 5724.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 1.6289 - categorical_accuracy: 0.3417 - top-3: 0.7405 - ROC-AUC: 0.8738 - PR-AUC: 0.3739 - precision: 0.5295 - recall: 0.1176 - TP: 1067.0000 - TN: 98844.0000 - FP: 948.0000 - FN: 8005.0000 - val_loss: 1.5405 - val_categorical_accuracy: 0.3633 - val_top-3: 0.7722 - val_ROC-AUC: 0.8901 - val_PR-AUC: 0.3905 - val_precision: 0.4634 - val_recall: 0.0732 - val_TP: 443.0000 - val_TN: 66015.0000 - val_FP: 513.0000 - val_FN: 5605.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 1.4681 - categorical_accuracy: 0.3950 - top-3: 0.8006 - ROC-AUC: 0.9005 - PR-AUC: 0.4601 - precision: 0.6129 - recall: 0.2032 - TP: 1843.0000 - TN: 98628.0000 - FP: 1164.0000 - FN: 7229.0000 - val_loss: 1.1417 - val_categorical_accuracy: 0.5362 - val_top-3: 0.8621 - val_ROC-AUC: 0.9393 - val_PR-AUC: 0.6523 - val_precision: 0.7846 - val_recall: 0.3788 - val_TP: 2291.0000 - val_TN: 65899.0000 - val_FP: 629.0000 - val_FN: 3757.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 1.3312 - categorical_accuracy: 0.4878 - top-3: 0.8097 - ROC-AUC: 0.9176 - PR-AUC: 0.5880 - precision: 0.7567 - recall: 0.3103 - TP: 2815.0000 - TN: 98887.0000 - FP: 905.0000 - FN: 6257.0000 - val_loss: 1.2867 - val_categorical_accuracy: 0.5157 - val_top-3: 0.7922 - val_ROC-AUC: 0.9187 - val_PR-AUC: 0.6210 - val_precision: 0.9069 - val_recall: 0.3108 - val_TP: 1880.0000 - val_TN: 66335.0000 - val_FP: 193.0000 - val_FN: 4168.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 1.3163 - categorical_accuracy: 0.4972 - top-3: 0.8035 - ROC-AUC: 0.9179 - PR-AUC: 0.6042 - precision: 0.7882 - recall: 0.3191 - TP: 2895.0000 - TN: 99014.0000 - FP: 778.0000 - FN: 6177.0000 - val_loss: 1.0061 - val_categorical_accuracy: 0.6035 - val_top-3: 0.8986 - val_ROC-AUC: 0.9552 - val_PR-AUC: 0.7209 - val_precision: 0.8522 - val_recall: 0.3993 - val_TP: 2415.0000 - val_TN: 66109.0000 - val_FP: 419.0000 - val_FN: 3633.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 1.1094 - categorical_accuracy: 0.5585 - top-3: 0.8689 - ROC-AUC: 0.9424 - PR-AUC: 0.6865 - precision: 0.8071 - recall: 0.3975 - TP: 3606.0000 - TN: 98930.0000 - FP: 862.0000 - FN: 5466.0000 - val_loss: 1.0206 - val_categorical_accuracy: 0.5795 - val_top-3: 0.9215 - val_ROC-AUC: 0.9539 - val_PR-AUC: 0.7226 - val_precision: 0.7846 - val_recall: 0.4428 - val_TP: 2678.0000 - val_TN: 65793.0000 - val_FP: 735.0000 - val_FN: 3370.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 1.2156 - categorical_accuracy: 0.5282 - top-3: 0.8308 - ROC-AUC: 0.9301 - PR-AUC: 0.6512 - precision: 0.8140 - recall: 0.3651 - TP: 3312.0000 - TN: 99035.0000 - FP: 757.0000 - FN: 5760.0000 - val_loss: 1.0210 - val_categorical_accuracy: 0.6159 - val_top-3: 0.8838 - val_ROC-AUC: 0.9514 - val_PR-AUC: 0.7281 - val_precision: 0.8601 - val_recall: 0.4097 - val_TP: 2478.0000 - val_TN: 66125.0000 - val_FP: 403.0000 - val_FN: 3570.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 1.0734 - categorical_accuracy: 0.5928 - top-3: 0.8784 - ROC-AUC: 0.9462 - PR-AUC: 0.7092 - precision: 0.8215 - recall: 0.4280 - TP: 3883.0000 - TN: 98948.0000 - FP: 844.0000 - FN: 5189.0000 - val_loss: 0.8552 - val_categorical_accuracy: 0.6655 - val_top-3: 0.9182 - val_ROC-AUC: 0.9658 - val_PR-AUC: 0.7888 - val_precision: 0.9015 - val_recall: 0.4692 - val_TP: 2838.0000 - val_TN: 66218.0000 - val_FP: 310.0000 - val_FN: 3210.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 1.0808 - categorical_accuracy: 0.5987 - top-3: 0.8610 - ROC-AUC: 0.9448 - PR-AUC: 0.7157 - precision: 0.8375 - recall: 0.4454 - TP: 4041.0000 - TN: 99008.0000 - FP: 784.0000 - FN: 5031.0000 - val_loss: 0.8396 - val_categorical_accuracy: 0.6645 - val_top-3: 0.9107 - val_ROC-AUC: 0.9669 - val_PR-AUC: 0.7977 - val_precision: 0.8844 - val_recall: 0.5061 - val_TP: 3061.0000 - val_TN: 66128.0000 - val_FP: 400.0000 - val_FN: 2987.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.9498 - categorical_accuracy: 0.6519 - top-3: 0.8988 - ROC-AUC: 0.9579 - PR-AUC: 0.7654 - precision: 0.8348 - recall: 0.5141 - TP: 4664.0000 - TN: 98869.0000 - FP: 923.0000 - FN: 4408.0000 - val_loss: 0.7698 - val_categorical_accuracy: 0.7077 - val_top-3: 0.9254 - val_ROC-AUC: 0.9727 - val_PR-AUC: 0.8317 - val_precision: 0.8740 - val_recall: 0.5699 - val_TP: 3447.0000 - val_TN: 66031.0000 - val_FP: 497.0000 - val_FN: 2601.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 160s 283ms/step - loss: 0.8350 - categorical_accuracy: 0.7007 - top-3: 0.9172 - ROC-AUC: 0.9665 - PR-AUC: 0.8110 - precision: 0.8526 - recall: 0.5756 - TP: 5222.0000 - TN: 98889.0000 - FP: 903.0000 - FN: 3850.0000 - val_loss: 0.7331 - val_categorical_accuracy: 0.7318 - val_top-3: 0.9380 - val_ROC-AUC: 0.9752 - val_PR-AUC: 0.8429 - val_precision: 0.9033 - val_recall: 0.5870 - val_TP: 3550.0000 - val_TN: 66148.0000 - val_FP: 380.0000 - val_FN: 2498.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.8559 - categorical_accuracy: 0.7072 - top-3: 0.9169 - ROC-AUC: 0.9647 - PR-AUC: 0.8066 - precision: 0.8368 - recall: 0.5831 - TP: 5290.0000 - TN: 98760.0000 - FP: 1032.0000 - FN: 3782.0000 - val_loss: 0.6360 - val_categorical_accuracy: 0.7703 - val_top-3: 0.9542 - val_ROC-AUC: 0.9808 - val_PR-AUC: 0.8803 - val_precision: 0.9196 - val_recall: 0.6316 - val_TP: 3820.0000 - val_TN: 66194.0000 - val_FP: 334.0000 - val_FN: 2228.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.8181 - categorical_accuracy: 0.7196 - top-3: 0.9237 - ROC-AUC: 0.9670 - PR-AUC: 0.8195 - precision: 0.8417 - recall: 0.5956 - TP: 5403.0000 - TN: 98776.0000 - FP: 1016.0000 - FN: 3669.0000 - val_loss: 0.8461 - val_categorical_accuracy: 0.7209 - val_top-3: 0.9264 - val_ROC-AUC: 0.9684 - val_PR-AUC: 0.8115 - val_precision: 0.8872 - val_recall: 0.5410 - val_TP: 3272.0000 - val_TN: 66112.0000 - val_FP: 416.0000 - val_FN: 2776.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.7841 - categorical_accuracy: 0.7317 - top-3: 0.9286 - ROC-AUC: 0.9704 - PR-AUC: 0.8321 - precision: 0.8553 - recall: 0.6160 - TP: 5588.0000 - TN: 98847.0000 - FP: 945.0000 - FN: 3484.0000 - val_loss: 0.5611 - val_categorical_accuracy: 0.8216 - val_top-3: 0.9580 - val_ROC-AUC: 0.9841 - val_PR-AUC: 0.9083 - val_precision: 0.8984 - val_recall: 0.7297 - val_TP: 4413.0000 - val_TN: 66029.0000 - val_FP: 499.0000 - val_FN: 1635.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.9596 - categorical_accuracy: 0.6834 - top-3: 0.8908 - ROC-AUC: 0.9556 - PR-AUC: 0.7796 - precision: 0.8466 - recall: 0.5599 - TP: 5079.0000 - TN: 98872.0000 - FP: 920.0000 - FN: 3993.0000 - val_loss: 1.0870 - val_categorical_accuracy: 0.6240 - val_top-3: 0.8796 - val_ROC-AUC: 0.9464 - val_PR-AUC: 0.7164 - val_precision: 0.8193 - val_recall: 0.4363 - val_TP: 2639.0000 - val_TN: 65946.0000 - val_FP: 582.0000 - val_FN: 3409.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.9708 - categorical_accuracy: 0.6625 - top-3: 0.8902 - ROC-AUC: 0.9554 - PR-AUC: 0.7646 - precision: 0.8468 - recall: 0.5101 - TP: 4628.0000 - TN: 98955.0000 - FP: 837.0000 - FN: 4444.0000 - val_loss: 0.6031 - val_categorical_accuracy: 0.7897 - val_top-3: 0.9549 - val_ROC-AUC: 0.9818 - val_PR-AUC: 0.8894 - val_precision: 0.8801 - val_recall: 0.6895 - val_TP: 4170.0000 - val_TN: 65960.0000 - val_FP: 568.0000 - val_FN: 1878.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 160s 283ms/step - loss: 0.8885 - categorical_accuracy: 0.7054 - top-3: 0.9138 - ROC-AUC: 0.9623 - PR-AUC: 0.8055 - precision: 0.8584 - recall: 0.5759 - TP: 5225.0000 - TN: 98930.0000 - FP: 862.0000 - FN: 3847.0000 - val_loss: 0.8853 - val_categorical_accuracy: 0.7247 - val_top-3: 0.9168 - val_ROC-AUC: 0.9643 - val_PR-AUC: 0.8047 - val_precision: 0.8796 - val_recall: 0.5475 - val_TP: 3311.0000 - val_TN: 66075.0000 - val_FP: 453.0000 - val_FN: 2737.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.8848 - categorical_accuracy: 0.6881 - top-3: 0.9045 - ROC-AUC: 0.9621 - PR-AUC: 0.8008 - precision: 0.8623 - recall: 0.5612 - TP: 5091.0000 - TN: 98979.0000 - FP: 813.0000 - FN: 3981.0000 - val_loss: 0.6745 - val_categorical_accuracy: 0.7465 - val_top-3: 0.9438 - val_ROC-AUC: 0.9777 - val_PR-AUC: 0.8635 - val_precision: 0.8795 - val_recall: 0.6177 - val_TP: 3736.0000 - val_TN: 66016.0000 - val_FP: 512.0000 - val_FN: 2312.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.7845 - categorical_accuracy: 0.7320 - top-3: 0.9284 - ROC-AUC: 0.9713 - PR-AUC: 0.8345 - precision: 0.8633 - recall: 0.6099 - TP: 5533.0000 - TN: 98916.0000 - FP: 876.0000 - FN: 3539.0000 - val_loss: 0.5546 - val_categorical_accuracy: 0.7874 - val_top-3: 0.9598 - val_ROC-AUC: 0.9846 - val_PR-AUC: 0.8989 - val_precision: 0.9024 - val_recall: 0.6619 - val_TP: 4003.0000 - val_TN: 66095.0000 - val_FP: 433.0000 - val_FN: 2045.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 159s 281ms/step - loss: 0.8145 - categorical_accuracy: 0.7317 - top-3: 0.9214 - ROC-AUC: 0.9678 - PR-AUC: 0.8268 - precision: 0.8471 - recall: 0.6194 - TP: 5619.0000 - TN: 98778.0000 - FP: 1014.0000 - FN: 3453.0000 - val_loss: 0.6722 - val_categorical_accuracy: 0.7984 - val_top-3: 0.9461 - val_ROC-AUC: 0.9774 - val_PR-AUC: 0.8767 - val_precision: 0.9020 - val_recall: 0.6756 - val_TP: 4086.0000 - val_TN: 66084.0000 - val_FP: 444.0000 - val_FN: 1962.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.6154 - categorical_accuracy: 0.8089 - top-3: 0.9509 - ROC-AUC: 0.9794 - PR-AUC: 0.8885 - precision: 0.8698 - recall: 0.7370 - TP: 6686.0000 - TN: 98791.0000 - FP: 1001.0000 - FN: 2386.0000 - val_loss: 0.4418 - val_categorical_accuracy: 0.8578 - val_top-3: 0.9611 - val_ROC-AUC: 0.9881 - val_PR-AUC: 0.9363 - val_precision: 0.9075 - val_recall: 0.8158 - val_TP: 4934.0000 - val_TN: 66025.0000 - val_FP: 503.0000 - val_FN: 1114.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.6571 - categorical_accuracy: 0.7946 - top-3: 0.9426 - ROC-AUC: 0.9776 - PR-AUC: 0.8805 - precision: 0.8628 - recall: 0.7377 - TP: 6692.0000 - TN: 98728.0000 - FP: 1064.0000 - FN: 2380.0000 - val_loss: 0.6039 - val_categorical_accuracy: 0.7864 - val_top-3: 0.9555 - val_ROC-AUC: 0.9829 - val_PR-AUC: 0.8948 - val_precision: 0.9259 - val_recall: 0.6839 - val_TP: 4136.0000 - val_TN: 66197.0000 - val_FP: 331.0000 - val_FN: 1912.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.7180 - categorical_accuracy: 0.7679 - top-3: 0.9392 - ROC-AUC: 0.9741 - PR-AUC: 0.8612 - precision: 0.8691 - recall: 0.6785 - TP: 6155.0000 - TN: 98865.0000 - FP: 927.0000 - FN: 2917.0000 - val_loss: 0.5672 - val_categorical_accuracy: 0.8327 - val_top-3: 0.9560 - val_ROC-AUC: 0.9819 - val_PR-AUC: 0.9028 - val_precision: 0.8671 - val_recall: 0.7960 - val_TP: 4814.0000 - val_TN: 65790.0000 - val_FP: 738.0000 - val_FN: 1234.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.5698 - categorical_accuracy: 0.8255 - top-3: 0.9575 - ROC-AUC: 0.9821 - PR-AUC: 0.9045 - precision: 0.8815 - recall: 0.7722 - TP: 7005.0000 - TN: 98850.0000 - FP: 942.0000 - FN: 2067.0000 - val_loss: 0.3838 - val_categorical_accuracy: 0.8912 - val_top-3: 0.9730 - val_ROC-AUC: 0.9908 - val_PR-AUC: 0.9510 - val_precision: 0.9208 - val_recall: 0.8598 - val_TP: 5200.0000 - val_TN: 66081.0000 - val_FP: 447.0000 - val_FN: 848.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.4687 - categorical_accuracy: 0.8682 - top-3: 0.9687 - ROC-AUC: 0.9864 - PR-AUC: 0.9305 - precision: 0.9096 - recall: 0.8302 - TP: 7532.0000 - TN: 99043.0000 - FP: 749.0000 - FN: 1540.0000 - val_loss: 0.2475 - val_categorical_accuracy: 0.9315 - val_top-3: 0.9846 - val_ROC-AUC: 0.9957 - val_PR-AUC: 0.9757 - val_precision: 0.9456 - val_recall: 0.9228 - val_TP: 5581.0000 - val_TN: 66207.0000 - val_FP: 321.0000 - val_FN: 467.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.3905 - categorical_accuracy: 0.8908 - top-3: 0.9753 - ROC-AUC: 0.9893 - PR-AUC: 0.9460 - precision: 0.9174 - recall: 0.8636 - TP: 7835.0000 - TN: 99087.0000 - FP: 705.0000 - FN: 1237.0000 - val_loss: 0.2584 - val_categorical_accuracy: 0.9243 - val_top-3: 0.9854 - val_ROC-AUC: 0.9958 - val_PR-AUC: 0.9742 - val_precision: 0.9455 - val_recall: 0.9087 - val_TP: 5496.0000 - val_TN: 66211.0000 - val_FP: 317.0000 - val_FN: 552.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.4091 - categorical_accuracy: 0.8857 - top-3: 0.9783 - ROC-AUC: 0.9885 - PR-AUC: 0.9417 - precision: 0.9101 - recall: 0.8608 - TP: 7809.0000 - TN: 99021.0000 - FP: 771.0000 - FN: 1263.0000 - val_loss: 0.2895 - val_categorical_accuracy: 0.9183 - val_top-3: 0.9864 - val_ROC-AUC: 0.9935 - val_PR-AUC: 0.9675 - val_precision: 0.9321 - val_recall: 0.9062 - val_TP: 5481.0000 - val_TN: 66129.0000 - val_FP: 399.0000 - val_FN: 567.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 162s 286ms/step - loss: 0.3488 - categorical_accuracy: 0.9119 - top-3: 0.9804 - ROC-AUC: 0.9913 - PR-AUC: 0.9577 - precision: 0.9302 - recall: 0.8925 - TP: 8097.0000 - TN: 99184.0000 - FP: 608.0000 - FN: 975.0000 - val_loss: 0.2491 - val_categorical_accuracy: 0.9382 - val_top-3: 0.9863 - val_ROC-AUC: 0.9938 - val_PR-AUC: 0.9671 - val_precision: 0.9491 - val_recall: 0.9248 - val_TP: 5593.0000 - val_TN: 66228.0000 - val_FP: 300.0000 - val_FN: 455.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.2870 - categorical_accuracy: 0.9216 - top-3: 0.9830 - ROC-AUC: 0.9931 - PR-AUC: 0.9670 - precision: 0.9365 - recall: 0.9115 - TP: 8269.0000 - TN: 99231.0000 - FP: 561.0000 - FN: 803.0000 - val_loss: 0.1823 - val_categorical_accuracy: 0.9547 - val_top-3: 0.9901 - val_ROC-AUC: 0.9961 - val_PR-AUC: 0.9837 - val_precision: 0.9652 - val_recall: 0.9415 - val_TP: 5694.0000 - val_TN: 66323.0000 - val_FP: 205.0000 - val_FN: 354.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 159s 281ms/step - loss: 0.2984 - categorical_accuracy: 0.9217 - top-3: 0.9806 - ROC-AUC: 0.9921 - PR-AUC: 0.9640 - precision: 0.9401 - recall: 0.9061 - TP: 8220.0000 - TN: 99268.0000 - FP: 524.0000 - FN: 852.0000 - val_loss: 0.1720 - val_categorical_accuracy: 0.9618 - val_top-3: 0.9911 - val_ROC-AUC: 0.9960 - val_PR-AUC: 0.9832 - val_precision: 0.9682 - val_recall: 0.9529 - val_TP: 5763.0000 - val_TN: 66339.0000 - val_FP: 189.0000 - val_FN: 285.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.3154 - categorical_accuracy: 0.9194 - top-3: 0.9795 - ROC-AUC: 0.9916 - PR-AUC: 0.9624 - precision: 0.9389 - recall: 0.8997 - TP: 8162.0000 - TN: 99261.0000 - FP: 531.0000 - FN: 910.0000 - val_loss: 0.1386 - val_categorical_accuracy: 0.9659 - val_top-3: 0.9917 - val_ROC-AUC: 0.9977 - val_PR-AUC: 0.9896 - val_precision: 0.9770 - val_recall: 0.9549 - val_TP: 5775.0000 - val_TN: 66392.0000 - val_FP: 136.0000 - val_FN: 273.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 160s 281ms/step - loss: 0.3312 - categorical_accuracy: 0.9184 - top-3: 0.9800 - ROC-AUC: 0.9912 - PR-AUC: 0.9617 - precision: 0.9406 - recall: 0.8954 - TP: 8123.0000 - TN: 99279.0000 - FP: 513.0000 - FN: 949.0000 - val_loss: 0.2177 - val_categorical_accuracy: 0.9506 - val_top-3: 0.9902 - val_ROC-AUC: 0.9943 - val_PR-AUC: 0.9743 - val_precision: 0.9615 - val_recall: 0.9373 - val_TP: 5669.0000 - val_TN: 66301.0000 - val_FP: 227.0000 - val_FN: 379.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.2642 - categorical_accuracy: 0.9343 - top-3: 0.9857 - ROC-AUC: 0.9929 - PR-AUC: 0.9705 - precision: 0.9503 - recall: 0.9201 - TP: 8347.0000 - TN: 99355.0000 - FP: 437.0000 - FN: 725.0000 - val_loss: 0.0971 - val_categorical_accuracy: 0.9759 - val_top-3: 0.9942 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9934 - val_precision: 0.9829 - val_recall: 0.9712 - val_TP: 5874.0000 - val_TN: 66426.0000 - val_FP: 102.0000 - val_FN: 174.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 160s 281ms/step - loss: 0.2109 - categorical_accuracy: 0.9490 - top-3: 0.9863 - ROC-AUC: 0.9942 - PR-AUC: 0.9793 - precision: 0.9610 - recall: 0.9374 - TP: 8504.0000 - TN: 99447.0000 - FP: 345.0000 - FN: 568.0000 - val_loss: 0.2235 - val_categorical_accuracy: 0.9469 - val_top-3: 0.9863 - val_ROC-AUC: 0.9943 - val_PR-AUC: 0.9777 - val_precision: 0.9553 - val_recall: 0.9372 - val_TP: 5668.0000 - val_TN: 66263.0000 - val_FP: 265.0000 - val_FN: 380.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.2550 - categorical_accuracy: 0.9311 - top-3: 0.9848 - ROC-AUC: 0.9939 - PR-AUC: 0.9730 - precision: 0.9472 - recall: 0.9153 - TP: 8304.0000 - TN: 99329.0000 - FP: 463.0000 - FN: 768.0000 - val_loss: 0.1805 - val_categorical_accuracy: 0.9537 - val_top-3: 0.9927 - val_ROC-AUC: 0.9964 - val_PR-AUC: 0.9832 - val_precision: 0.9614 - val_recall: 0.9482 - val_TP: 5735.0000 - val_TN: 66298.0000 - val_FP: 230.0000 - val_FN: 313.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.2102 - categorical_accuracy: 0.9446 - top-3: 0.9878 - ROC-AUC: 0.9949 - PR-AUC: 0.9790 - precision: 0.9575 - recall: 0.9343 - TP: 8476.0000 - TN: 99416.0000 - FP: 376.0000 - FN: 596.0000 - val_loss: 0.1052 - val_categorical_accuracy: 0.9778 - val_top-3: 0.9945 - val_ROC-AUC: 0.9976 - val_PR-AUC: 0.9920 - val_precision: 0.9817 - val_recall: 0.9745 - val_TP: 5894.0000 - val_TN: 66418.0000 - val_FP: 110.0000 - val_FN: 154.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.2613 - categorical_accuracy: 0.9353 - top-3: 0.9834 - ROC-AUC: 0.9930 - PR-AUC: 0.9721 - precision: 0.9515 - recall: 0.9209 - TP: 8354.0000 - TN: 99366.0000 - FP: 426.0000 - FN: 718.0000 - val_loss: 0.2133 - val_categorical_accuracy: 0.9545 - val_top-3: 0.9821 - val_ROC-AUC: 0.9934 - val_PR-AUC: 0.9781 - val_precision: 0.9673 - val_recall: 0.9449 - val_TP: 5715.0000 - val_TN: 66335.0000 - val_FP: 193.0000 - val_FN: 333.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.2599 - categorical_accuracy: 0.9356 - top-3: 0.9829 - ROC-AUC: 0.9935 - PR-AUC: 0.9724 - precision: 0.9535 - recall: 0.9177 - TP: 8325.0000 - TN: 99386.0000 - FP: 406.0000 - FN: 747.0000 - val_loss: 0.2684 - val_categorical_accuracy: 0.9413 - val_top-3: 0.9833 - val_ROC-AUC: 0.9899 - val_PR-AUC: 0.9644 - val_precision: 0.9479 - val_recall: 0.9352 - val_TP: 5656.0000 - val_TN: 66217.0000 - val_FP: 311.0000 - val_FN: 392.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 160s 283ms/step - loss: 0.2268 - categorical_accuracy: 0.9414 - top-3: 0.9881 - ROC-AUC: 0.9942 - PR-AUC: 0.9771 - precision: 0.9554 - recall: 0.9276 - TP: 8415.0000 - TN: 99399.0000 - FP: 393.0000 - FN: 657.0000 - val_loss: 0.1827 - val_categorical_accuracy: 0.9580 - val_top-3: 0.9879 - val_ROC-AUC: 0.9956 - val_PR-AUC: 0.9828 - val_precision: 0.9666 - val_recall: 0.9482 - val_TP: 5735.0000 - val_TN: 66330.0000 - val_FP: 198.0000 - val_FN: 313.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.2138 - categorical_accuracy: 0.9432 - top-3: 0.9864 - ROC-AUC: 0.9947 - PR-AUC: 0.9789 - precision: 0.9610 - recall: 0.9293 - TP: 8431.0000 - TN: 99450.0000 - FP: 342.0000 - FN: 641.0000 - val_loss: 0.1410 - val_categorical_accuracy: 0.9717 - val_top-3: 0.9909 - val_ROC-AUC: 0.9968 - val_PR-AUC: 0.9884 - val_precision: 0.9773 - val_recall: 0.9678 - val_TP: 5853.0000 - val_TN: 66392.0000 - val_FP: 136.0000 - val_FN: 195.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.2358 - categorical_accuracy: 0.9424 - top-3: 0.9857 - ROC-AUC: 0.9939 - PR-AUC: 0.9759 - precision: 0.9544 - recall: 0.9298 - TP: 8435.0000 - TN: 99389.0000 - FP: 403.0000 - FN: 637.0000 - val_loss: 0.1012 - val_categorical_accuracy: 0.9783 - val_top-3: 0.9947 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9943 - val_precision: 0.9821 - val_recall: 0.9726 - val_TP: 5882.0000 - val_TN: 66421.0000 - val_FP: 107.0000 - val_FN: 166.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 160s 283ms/step - loss: 0.1886 - categorical_accuracy: 0.9592 - top-3: 0.9896 - ROC-AUC: 0.9958 - PR-AUC: 0.9835 - precision: 0.9685 - recall: 0.9508 - TP: 8626.0000 - TN: 99511.0000 - FP: 281.0000 - FN: 446.0000 - val_loss: 0.0794 - val_categorical_accuracy: 0.9813 - val_top-3: 0.9949 - val_ROC-AUC: 0.9979 - val_PR-AUC: 0.9936 - val_precision: 0.9852 - val_recall: 0.9800 - val_TP: 5927.0000 - val_TN: 66439.0000 - val_FP: 89.0000 - val_FN: 121.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.1884 - categorical_accuracy: 0.9540 - top-3: 0.9873 - ROC-AUC: 0.9947 - PR-AUC: 0.9818 - precision: 0.9651 - recall: 0.9461 - TP: 8583.0000 - TN: 99482.0000 - FP: 310.0000 - FN: 489.0000 - val_loss: 0.1852 - val_categorical_accuracy: 0.9517 - val_top-3: 0.9907 - val_ROC-AUC: 0.9956 - val_PR-AUC: 0.9831 - val_precision: 0.9681 - val_recall: 0.9439 - val_TP: 5709.0000 - val_TN: 66340.0000 - val_FP: 188.0000 - val_FN: 339.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.2143 - categorical_accuracy: 0.9508 - top-3: 0.9867 - ROC-AUC: 0.9946 - PR-AUC: 0.9797 - precision: 0.9627 - recall: 0.9379 - TP: 8509.0000 - TN: 99462.0000 - FP: 330.0000 - FN: 563.0000 - val_loss: 0.1366 - val_categorical_accuracy: 0.9683 - val_top-3: 0.9934 - val_ROC-AUC: 0.9973 - val_PR-AUC: 0.9892 - val_precision: 0.9767 - val_recall: 0.9562 - val_TP: 5783.0000 - val_TN: 66390.0000 - val_FP: 138.0000 - val_FN: 265.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 160s 282ms/step - loss: 0.1648 - categorical_accuracy: 0.9611 - top-3: 0.9921 - ROC-AUC: 0.9960 - PR-AUC: 0.9858 - precision: 0.9699 - recall: 0.9535 - TP: 8650.0000 - TN: 99524.0000 - FP: 268.0000 - FN: 422.0000 - val_loss: 0.0844 - val_categorical_accuracy: 0.9812 - val_top-3: 0.9950 - val_ROC-AUC: 0.9970 - val_PR-AUC: 0.9924 - val_precision: 0.9839 - val_recall: 0.9793 - val_TP: 5923.0000 - val_TN: 66431.0000 - val_FP: 97.0000 - val_FN: 125.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.1711 - categorical_accuracy: 0.9621 - top-3: 0.9900 - ROC-AUC: 0.9961 - PR-AUC: 0.9861 - precision: 0.9705 - recall: 0.9545 - TP: 8659.0000 - TN: 99529.0000 - FP: 263.0000 - FN: 413.0000 - val_loss: 0.2706 - val_categorical_accuracy: 0.9102 - val_top-3: 0.9802 - val_ROC-AUC: 0.9928 - val_PR-AUC: 0.9730 - val_precision: 0.9580 - val_recall: 0.8872 - val_TP: 5366.0000 - val_TN: 66293.0000 - val_FP: 235.0000 - val_FN: 682.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 162s 286ms/step - loss: 0.1718 - categorical_accuracy: 0.9633 - top-3: 0.9906 - ROC-AUC: 0.9957 - PR-AUC: 0.9846 - precision: 0.9737 - recall: 0.9546 - TP: 8660.0000 - TN: 99558.0000 - FP: 234.0000 - FN: 412.0000 - val_loss: 0.0968 - val_categorical_accuracy: 0.9775 - val_top-3: 0.9940 - val_ROC-AUC: 0.9969 - val_PR-AUC: 0.9922 - val_precision: 0.9811 - val_recall: 0.9764 - val_TP: 5905.0000 - val_TN: 66414.0000 - val_FP: 114.0000 - val_FN: 143.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 161s 283ms/step - loss: 0.2187 - categorical_accuracy: 0.9490 - top-3: 0.9874 - ROC-AUC: 0.9944 - PR-AUC: 0.9782 - precision: 0.9634 - recall: 0.9344 - TP: 8477.0000 - TN: 99470.0000 - FP: 322.0000 - FN: 595.0000 - val_loss: 0.0961 - val_categorical_accuracy: 0.9767 - val_top-3: 0.9940 - val_ROC-AUC: 0.9978 - val_PR-AUC: 0.9928 - val_precision: 0.9810 - val_recall: 0.9729 - val_TP: 5884.0000 - val_TN: 66414.0000 - val_FP: 114.0000 - val_FN: 164.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.1730 - categorical_accuracy: 0.9633 - top-3: 0.9890 - ROC-AUC: 0.9955 - PR-AUC: 0.9847 - precision: 0.9717 - recall: 0.9552 - TP: 8666.0000 - TN: 99540.0000 - FP: 252.0000 - FN: 406.0000 - val_loss: 0.1027 - val_categorical_accuracy: 0.9815 - val_top-3: 0.9939 - val_ROC-AUC: 0.9979 - val_PR-AUC: 0.9935 - val_precision: 0.9863 - val_recall: 0.9790 - val_TP: 5921.0000 - val_TN: 66446.0000 - val_FP: 82.0000 - val_FN: 127.0000\n",
      "-----\n",
      "(8078295.16 ms) == (134m:38s)\n",
      "-----\n",
      "\n",
      "\n",
      "36\n",
      "['mobilenetv2_1.00_64-16-fc12.tensorboard',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.001_0.2814_1.7152.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.002_0.3750_1.5874.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.003_0.3633_1.5405.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.004_0.5362_1.1417.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.006_0.6035_1.0061.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.008_0.6159_1.0210.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.009_0.6655_0.8552.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.010_0.6645_0.8396.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.011_0.7077_0.7698.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.012_0.7318_0.7331.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.013_0.7703_0.6360.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.015_0.8216_0.5611.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.020_0.7874_0.5546.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.022_0.8578_0.4418.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.025_0.8912_0.3838.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.026_0.9315_0.2475.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.029_0.9382_0.2491.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.030_0.9547_0.1823.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.031_0.9618_0.1720.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.032_0.9659_0.1386.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.034_0.9759_0.0971.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.037_0.9778_0.1052.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.042_0.9783_0.1012.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.043_0.9813_0.0794.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.050.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-fc12.weights.050_0.9815_0.1027.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_64-16-fc12.csv',\n",
      " 'model.mobilenetv2_1.00_64-16-fc12.h5',\n",
      " 'weights.mobilenetv2_1.00_64-16-fc12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_64-16-fc12\n",
    "model_15 = consecutiveModelTraining(\n",
    "    input_size=64,\n",
    "    batch_size=16,\n",
    "    weights=None,\n",
    "    dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a610316-e3af-4b30-9637-caea18bd97ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-11T08:48:24.481407Z",
     "iopub.status.busy": "2021-06-11T08:48:24.481407Z",
     "iopub.status.idle": "2021-06-11T08:48:24.560409Z",
     "shell.execute_reply": "2021-06-11T08:48:24.559413Z",
     "shell.execute_reply.started": "2021-06-11T08:48:24.481407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.655971</td>\n",
       "      <td>0.774718</td>\n",
       "      <td>0.923587</td>\n",
       "      <td>0.965719</td>\n",
       "      <td>0.838849</td>\n",
       "      <td>0.870819</td>\n",
       "      <td>0.697650</td>\n",
       "      <td>6329.080000</td>\n",
       "      <td>99140.880000</td>\n",
       "      <td>651.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814471</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.976675</td>\n",
       "      <td>0.874721</td>\n",
       "      <td>0.906945</td>\n",
       "      <td>0.732431</td>\n",
       "      <td>4429.740000</td>\n",
       "      <td>66214.300000</td>\n",
       "      <td>313.700000</td>\n",
       "      <td>1618.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488612</td>\n",
       "      <td>0.200908</td>\n",
       "      <td>0.096756</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>0.117509</td>\n",
       "      <td>0.268375</td>\n",
       "      <td>2434.697952</td>\n",
       "      <td>281.141524</td>\n",
       "      <td>281.141524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182952</td>\n",
       "      <td>0.067178</td>\n",
       "      <td>0.031439</td>\n",
       "      <td>0.163107</td>\n",
       "      <td>0.097515</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>1638.118094</td>\n",
       "      <td>179.322677</td>\n",
       "      <td>179.322677</td>\n",
       "      <td>1638.118094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.164832</td>\n",
       "      <td>0.174052</td>\n",
       "      <td>0.465388</td>\n",
       "      <td>0.725611</td>\n",
       "      <td>0.191849</td>\n",
       "      <td>0.452685</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>98628.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281415</td>\n",
       "      <td>0.708829</td>\n",
       "      <td>0.858215</td>\n",
       "      <td>0.320128</td>\n",
       "      <td>0.463389</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>65790.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.240575</td>\n",
       "      <td>0.684579</td>\n",
       "      <td>0.900243</td>\n",
       "      <td>0.958960</td>\n",
       "      <td>0.784879</td>\n",
       "      <td>0.842950</td>\n",
       "      <td>0.560185</td>\n",
       "      <td>5082.000000</td>\n",
       "      <td>98887.500000</td>\n",
       "      <td>395.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721850</td>\n",
       "      <td>0.925678</td>\n",
       "      <td>0.969470</td>\n",
       "      <td>0.816543</td>\n",
       "      <td>0.881195</td>\n",
       "      <td>0.553075</td>\n",
       "      <td>3345.000000</td>\n",
       "      <td>66086.750000</td>\n",
       "      <td>150.500000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.519272</td>\n",
       "      <td>0.846836</td>\n",
       "      <td>0.963073</td>\n",
       "      <td>0.984260</td>\n",
       "      <td>0.917491</td>\n",
       "      <td>0.895508</td>\n",
       "      <td>0.801201</td>\n",
       "      <td>7268.500000</td>\n",
       "      <td>99065.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900711</td>\n",
       "      <td>0.976604</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.957694</td>\n",
       "      <td>0.929022</td>\n",
       "      <td>0.873512</td>\n",
       "      <td>5283.000000</td>\n",
       "      <td>66217.500000</td>\n",
       "      <td>310.500000</td>\n",
       "      <td>765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.934500</td>\n",
       "      <td>0.939925</td>\n",
       "      <td>0.985670</td>\n",
       "      <td>0.993855</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.954176</td>\n",
       "      <td>0.925898</td>\n",
       "      <td>8399.750000</td>\n",
       "      <td>99396.500000</td>\n",
       "      <td>904.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957176</td>\n",
       "      <td>0.990865</td>\n",
       "      <td>0.996108</td>\n",
       "      <td>0.983194</td>\n",
       "      <td>0.967923</td>\n",
       "      <td>0.948247</td>\n",
       "      <td>5735.000000</td>\n",
       "      <td>66377.500000</td>\n",
       "      <td>441.250000</td>\n",
       "      <td>2703.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.208457</td>\n",
       "      <td>0.963294</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.996089</td>\n",
       "      <td>0.986136</td>\n",
       "      <td>0.973690</td>\n",
       "      <td>0.955247</td>\n",
       "      <td>8666.000000</td>\n",
       "      <td>99578.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.995040</td>\n",
       "      <td>0.998622</td>\n",
       "      <td>0.994265</td>\n",
       "      <td>0.986340</td>\n",
       "      <td>0.979993</td>\n",
       "      <td>5927.000000</td>\n",
       "      <td>66481.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>5982.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.655971              0.774718   0.923587   0.965719   0.838849   \n",
       "std     0.488612              0.200908   0.096756   0.048062   0.188383   \n",
       "min     0.164832              0.174052   0.465388   0.725611   0.191849   \n",
       "25%     0.240575              0.684579   0.900243   0.958960   0.784879   \n",
       "50%     0.519272              0.846836   0.963073   0.984260   0.917491   \n",
       "75%     0.934500              0.939925   0.985670   0.993855   0.975178   \n",
       "max     2.208457              0.963294   0.992063   0.996089   0.986136   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.870819   0.697650  6329.080000  99140.880000   651.120000  ...   \n",
       "std     0.117509   0.268375  2434.697952    281.141524   281.141524  ...   \n",
       "min     0.452685   0.019511   177.000000  98628.000000   214.000000  ...   \n",
       "25%     0.842950   0.560185  5082.000000  98887.500000   395.500000  ...   \n",
       "50%     0.895508   0.801201  7268.500000  99065.000000   727.000000  ...   \n",
       "75%     0.954176   0.925898  8399.750000  99396.500000   904.500000  ...   \n",
       "max     0.973690   0.955247  8666.000000  99578.000000  1164.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.814471   0.946300     0.976675    0.874721   \n",
       "std                    0.182952   0.067178     0.031439    0.163107   \n",
       "min                    0.281415   0.708829     0.858215    0.320128   \n",
       "25%                    0.721850   0.925678     0.969470    0.816543   \n",
       "50%                    0.900711   0.976604     0.990333    0.957694   \n",
       "75%                    0.957176   0.990865     0.996108    0.983194   \n",
       "max                    0.981481   0.995040     0.998622    0.994265   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.906945    0.732431  4429.740000  66214.300000  313.700000   \n",
       "std         0.097515    0.270853  1638.118094    179.322677  179.322677   \n",
       "min         0.463389    0.010913    66.000000  65790.000000   47.000000   \n",
       "25%         0.881195    0.553075  3345.000000  66086.750000  150.500000   \n",
       "50%         0.929022    0.873512  5283.000000  66217.500000  310.500000   \n",
       "75%         0.967923    0.948247  5735.000000  66377.500000  441.250000   \n",
       "max         0.986340    0.979993  5927.000000  66481.000000  738.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean   1618.260000  \n",
       "std    1638.118094  \n",
       "min     121.000000  \n",
       "25%     313.000000  \n",
       "50%     765.000000  \n",
       "75%    2703.000000  \n",
       "max    5982.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_15['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b317364-ba50-4afc-bb78-813a12f2dbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dd203-e647-4efa-9d03-c14686d8810d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f2565-7c02-4ab8-9239-bca045abe15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43635674-34a1-4275-b426-eb52d23e6e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab3ec8-1feb-4110-a138-a8a69b1e4061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d15dc54-dca4-4915-9e33-a8b16eb8525f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T15:45:22.368217Z",
     "iopub.status.busy": "2021-06-10T15:45:22.368217Z",
     "iopub.status.idle": "2021-06-10T18:29:24.411550Z",
     "shell.execute_reply": "2021-06-10T18:29:24.410551Z",
     "shell.execute_reply.started": "2021-06-10T15:45:22.368217Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_128-imagenet128-16-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_128-imagenet128-16-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_128 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 15,372\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_128-imagenet128-16-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_128-imagenet128-16-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_128-imagenet128-16-12\n",
      "Epoch 1/50\n",
      "  1/567 [..............................] - ETA: 2s - loss: 3.1964 - categorical_accuracy: 0.0625 - top-3: 0.1875 - ROC-AUC: 0.4698 - PR-AUC: 0.0770 - precision: 0.0000e+00 - recall: 0.0000e+00 - TP: 0.0000e+00 - TN: 175.0000 - FP: 1.0000 - FN: 16.0000WARNING:tensorflow:From X:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From X:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/567 [..............................] - ETA: 3:09 - loss: 2.6868 - categorical_accuracy: 0.2500 - top-3: 0.4062 - ROC-AUC: 0.6475 - PR-AUC: 0.2021 - precision: 0.4545 - recall: 0.1562 - TP: 5.0000 - TN: 346.0000 - FP: 6.0000 - FN: 27.0000          WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2160s vs `on_train_batch_end` time: 0.4470s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2160s vs `on_train_batch_end` time: 0.4470s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/567 [==============================] - 204s 359ms/step - loss: 0.2954 - categorical_accuracy: 0.9106 - top-3: 0.9778 - ROC-AUC: 0.9919 - PR-AUC: 0.9667 - precision: 0.9307 - recall: 0.8983 - TP: 8149.0000 - TN: 99185.0000 - FP: 607.0000 - FN: 923.0000 - val_loss: 0.0845 - val_categorical_accuracy: 0.9744 - val_top-3: 0.9985 - val_ROC-AUC: 0.9984 - val_PR-AUC: 0.9942 - val_precision: 0.9761 - val_recall: 0.9735 - val_TP: 5888.0000 - val_TN: 66384.0000 - val_FP: 144.0000 - val_FN: 160.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 199s 350ms/step - loss: 0.1914 - categorical_accuracy: 0.9509 - top-3: 0.9955 - ROC-AUC: 0.9943 - PR-AUC: 0.9807 - precision: 0.9535 - recall: 0.9490 - TP: 8609.0000 - TN: 99372.0000 - FP: 420.0000 - FN: 463.0000 - val_loss: 0.0477 - val_categorical_accuracy: 0.9864 - val_top-3: 0.9995 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9960 - val_precision: 0.9866 - val_recall: 0.9861 - val_TP: 5964.0000 - val_TN: 66447.0000 - val_FP: 81.0000 - val_FN: 84.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1457 - categorical_accuracy: 0.9676 - top-3: 0.9976 - ROC-AUC: 0.9948 - PR-AUC: 0.9844 - precision: 0.9694 - recall: 0.9667 - TP: 8770.0000 - TN: 99515.0000 - FP: 277.0000 - FN: 302.0000 - val_loss: 0.0306 - val_categorical_accuracy: 0.9924 - val_top-3: 0.9998 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9970 - val_precision: 0.9926 - val_recall: 0.9919 - val_TP: 5999.0000 - val_TN: 66483.0000 - val_FP: 45.0000 - val_FN: 49.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.1299 - categorical_accuracy: 0.9719 - top-3: 0.9981 - ROC-AUC: 0.9950 - PR-AUC: 0.9851 - precision: 0.9735 - recall: 0.9716 - TP: 8814.0000 - TN: 99552.0000 - FP: 240.0000 - FN: 258.0000 - val_loss: 0.0435 - val_categorical_accuracy: 0.9912 - val_top-3: 0.9993 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9953 - val_precision: 0.9914 - val_recall: 0.9911 - val_TP: 5994.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 54.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1669 - categorical_accuracy: 0.9696 - top-3: 0.9976 - ROC-AUC: 0.9939 - PR-AUC: 0.9810 - precision: 0.9702 - recall: 0.9690 - TP: 8791.0000 - TN: 99522.0000 - FP: 270.0000 - FN: 281.0000 - val_loss: 0.0438 - val_categorical_accuracy: 0.9897 - val_top-3: 0.9998 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9954 - val_precision: 0.9897 - val_recall: 0.9897 - val_TP: 5986.0000 - val_TN: 66466.0000 - val_FP: 62.0000 - val_FN: 62.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1748 - categorical_accuracy: 0.9686 - top-3: 0.9977 - ROC-AUC: 0.9938 - PR-AUC: 0.9809 - precision: 0.9689 - recall: 0.9684 - TP: 8785.0000 - TN: 99510.0000 - FP: 282.0000 - FN: 287.0000 - val_loss: 0.0290 - val_categorical_accuracy: 0.9950 - val_top-3: 1.0000 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9969 - val_precision: 0.9950 - val_recall: 0.9950 - val_TP: 6018.0000 - val_TN: 66498.0000 - val_FP: 30.0000 - val_FN: 30.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.1374 - categorical_accuracy: 0.9730 - top-3: 0.9985 - ROC-AUC: 0.9949 - PR-AUC: 0.9843 - precision: 0.9732 - recall: 0.9728 - TP: 8825.0000 - TN: 99549.0000 - FP: 243.0000 - FN: 247.0000 - val_loss: 0.0852 - val_categorical_accuracy: 0.9854 - val_top-3: 0.9993 - val_ROC-AUC: 0.9971 - val_PR-AUC: 0.9908 - val_precision: 0.9854 - val_recall: 0.9854 - val_TP: 5960.0000 - val_TN: 66440.0000 - val_FP: 88.0000 - val_FN: 88.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1227 - categorical_accuracy: 0.9794 - top-3: 0.9988 - ROC-AUC: 0.9955 - PR-AUC: 0.9858 - precision: 0.9795 - recall: 0.9792 - TP: 8883.0000 - TN: 99606.0000 - FP: 186.0000 - FN: 189.0000 - val_loss: 0.0787 - val_categorical_accuracy: 0.9856 - val_top-3: 0.9997 - val_ROC-AUC: 0.9971 - val_PR-AUC: 0.9910 - val_precision: 0.9858 - val_recall: 0.9856 - val_TP: 5961.0000 - val_TN: 66442.0000 - val_FP: 86.0000 - val_FN: 87.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.1294 - categorical_accuracy: 0.9792 - top-3: 0.9989 - ROC-AUC: 0.9948 - PR-AUC: 0.9846 - precision: 0.9796 - recall: 0.9791 - TP: 8882.0000 - TN: 99607.0000 - FP: 185.0000 - FN: 190.0000 - val_loss: 0.0734 - val_categorical_accuracy: 0.9868 - val_top-3: 0.9983 - val_ROC-AUC: 0.9974 - val_PR-AUC: 0.9922 - val_precision: 0.9869 - val_recall: 0.9868 - val_TP: 5968.0000 - val_TN: 66449.0000 - val_FP: 79.0000 - val_FN: 80.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1473 - categorical_accuracy: 0.9767 - top-3: 0.9988 - ROC-AUC: 0.9946 - PR-AUC: 0.9831 - precision: 0.9770 - recall: 0.9766 - TP: 8860.0000 - TN: 99583.0000 - FP: 209.0000 - FN: 212.0000 - val_loss: 0.0649 - val_categorical_accuracy: 0.9896 - val_top-3: 0.9998 - val_ROC-AUC: 0.9979 - val_PR-AUC: 0.9932 - val_precision: 0.9897 - val_recall: 0.9896 - val_TP: 5985.0000 - val_TN: 66466.0000 - val_FP: 62.0000 - val_FN: 63.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 197s 348ms/step - loss: 0.1007 - categorical_accuracy: 0.9837 - top-3: 0.9992 - ROC-AUC: 0.9960 - PR-AUC: 0.9873 - precision: 0.9839 - recall: 0.9837 - TP: 8924.0000 - TN: 99646.0000 - FP: 146.0000 - FN: 148.0000 - val_loss: 0.0250 - val_categorical_accuracy: 0.9950 - val_top-3: 1.0000 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9969 - val_precision: 0.9950 - val_recall: 0.9950 - val_TP: 6018.0000 - val_TN: 66498.0000 - val_FP: 30.0000 - val_FN: 30.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1407 - categorical_accuracy: 0.9791 - top-3: 0.9993 - ROC-AUC: 0.9947 - PR-AUC: 0.9834 - precision: 0.9792 - recall: 0.9791 - TP: 8882.0000 - TN: 99603.0000 - FP: 189.0000 - FN: 190.0000 - val_loss: 0.0419 - val_categorical_accuracy: 0.9939 - val_top-3: 0.9993 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9956 - val_precision: 0.9939 - val_recall: 0.9939 - val_TP: 6011.0000 - val_TN: 66491.0000 - val_FP: 37.0000 - val_FN: 37.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.1583 - categorical_accuracy: 0.9808 - top-3: 0.9990 - ROC-AUC: 0.9943 - PR-AUC: 0.9818 - precision: 0.9808 - recall: 0.9808 - TP: 8898.0000 - TN: 99618.0000 - FP: 174.0000 - FN: 174.0000 - val_loss: 0.0405 - val_categorical_accuracy: 0.9942 - val_top-3: 1.0000 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9951 - val_precision: 0.9942 - val_recall: 0.9942 - val_TP: 6013.0000 - val_TN: 66493.0000 - val_FP: 35.0000 - val_FN: 35.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1610 - categorical_accuracy: 0.9806 - top-3: 0.9990 - ROC-AUC: 0.9947 - PR-AUC: 0.9841 - precision: 0.9806 - recall: 0.9806 - TP: 8896.0000 - TN: 99616.0000 - FP: 176.0000 - FN: 176.0000 - val_loss: 0.0499 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9993 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9954 - val_precision: 0.9927 - val_recall: 0.9927 - val_TP: 6004.0000 - val_TN: 66484.0000 - val_FP: 44.0000 - val_FN: 44.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1424 - categorical_accuracy: 0.9835 - top-3: 0.9989 - ROC-AUC: 0.9948 - PR-AUC: 0.9839 - precision: 0.9836 - recall: 0.9835 - TP: 8922.0000 - TN: 99643.0000 - FP: 149.0000 - FN: 150.0000 - val_loss: 0.0407 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9997 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9950 - val_precision: 0.9949 - val_recall: 0.9945 - val_TP: 6015.0000 - val_TN: 66497.0000 - val_FP: 31.0000 - val_FN: 33.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1333 - categorical_accuracy: 0.9825 - top-3: 0.9989 - ROC-AUC: 0.9959 - PR-AUC: 0.9871 - precision: 0.9827 - recall: 0.9824 - TP: 8912.0000 - TN: 99635.0000 - FP: 157.0000 - FN: 160.0000 - val_loss: 0.0424 - val_categorical_accuracy: 0.9945 - val_top-3: 1.0000 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9938 - val_precision: 0.9945 - val_recall: 0.9945 - val_TP: 6015.0000 - val_TN: 66495.0000 - val_FP: 33.0000 - val_FN: 33.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.1343 - categorical_accuracy: 0.9839 - top-3: 0.9993 - ROC-AUC: 0.9952 - PR-AUC: 0.9852 - precision: 0.9839 - recall: 0.9839 - TP: 8926.0000 - TN: 99646.0000 - FP: 146.0000 - FN: 146.0000 - val_loss: 0.0464 - val_categorical_accuracy: 0.9944 - val_top-3: 0.9998 - val_ROC-AUC: 0.9983 - val_PR-AUC: 0.9946 - val_precision: 0.9944 - val_recall: 0.9944 - val_TP: 6014.0000 - val_TN: 66494.0000 - val_FP: 34.0000 - val_FN: 34.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 198s 350ms/step - loss: 0.1447 - categorical_accuracy: 0.9815 - top-3: 0.9988 - ROC-AUC: 0.9951 - PR-AUC: 0.9846 - precision: 0.9817 - recall: 0.9815 - TP: 8904.0000 - TN: 99626.0000 - FP: 166.0000 - FN: 168.0000 - val_loss: 0.0354 - val_categorical_accuracy: 0.9959 - val_top-3: 0.9998 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9974 - val_precision: 0.9959 - val_recall: 0.9959 - val_TP: 6023.0000 - val_TN: 66503.0000 - val_FP: 25.0000 - val_FN: 25.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 201s 354ms/step - loss: 0.1186 - categorical_accuracy: 0.9845 - top-3: 0.9996 - ROC-AUC: 0.9954 - PR-AUC: 0.9855 - precision: 0.9845 - recall: 0.9845 - TP: 8931.0000 - TN: 99651.0000 - FP: 141.0000 - FN: 141.0000 - val_loss: 0.0203 - val_categorical_accuracy: 0.9964 - val_top-3: 0.9998 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9974 - val_precision: 0.9964 - val_recall: 0.9964 - val_TP: 6026.0000 - val_TN: 66506.0000 - val_FP: 22.0000 - val_FN: 22.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 198s 349ms/step - loss: 0.1221 - categorical_accuracy: 0.9857 - top-3: 0.9993 - ROC-AUC: 0.9955 - PR-AUC: 0.9856 - precision: 0.9858 - recall: 0.9857 - TP: 8942.0000 - TN: 99663.0000 - FP: 129.0000 - FN: 130.0000 - val_loss: 0.0301 - val_categorical_accuracy: 0.9962 - val_top-3: 1.0000 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9959 - val_precision: 0.9962 - val_recall: 0.9962 - val_TP: 6025.0000 - val_TN: 66505.0000 - val_FP: 23.0000 - val_FN: 23.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1226 - categorical_accuracy: 0.9848 - top-3: 0.9998 - ROC-AUC: 0.9960 - PR-AUC: 0.9869 - precision: 0.9848 - recall: 0.9848 - TP: 8934.0000 - TN: 99654.0000 - FP: 138.0000 - FN: 138.0000 - val_loss: 0.0319 - val_categorical_accuracy: 0.9957 - val_top-3: 1.0000 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9965 - val_precision: 0.9957 - val_recall: 0.9957 - val_TP: 6022.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 26.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.1106 - categorical_accuracy: 0.9882 - top-3: 0.9996 - ROC-AUC: 0.9967 - PR-AUC: 0.9894 - precision: 0.9883 - recall: 0.9882 - TP: 8965.0000 - TN: 99686.0000 - FP: 106.0000 - FN: 107.0000 - val_loss: 0.0823 - val_categorical_accuracy: 0.9909 - val_top-3: 0.9998 - val_ROC-AUC: 0.9972 - val_PR-AUC: 0.9908 - val_precision: 0.9909 - val_recall: 0.9909 - val_TP: 5993.0000 - val_TN: 66473.0000 - val_FP: 55.0000 - val_FN: 55.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1115 - categorical_accuracy: 0.9869 - top-3: 0.9997 - ROC-AUC: 0.9956 - PR-AUC: 0.9862 - precision: 0.9870 - recall: 0.9869 - TP: 8953.0000 - TN: 99674.0000 - FP: 118.0000 - FN: 119.0000 - val_loss: 0.0449 - val_categorical_accuracy: 0.9939 - val_top-3: 1.0000 - val_ROC-AUC: 0.9983 - val_PR-AUC: 0.9949 - val_precision: 0.9939 - val_recall: 0.9939 - val_TP: 6011.0000 - val_TN: 66491.0000 - val_FP: 37.0000 - val_FN: 37.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 199s 350ms/step - loss: 0.1229 - categorical_accuracy: 0.9856 - top-3: 0.9994 - ROC-AUC: 0.9963 - PR-AUC: 0.9885 - precision: 0.9856 - recall: 0.9854 - TP: 8940.0000 - TN: 99661.0000 - FP: 131.0000 - FN: 132.0000 - val_loss: 0.0152 - val_categorical_accuracy: 0.9983 - val_top-3: 0.9997 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9979 - val_precision: 0.9983 - val_recall: 0.9983 - val_TP: 6038.0000 - val_TN: 66518.0000 - val_FP: 10.0000 - val_FN: 10.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1123 - categorical_accuracy: 0.9864 - top-3: 0.9991 - ROC-AUC: 0.9961 - PR-AUC: 0.9878 - precision: 0.9864 - recall: 0.9863 - TP: 8948.0000 - TN: 99669.0000 - FP: 123.0000 - FN: 124.0000 - val_loss: 0.0196 - val_categorical_accuracy: 0.9975 - val_top-3: 0.9998 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9979 - val_precision: 0.9975 - val_recall: 0.9975 - val_TP: 6033.0000 - val_TN: 66513.0000 - val_FP: 15.0000 - val_FN: 15.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.1450 - categorical_accuracy: 0.9838 - top-3: 0.9991 - ROC-AUC: 0.9949 - PR-AUC: 0.9846 - precision: 0.9838 - recall: 0.9838 - TP: 8925.0000 - TN: 99645.0000 - FP: 147.0000 - FN: 147.0000 - val_loss: 0.0076 - val_categorical_accuracy: 0.9985 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9985 - val_recall: 0.9985 - val_TP: 6039.0000 - val_TN: 66519.0000 - val_FP: 9.0000 - val_FN: 9.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 198s 350ms/step - loss: 0.1151 - categorical_accuracy: 0.9850 - top-3: 0.9999 - ROC-AUC: 0.9954 - PR-AUC: 0.9855 - precision: 0.9850 - recall: 0.9850 - TP: 8936.0000 - TN: 99656.0000 - FP: 136.0000 - FN: 136.0000 - val_loss: 0.0143 - val_categorical_accuracy: 0.9979 - val_top-3: 1.0000 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9982 - val_precision: 0.9979 - val_recall: 0.9979 - val_TP: 6035.0000 - val_TN: 66515.0000 - val_FP: 13.0000 - val_FN: 13.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.1024 - categorical_accuracy: 0.9880 - top-3: 0.9997 - ROC-AUC: 0.9965 - PR-AUC: 0.9889 - precision: 0.9880 - recall: 0.9880 - TP: 8963.0000 - TN: 99683.0000 - FP: 109.0000 - FN: 109.0000 - val_loss: 0.0232 - val_categorical_accuracy: 0.9979 - val_top-3: 1.0000 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9974 - val_precision: 0.9979 - val_recall: 0.9979 - val_TP: 6035.0000 - val_TN: 66515.0000 - val_FP: 13.0000 - val_FN: 13.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1205 - categorical_accuracy: 0.9870 - top-3: 0.9994 - ROC-AUC: 0.9960 - PR-AUC: 0.9876 - precision: 0.9870 - recall: 0.9870 - TP: 8954.0000 - TN: 99674.0000 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.0179 - val_categorical_accuracy: 0.9977 - val_top-3: 0.9998 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9978 - val_precision: 0.9977 - val_recall: 0.9977 - val_TP: 6034.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 14.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 199s 351ms/step - loss: 0.0790 - categorical_accuracy: 0.9888 - top-3: 0.9996 - ROC-AUC: 0.9971 - PR-AUC: 0.9906 - precision: 0.9888 - recall: 0.9888 - TP: 8970.0000 - TN: 99690.0000 - FP: 102.0000 - FN: 102.0000 - val_loss: 0.0203 - val_categorical_accuracy: 0.9979 - val_top-3: 1.0000 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9975 - val_precision: 0.9979 - val_recall: 0.9979 - val_TP: 6035.0000 - val_TN: 66515.0000 - val_FP: 13.0000 - val_FN: 13.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.0889 - categorical_accuracy: 0.9884 - top-3: 0.9997 - ROC-AUC: 0.9974 - PR-AUC: 0.9917 - precision: 0.9884 - recall: 0.9884 - TP: 8967.0000 - TN: 99687.0000 - FP: 105.0000 - FN: 105.0000 - val_loss: 0.0090 - val_categorical_accuracy: 0.9985 - val_top-3: 0.9998 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9985 - val_recall: 0.9985 - val_TP: 6039.0000 - val_TN: 66519.0000 - val_FP: 9.0000 - val_FN: 9.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1234 - categorical_accuracy: 0.9868 - top-3: 0.9992 - ROC-AUC: 0.9960 - PR-AUC: 0.9876 - precision: 0.9868 - recall: 0.9868 - TP: 8952.0000 - TN: 99672.0000 - FP: 120.0000 - FN: 120.0000 - val_loss: 0.0431 - val_categorical_accuracy: 0.9952 - val_top-3: 0.9998 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9955 - val_precision: 0.9952 - val_recall: 0.9952 - val_TP: 6019.0000 - val_TN: 66499.0000 - val_FP: 29.0000 - val_FN: 29.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.1048 - categorical_accuracy: 0.9878 - top-3: 0.9998 - ROC-AUC: 0.9962 - PR-AUC: 0.9877 - precision: 0.9878 - recall: 0.9878 - TP: 8961.0000 - TN: 99681.0000 - FP: 111.0000 - FN: 111.0000 - val_loss: 0.0081 - val_categorical_accuracy: 0.9983 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9983 - val_recall: 0.9983 - val_TP: 6038.0000 - val_TN: 66518.0000 - val_FP: 10.0000 - val_FN: 10.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1121 - categorical_accuracy: 0.9875 - top-3: 0.9992 - ROC-AUC: 0.9964 - PR-AUC: 0.9891 - precision: 0.9875 - recall: 0.9875 - TP: 8959.0000 - TN: 99679.0000 - FP: 113.0000 - FN: 113.0000 - val_loss: 0.0068 - val_categorical_accuracy: 0.9988 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9988 - val_recall: 0.9988 - val_TP: 6041.0000 - val_TN: 66521.0000 - val_FP: 7.0000 - val_FN: 7.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 198s 349ms/step - loss: 0.1038 - categorical_accuracy: 0.9884 - top-3: 0.9991 - ROC-AUC: 0.9964 - PR-AUC: 0.9891 - precision: 0.9884 - recall: 0.9884 - TP: 8967.0000 - TN: 99687.0000 - FP: 105.0000 - FN: 105.0000 - val_loss: 0.0161 - val_categorical_accuracy: 0.9985 - val_top-3: 0.9998 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9982 - val_precision: 0.9985 - val_recall: 0.9985 - val_TP: 6039.0000 - val_TN: 66519.0000 - val_FP: 9.0000 - val_FN: 9.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.1248 - categorical_accuracy: 0.9871 - top-3: 0.9993 - ROC-AUC: 0.9960 - PR-AUC: 0.9873 - precision: 0.9872 - recall: 0.9871 - TP: 8955.0000 - TN: 99676.0000 - FP: 116.0000 - FN: 117.0000 - val_loss: 0.0284 - val_categorical_accuracy: 0.9977 - val_top-3: 0.9998 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9977 - val_precision: 0.9977 - val_recall: 0.9977 - val_TP: 6034.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 14.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1013 - categorical_accuracy: 0.9881 - top-3: 0.9997 - ROC-AUC: 0.9963 - PR-AUC: 0.9881 - precision: 0.9881 - recall: 0.9881 - TP: 8964.0000 - TN: 99684.0000 - FP: 108.0000 - FN: 108.0000 - val_loss: 0.0953 - val_categorical_accuracy: 0.9897 - val_top-3: 0.9998 - val_ROC-AUC: 0.9964 - val_PR-AUC: 0.9885 - val_precision: 0.9897 - val_recall: 0.9897 - val_TP: 5986.0000 - val_TN: 66466.0000 - val_FP: 62.0000 - val_FN: 62.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.1301 - categorical_accuracy: 0.9868 - top-3: 0.9989 - ROC-AUC: 0.9954 - PR-AUC: 0.9857 - precision: 0.9870 - recall: 0.9868 - TP: 8952.0000 - TN: 99674.0000 - FP: 118.0000 - FN: 120.0000 - val_loss: 0.0156 - val_categorical_accuracy: 0.9977 - val_top-3: 1.0000 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9979 - val_precision: 0.9977 - val_recall: 0.9977 - val_TP: 6034.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 14.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1031 - categorical_accuracy: 0.9894 - top-3: 0.9997 - ROC-AUC: 0.9965 - PR-AUC: 0.9891 - precision: 0.9894 - recall: 0.9894 - TP: 8976.0000 - TN: 99696.0000 - FP: 96.0000 - FN: 96.0000 - val_loss: 0.0091 - val_categorical_accuracy: 0.9987 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9987 - val_recall: 0.9987 - val_TP: 6040.0000 - val_TN: 66520.0000 - val_FP: 8.0000 - val_FN: 8.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 198s 350ms/step - loss: 0.1108 - categorical_accuracy: 0.9890 - top-3: 0.9997 - ROC-AUC: 0.9966 - PR-AUC: 0.9895 - precision: 0.9890 - recall: 0.9890 - TP: 8972.0000 - TN: 99692.0000 - FP: 100.0000 - FN: 100.0000 - val_loss: 0.0052 - val_categorical_accuracy: 0.9990 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9990 - val_recall: 0.9990 - val_TP: 6042.0000 - val_TN: 66522.0000 - val_FP: 6.0000 - val_FN: 6.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.1059 - categorical_accuracy: 0.9902 - top-3: 0.9996 - ROC-AUC: 0.9968 - PR-AUC: 0.9896 - precision: 0.9902 - recall: 0.9902 - TP: 8983.0000 - TN: 99703.0000 - FP: 89.0000 - FN: 89.0000 - val_loss: 0.0031 - val_categorical_accuracy: 0.9995 - val_top-3: 1.0000 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9995 - val_recall: 0.9995 - val_TP: 6045.0000 - val_TN: 66525.0000 - val_FP: 3.0000 - val_FN: 3.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.1002 - categorical_accuracy: 0.9892 - top-3: 0.9996 - ROC-AUC: 0.9966 - PR-AUC: 0.9895 - precision: 0.9892 - recall: 0.9892 - TP: 8974.0000 - TN: 99694.0000 - FP: 98.0000 - FN: 98.0000 - val_loss: 0.0142 - val_categorical_accuracy: 0.9977 - val_top-3: 0.9998 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9981 - val_precision: 0.9977 - val_recall: 0.9977 - val_TP: 6034.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 14.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.1138 - categorical_accuracy: 0.9895 - top-3: 0.9996 - ROC-AUC: 0.9967 - PR-AUC: 0.9899 - precision: 0.9895 - recall: 0.9895 - TP: 8977.0000 - TN: 99697.0000 - FP: 95.0000 - FN: 95.0000 - val_loss: 0.0446 - val_categorical_accuracy: 0.9970 - val_top-3: 1.0000 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9965 - val_precision: 0.9970 - val_recall: 0.9970 - val_TP: 6030.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 18.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.1212 - categorical_accuracy: 0.9899 - top-3: 0.9997 - ROC-AUC: 0.9962 - PR-AUC: 0.9876 - precision: 0.9899 - recall: 0.9899 - TP: 8980.0000 - TN: 99700.0000 - FP: 92.0000 - FN: 92.0000 - val_loss: 0.0062 - val_categorical_accuracy: 0.9992 - val_top-3: 1.0000 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9992 - val_recall: 0.9992 - val_TP: 6043.0000 - val_TN: 66523.0000 - val_FP: 5.0000 - val_FN: 5.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.0985 - categorical_accuracy: 0.9902 - top-3: 0.9998 - ROC-AUC: 0.9970 - PR-AUC: 0.9904 - precision: 0.9902 - recall: 0.9902 - TP: 8983.0000 - TN: 99703.0000 - FP: 89.0000 - FN: 89.0000 - val_loss: 0.0325 - val_categorical_accuracy: 0.9969 - val_top-3: 0.9998 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969 - val_TP: 6029.0000 - val_TN: 66509.0000 - val_FP: 19.0000 - val_FN: 19.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.1237 - categorical_accuracy: 0.9880 - top-3: 0.9994 - ROC-AUC: 0.9959 - PR-AUC: 0.9872 - precision: 0.9881 - recall: 0.9880 - TP: 8963.0000 - TN: 99684.0000 - FP: 108.0000 - FN: 109.0000 - val_loss: 0.0211 - val_categorical_accuracy: 0.9979 - val_top-3: 1.0000 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9984 - val_precision: 0.9979 - val_recall: 0.9979 - val_TP: 6035.0000 - val_TN: 66515.0000 - val_FP: 13.0000 - val_FN: 13.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.1029 - categorical_accuracy: 0.9890 - top-3: 0.9999 - ROC-AUC: 0.9961 - PR-AUC: 0.9875 - precision: 0.9890 - recall: 0.9890 - TP: 8972.0000 - TN: 99692.0000 - FP: 100.0000 - FN: 100.0000 - val_loss: 0.0103 - val_categorical_accuracy: 0.9987 - val_top-3: 0.9998 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9990 - val_precision: 0.9987 - val_recall: 0.9987 - val_TP: 6040.0000 - val_TN: 66520.0000 - val_FP: 8.0000 - val_FN: 8.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.0789 - categorical_accuracy: 0.9909 - top-3: 0.9997 - ROC-AUC: 0.9974 - PR-AUC: 0.9917 - precision: 0.9910 - recall: 0.9907 - TP: 8988.0000 - TN: 99710.0000 - FP: 82.0000 - FN: 84.0000 - val_loss: 0.0347 - val_categorical_accuracy: 0.9972 - val_top-3: 1.0000 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9959 - val_precision: 0.9972 - val_recall: 0.9972 - val_TP: 6031.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 17.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.0718 - categorical_accuracy: 0.9910 - top-3: 0.9998 - ROC-AUC: 0.9973 - PR-AUC: 0.9917 - precision: 0.9910 - recall: 0.9910 - TP: 8990.0000 - TN: 99710.0000 - FP: 82.0000 - FN: 82.0000 - val_loss: 0.0375 - val_categorical_accuracy: 0.9980 - val_top-3: 1.0000 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9971 - val_precision: 0.9980 - val_recall: 0.9980 - val_TP: 6036.0000 - val_TN: 66516.0000 - val_FP: 12.0000 - val_FN: 12.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.0774 - categorical_accuracy: 0.9914 - top-3: 0.9997 - ROC-AUC: 0.9975 - PR-AUC: 0.9919 - precision: 0.9914 - recall: 0.9914 - TP: 8994.0000 - TN: 99714.0000 - FP: 78.0000 - FN: 78.0000 - val_loss: 0.0243 - val_categorical_accuracy: 0.9979 - val_top-3: 1.0000 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9978 - val_precision: 0.9979 - val_recall: 0.9979 - val_TP: 6035.0000 - val_TN: 66515.0000 - val_FP: 13.0000 - val_FN: 13.0000\n",
      "-----\n",
      "(9837464.99 ms) == (163m:57s)\n",
      "-----\n",
      "\n",
      "\n",
      "23\n",
      "['mobilenetv2_1.00_128-imagenet128-16-12.tensorboard',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.001_0.9744_0.0845.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.002_0.9864_0.0477.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.003_0.9924_0.0306.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.006_0.9950_0.0290.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.011_0.9950_0.0250.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.018_0.9959_0.0354.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.019_0.9964_0.0203.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.024_0.9983_0.0152.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.026_0.9985_0.0076.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.034_0.9988_0.0068.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.040_0.9990_0.0052.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.041_0.9995_0.0031.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_128-imagenet128-16-12.csv',\n",
      " 'model.mobilenetv2_1.00_128-imagenet128-16-12.h5',\n",
      " 'weights.mobilenetv2_1.00_128-imagenet128-16-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_128-imagenet128-16-12\n",
    "model_12 = consecutiveModelTraining(\n",
    "    input_size=128,\n",
    "    batch_size=16,\n",
    "    weights='imagenet',\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc5df83-988c-431b-9def-9584b8325be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T18:29:24.413555Z",
     "iopub.status.busy": "2021-06-10T18:29:24.412551Z",
     "iopub.status.idle": "2021-06-10T18:29:24.491554Z",
     "shell.execute_reply": "2021-06-10T18:29:24.490557Z",
     "shell.execute_reply.started": "2021-06-10T18:29:24.413555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.124728</td>\n",
       "      <td>0.982319</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.986462</td>\n",
       "      <td>0.982912</td>\n",
       "      <td>0.981971</td>\n",
       "      <td>8908.440000</td>\n",
       "      <td>99637.500000</td>\n",
       "      <td>154.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.994815</td>\n",
       "      <td>6016.640000</td>\n",
       "      <td>66497.240000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>31.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034930</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>130.791181</td>\n",
       "      <td>92.241088</td>\n",
       "      <td>92.241088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>29.639163</td>\n",
       "      <td>27.985827</td>\n",
       "      <td>27.985827</td>\n",
       "      <td>29.639163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.910604</td>\n",
       "      <td>0.977844</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.966745</td>\n",
       "      <td>0.930676</td>\n",
       "      <td>0.898258</td>\n",
       "      <td>8149.000000</td>\n",
       "      <td>99185.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974372</td>\n",
       "      <td>0.998347</td>\n",
       "      <td>0.996399</td>\n",
       "      <td>0.988536</td>\n",
       "      <td>0.976127</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>5888.000000</td>\n",
       "      <td>66384.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>0.981040</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>8899.500000</td>\n",
       "      <td>99620.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>6011.000000</td>\n",
       "      <td>66491.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.121625</td>\n",
       "      <td>0.986607</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.995973</td>\n",
       "      <td>0.987225</td>\n",
       "      <td>0.986606</td>\n",
       "      <td>0.986552</td>\n",
       "      <td>8950.000000</td>\n",
       "      <td>99670.500000</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.999051</td>\n",
       "      <td>0.996982</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>6027.500000</td>\n",
       "      <td>66507.500000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>20.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.136586</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.996454</td>\n",
       "      <td>0.989122</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>8967.000000</td>\n",
       "      <td>99687.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.998066</td>\n",
       "      <td>0.997851</td>\n",
       "      <td>0.997851</td>\n",
       "      <td>6035.000000</td>\n",
       "      <td>66515.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.295429</td>\n",
       "      <td>0.991402</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.997477</td>\n",
       "      <td>0.991936</td>\n",
       "      <td>0.991402</td>\n",
       "      <td>0.991402</td>\n",
       "      <td>8994.000000</td>\n",
       "      <td>99714.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>6045.000000</td>\n",
       "      <td>66525.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.124728              0.982319   0.998735   0.995722   0.986462   \n",
       "std     0.034930              0.012842   0.003112   0.001087   0.004046   \n",
       "min     0.071764              0.910604   0.977844   0.991876   0.966745   \n",
       "25%     0.104082              0.980985   0.998898   0.994951   0.984602   \n",
       "50%     0.121625              0.986607   0.999339   0.995973   0.987225   \n",
       "75%     0.136586              0.988426   0.999669   0.996454   0.989122   \n",
       "max     0.295429              0.991402   0.999890   0.997477   0.991936   \n",
       "\n",
       "       precision     recall           TP            TN          FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000   50.000000  ...   \n",
       "mean    0.982912   0.981971  8908.440000  99637.500000  154.500000  ...   \n",
       "std     0.010430   0.014417   130.791181     92.241088   92.241088  ...   \n",
       "min     0.930676   0.898258  8149.000000  99185.000000   78.000000  ...   \n",
       "25%     0.981040   0.980985  8899.500000  99620.000000  105.000000  ...   \n",
       "50%     0.986606   0.986552  8950.000000  99670.500000  121.500000  ...   \n",
       "75%     0.988426   0.988426  8967.000000  99687.000000  172.000000  ...   \n",
       "max     0.991402   0.991402  8994.000000  99714.000000  607.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.994851   0.999798     0.998862    0.996400   \n",
       "std                    0.004808   0.000341     0.000794    0.002530   \n",
       "min                    0.974372   0.998347     0.996399    0.988536   \n",
       "25%                    0.993882   0.999835     0.998497    0.995319   \n",
       "50%                    0.996610   0.999835     0.999051    0.996982   \n",
       "75%                    0.997851   1.000000     0.999374    0.998066   \n",
       "max                    0.999504   1.000000     0.999910    0.999704   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.994912    0.994815  6016.640000  66497.240000   30.760000   \n",
       "std         0.004633    0.004901    29.639163     27.985827   27.985827   \n",
       "min         0.976127    0.973545  5888.000000  66384.000000    3.000000   \n",
       "25%         0.993882    0.993882  6011.000000  66491.000000   13.000000   \n",
       "50%         0.996610    0.996610  6027.500000  66507.500000   20.500000   \n",
       "75%         0.997851    0.997851  6035.000000  66515.000000   37.000000   \n",
       "max         0.999504    0.999504  6045.000000  66525.000000  144.000000   \n",
       "\n",
       "           val_FN  \n",
       "count   50.000000  \n",
       "mean    31.360000  \n",
       "std     29.639163  \n",
       "min      3.000000  \n",
       "25%     13.000000  \n",
       "50%     20.500000  \n",
       "75%     37.000000  \n",
       "max    160.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622274e-f7d9-4e96-8ce6-4810cfbaa5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d34acfe-6736-47fd-bf7f-d81d992bd70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T18:29:24.693568Z",
     "iopub.status.busy": "2021-06-10T18:29:24.692573Z",
     "iopub.status.idle": "2021-06-10T21:13:32.457203Z",
     "shell.execute_reply": "2021-06-10T21:13:32.456206Z",
     "shell.execute_reply.started": "2021-06-10T18:29:24.693568Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_128-imagenet128-16-fc12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_128-imagenet128-16-fc12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_128 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,686,156\n",
      "Trainable params: 428,172\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_128-imagenet128-16-fc12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_128-imagenet128-16-fc12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_128-imagenet128-16-fc12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 41:10 - loss: 5.7222 - categorical_accuracy: 0.0312 - top-3: 0.1250 - ROC-AUC: 0.4286 - PR-AUC: 0.0716 - precision: 0.1111 - recall: 0.0312 - TP: 1.0000 - TN: 344.0000 - FP: 8.0000 - FN: 31.0000                 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2110s vs `on_train_batch_end` time: 8.5322s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2110s vs `on_train_batch_end` time: 8.5322s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/567 [==============================] - 210s 371ms/step - loss: 0.9332 - categorical_accuracy: 0.7167 - top-3: 0.8922 - ROC-AUC: 0.9583 - PR-AUC: 0.8120 - precision: 0.8418 - recall: 0.6383 - TP: 5791.0000 - TN: 98704.0000 - FP: 1088.0000 - FN: 3281.0000 - val_loss: 0.2159 - val_categorical_accuracy: 0.9339 - val_top-3: 0.9889 - val_ROC-AUC: 0.9967 - val_PR-AUC: 0.9816 - val_precision: 0.9566 - val_recall: 0.9064 - val_TP: 5482.0000 - val_TN: 66279.0000 - val_FP: 249.0000 - val_FN: 566.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.4747 - categorical_accuracy: 0.8571 - top-3: 0.9538 - ROC-AUC: 0.9859 - PR-AUC: 0.9313 - precision: 0.9180 - recall: 0.8137 - TP: 7382.0000 - TN: 99133.0000 - FP: 659.0000 - FN: 1690.0000 - val_loss: 0.1222 - val_categorical_accuracy: 0.9661 - val_top-3: 0.9944 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9926 - val_precision: 0.9730 - val_recall: 0.9611 - val_TP: 5813.0000 - val_TN: 66367.0000 - val_FP: 161.0000 - val_FN: 235.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.5199 - categorical_accuracy: 0.8488 - top-3: 0.9415 - ROC-AUC: 0.9849 - PR-AUC: 0.9272 - precision: 0.9232 - recall: 0.7995 - TP: 7253.0000 - TN: 99189.0000 - FP: 603.0000 - FN: 1819.0000 - val_loss: 0.1533 - val_categorical_accuracy: 0.9565 - val_top-3: 0.9939 - val_ROC-AUC: 0.9979 - val_PR-AUC: 0.9894 - val_precision: 0.9668 - val_recall: 0.9383 - val_TP: 5675.0000 - val_TN: 66333.0000 - val_FP: 195.0000 - val_FN: 373.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.4462 - categorical_accuracy: 0.8685 - top-3: 0.9516 - ROC-AUC: 0.9877 - PR-AUC: 0.9416 - precision: 0.9327 - recall: 0.8307 - TP: 7536.0000 - TN: 99248.0000 - FP: 544.0000 - FN: 1536.0000 - val_loss: 0.1090 - val_categorical_accuracy: 0.9777 - val_top-3: 0.9967 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9948 - val_precision: 0.9858 - val_recall: 0.9633 - val_TP: 5826.0000 - val_TN: 66444.0000 - val_FP: 84.0000 - val_FN: 222.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 195s 345ms/step - loss: 0.4736 - categorical_accuracy: 0.8727 - top-3: 0.9432 - ROC-AUC: 0.9867 - PR-AUC: 0.9393 - precision: 0.9344 - recall: 0.8406 - TP: 7626.0000 - TN: 99257.0000 - FP: 535.0000 - FN: 1446.0000 - val_loss: 0.1161 - val_categorical_accuracy: 0.9777 - val_top-3: 0.9939 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9963 - val_precision: 0.9933 - val_recall: 0.9568 - val_TP: 5787.0000 - val_TN: 66489.0000 - val_FP: 39.0000 - val_FN: 261.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.4761 - categorical_accuracy: 0.8760 - top-3: 0.9475 - ROC-AUC: 0.9877 - PR-AUC: 0.9425 - precision: 0.9414 - recall: 0.8390 - TP: 7611.0000 - TN: 99318.0000 - FP: 474.0000 - FN: 1461.0000 - val_loss: 0.1203 - val_categorical_accuracy: 0.9681 - val_top-3: 0.9896 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9928 - val_precision: 0.9858 - val_recall: 0.9532 - val_TP: 5765.0000 - val_TN: 66445.0000 - val_FP: 83.0000 - val_FN: 283.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 195s 345ms/step - loss: 0.4739 - categorical_accuracy: 0.8645 - top-3: 0.9489 - ROC-AUC: 0.9874 - PR-AUC: 0.9386 - precision: 0.9354 - recall: 0.8258 - TP: 7492.0000 - TN: 99275.0000 - FP: 517.0000 - FN: 1580.0000 - val_loss: 0.0875 - val_categorical_accuracy: 0.9787 - val_top-3: 0.9954 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9955 - val_precision: 0.9877 - val_recall: 0.9701 - val_TP: 5867.0000 - val_TN: 66455.0000 - val_FP: 73.0000 - val_FN: 181.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 195s 345ms/step - loss: 0.3986 - categorical_accuracy: 0.8847 - top-3: 0.9582 - ROC-AUC: 0.9906 - PR-AUC: 0.9545 - precision: 0.9518 - recall: 0.8549 - TP: 7756.0000 - TN: 99399.0000 - FP: 393.0000 - FN: 1316.0000 - val_loss: 0.1380 - val_categorical_accuracy: 0.9697 - val_top-3: 0.9924 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9933 - val_precision: 0.9910 - val_recall: 0.9423 - val_TP: 5699.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 349.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 196s 347ms/step - loss: 0.3427 - categorical_accuracy: 0.9023 - top-3: 0.9635 - ROC-AUC: 0.9923 - PR-AUC: 0.9617 - precision: 0.9558 - recall: 0.8724 - TP: 7914.0000 - TN: 99426.0000 - FP: 366.0000 - FN: 1158.0000 - val_loss: 0.0517 - val_categorical_accuracy: 0.9879 - val_top-3: 0.9972 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9980 - val_precision: 0.9915 - val_recall: 0.9823 - val_TP: 5941.0000 - val_TN: 66477.0000 - val_FP: 51.0000 - val_FN: 107.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 198s 349ms/step - loss: 0.3116 - categorical_accuracy: 0.9078 - top-3: 0.9646 - ROC-AUC: 0.9936 - PR-AUC: 0.9679 - precision: 0.9623 - recall: 0.8823 - TP: 8004.0000 - TN: 99478.0000 - FP: 314.0000 - FN: 1068.0000 - val_loss: 0.0583 - val_categorical_accuracy: 0.9874 - val_top-3: 0.9970 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9982 - val_precision: 0.9920 - val_recall: 0.9823 - val_TP: 5941.0000 - val_TN: 66480.0000 - val_FP: 48.0000 - val_FN: 107.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3964 - categorical_accuracy: 0.8969 - top-3: 0.9584 - ROC-AUC: 0.9904 - PR-AUC: 0.9572 - precision: 0.9555 - recall: 0.8677 - TP: 7872.0000 - TN: 99425.0000 - FP: 367.0000 - FN: 1200.0000 - val_loss: 0.1820 - val_categorical_accuracy: 0.9375 - val_top-3: 0.9869 - val_ROC-AUC: 0.9984 - val_PR-AUC: 0.9873 - val_precision: 0.9629 - val_recall: 0.9173 - val_TP: 5548.0000 - val_TN: 66314.0000 - val_FP: 214.0000 - val_FN: 500.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3565 - categorical_accuracy: 0.9010 - top-3: 0.9605 - ROC-AUC: 0.9919 - PR-AUC: 0.9600 - precision: 0.9573 - recall: 0.8677 - TP: 7872.0000 - TN: 99441.0000 - FP: 351.0000 - FN: 1200.0000 - val_loss: 0.1098 - val_categorical_accuracy: 0.9721 - val_top-3: 0.9952 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9916 - val_precision: 0.9809 - val_recall: 0.9606 - val_TP: 5810.0000 - val_TN: 66415.0000 - val_FP: 113.0000 - val_FN: 238.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.4515 - categorical_accuracy: 0.8978 - top-3: 0.9516 - ROC-AUC: 0.9909 - PR-AUC: 0.9565 - precision: 0.9616 - recall: 0.8666 - TP: 7862.0000 - TN: 99478.0000 - FP: 314.0000 - FN: 1210.0000 - val_loss: 0.0689 - val_categorical_accuracy: 0.9810 - val_top-3: 0.9883 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9981 - val_precision: 0.9971 - val_recall: 0.9727 - val_TP: 5883.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 165.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.4139 - categorical_accuracy: 0.8882 - top-3: 0.9533 - ROC-AUC: 0.9905 - PR-AUC: 0.9532 - precision: 0.9504 - recall: 0.8573 - TP: 7777.0000 - TN: 99386.0000 - FP: 406.0000 - FN: 1295.0000 - val_loss: 0.3190 - val_categorical_accuracy: 0.9244 - val_top-3: 0.9640 - val_ROC-AUC: 0.9908 - val_PR-AUC: 0.9663 - val_precision: 0.9755 - val_recall: 0.8902 - val_TP: 5384.0000 - val_TN: 66393.0000 - val_FP: 135.0000 - val_FN: 664.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.4718 - categorical_accuracy: 0.8838 - top-3: 0.9415 - ROC-AUC: 0.9859 - PR-AUC: 0.9363 - precision: 0.9209 - recall: 0.8473 - TP: 7687.0000 - TN: 99132.0000 - FP: 660.0000 - FN: 1385.0000 - val_loss: 0.1681 - val_categorical_accuracy: 0.9754 - val_top-3: 0.9894 - val_ROC-AUC: 0.9961 - val_PR-AUC: 0.9847 - val_precision: 0.9824 - val_recall: 0.9694 - val_TP: 5863.0000 - val_TN: 66423.0000 - val_FP: 105.0000 - val_FN: 185.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.3995 - categorical_accuracy: 0.9035 - top-3: 0.9550 - ROC-AUC: 0.9905 - PR-AUC: 0.9545 - precision: 0.9359 - recall: 0.8784 - TP: 7969.0000 - TN: 99246.0000 - FP: 546.0000 - FN: 1103.0000 - val_loss: 0.0769 - val_categorical_accuracy: 0.9841 - val_top-3: 0.9927 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9963 - val_precision: 0.9887 - val_recall: 0.9803 - val_TP: 5929.0000 - val_TN: 66460.0000 - val_FP: 68.0000 - val_FN: 119.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.3837 - categorical_accuracy: 0.9005 - top-3: 0.9549 - ROC-AUC: 0.9909 - PR-AUC: 0.9575 - precision: 0.9491 - recall: 0.8722 - TP: 7913.0000 - TN: 99368.0000 - FP: 424.0000 - FN: 1159.0000 - val_loss: 0.1197 - val_categorical_accuracy: 0.9732 - val_top-3: 0.9952 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9954 - val_precision: 0.9916 - val_recall: 0.9611 - val_TP: 5813.0000 - val_TN: 66479.0000 - val_FP: 49.0000 - val_FN: 235.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.3272 - categorical_accuracy: 0.9128 - top-3: 0.9627 - ROC-AUC: 0.9934 - PR-AUC: 0.9659 - precision: 0.9516 - recall: 0.8803 - TP: 7986.0000 - TN: 99386.0000 - FP: 406.0000 - FN: 1086.0000 - val_loss: 0.0745 - val_categorical_accuracy: 0.9854 - val_top-3: 0.9927 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9971 - val_precision: 0.9936 - val_recall: 0.9820 - val_TP: 5939.0000 - val_TN: 66490.0000 - val_FP: 38.0000 - val_FN: 109.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.2595 - categorical_accuracy: 0.9218 - top-3: 0.9706 - ROC-AUC: 0.9946 - PR-AUC: 0.9746 - precision: 0.9675 - recall: 0.8991 - TP: 8157.0000 - TN: 99518.0000 - FP: 274.0000 - FN: 915.0000 - val_loss: 0.0284 - val_categorical_accuracy: 0.9955 - val_top-3: 0.9985 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9994 - val_precision: 0.9980 - val_recall: 0.9937 - val_TP: 6010.0000 - val_TN: 66516.0000 - val_FP: 12.0000 - val_FN: 38.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.3253 - categorical_accuracy: 0.9153 - top-3: 0.9633 - ROC-AUC: 0.9940 - PR-AUC: 0.9707 - precision: 0.9686 - recall: 0.8908 - TP: 8081.0000 - TN: 99530.0000 - FP: 262.0000 - FN: 991.0000 - val_loss: 0.0696 - val_categorical_accuracy: 0.9874 - val_top-3: 0.9970 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9965 - val_precision: 0.9916 - val_recall: 0.9783 - val_TP: 5917.0000 - val_TN: 66478.0000 - val_FP: 50.0000 - val_FN: 131.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.3423 - categorical_accuracy: 0.9074 - top-3: 0.9609 - ROC-AUC: 0.9931 - PR-AUC: 0.9662 - precision: 0.9636 - recall: 0.8833 - TP: 8013.0000 - TN: 99489.0000 - FP: 303.0000 - FN: 1059.0000 - val_loss: 0.0493 - val_categorical_accuracy: 0.9869 - val_top-3: 0.9962 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9971 - val_precision: 0.9925 - val_recall: 0.9841 - val_TP: 5952.0000 - val_TN: 66483.0000 - val_FP: 45.0000 - val_FN: 96.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3610 - categorical_accuracy: 0.8924 - top-3: 0.9532 - ROC-AUC: 0.9922 - PR-AUC: 0.9579 - precision: 0.9656 - recall: 0.8620 - TP: 7820.0000 - TN: 99513.0000 - FP: 279.0000 - FN: 1252.0000 - val_loss: 0.1254 - val_categorical_accuracy: 0.9692 - val_top-3: 0.9901 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9944 - val_precision: 0.9957 - val_recall: 0.9519 - val_TP: 5757.0000 - val_TN: 66503.0000 - val_FP: 25.0000 - val_FN: 291.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.3979 - categorical_accuracy: 0.8816 - top-3: 0.9415 - ROC-AUC: 0.9907 - PR-AUC: 0.9515 - precision: 0.9644 - recall: 0.8459 - TP: 7674.0000 - TN: 99509.0000 - FP: 283.0000 - FN: 1398.0000 - val_loss: 0.0797 - val_categorical_accuracy: 0.9899 - val_top-3: 0.9950 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9978 - val_precision: 0.9971 - val_recall: 0.9800 - val_TP: 5927.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 121.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3370 - categorical_accuracy: 0.9047 - top-3: 0.9560 - ROC-AUC: 0.9923 - PR-AUC: 0.9627 - precision: 0.9682 - recall: 0.8773 - TP: 7959.0000 - TN: 99531.0000 - FP: 261.0000 - FN: 1113.0000 - val_loss: 0.0452 - val_categorical_accuracy: 0.9874 - val_top-3: 0.9970 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9985 - val_precision: 0.9925 - val_recall: 0.9843 - val_TP: 5953.0000 - val_TN: 66483.0000 - val_FP: 45.0000 - val_FN: 95.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3078 - categorical_accuracy: 0.9142 - top-3: 0.9626 - ROC-AUC: 0.9938 - PR-AUC: 0.9702 - precision: 0.9661 - recall: 0.8900 - TP: 8074.0000 - TN: 99509.0000 - FP: 283.0000 - FN: 998.0000 - val_loss: 0.0440 - val_categorical_accuracy: 0.9881 - val_top-3: 0.9967 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9981 - val_precision: 0.9923 - val_recall: 0.9826 - val_TP: 5943.0000 - val_TN: 66482.0000 - val_FP: 46.0000 - val_FN: 105.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3121 - categorical_accuracy: 0.9093 - top-3: 0.9629 - ROC-AUC: 0.9937 - PR-AUC: 0.9686 - precision: 0.9648 - recall: 0.8834 - TP: 8014.0000 - TN: 99500.0000 - FP: 292.0000 - FN: 1058.0000 - val_loss: 0.0553 - val_categorical_accuracy: 0.9830 - val_top-3: 0.9926 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9987 - val_precision: 0.9941 - val_recall: 0.9759 - val_TP: 5902.0000 - val_TN: 66493.0000 - val_FP: 35.0000 - val_FN: 146.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.3178 - categorical_accuracy: 0.9073 - top-3: 0.9613 - ROC-AUC: 0.9934 - PR-AUC: 0.9679 - precision: 0.9627 - recall: 0.8803 - TP: 7986.0000 - TN: 99483.0000 - FP: 309.0000 - FN: 1086.0000 - val_loss: 0.0642 - val_categorical_accuracy: 0.9841 - val_top-3: 0.9959 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9980 - val_precision: 0.9921 - val_recall: 0.9767 - val_TP: 5907.0000 - val_TN: 66481.0000 - val_FP: 47.0000 - val_FN: 141.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.2886 - categorical_accuracy: 0.9144 - top-3: 0.9676 - ROC-AUC: 0.9945 - PR-AUC: 0.9718 - precision: 0.9682 - recall: 0.8890 - TP: 8065.0000 - TN: 99527.0000 - FP: 265.0000 - FN: 1007.0000 - val_loss: 0.0702 - val_categorical_accuracy: 0.9821 - val_top-3: 0.9979 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9974 - val_precision: 0.9913 - val_recall: 0.9760 - val_TP: 5903.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 145.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.3115 - categorical_accuracy: 0.9164 - top-3: 0.9674 - ROC-AUC: 0.9942 - PR-AUC: 0.9719 - precision: 0.9680 - recall: 0.8907 - TP: 8080.0000 - TN: 99525.0000 - FP: 267.0000 - FN: 992.0000 - val_loss: 0.0713 - val_categorical_accuracy: 0.9916 - val_top-3: 0.9965 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9962 - val_precision: 0.9958 - val_recall: 0.9871 - val_TP: 5970.0000 - val_TN: 66503.0000 - val_FP: 25.0000 - val_FN: 78.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.2634 - categorical_accuracy: 0.9156 - top-3: 0.9673 - ROC-AUC: 0.9955 - PR-AUC: 0.9751 - precision: 0.9714 - recall: 0.8941 - TP: 8111.0000 - TN: 99553.0000 - FP: 239.0000 - FN: 961.0000 - val_loss: 0.0541 - val_categorical_accuracy: 0.9873 - val_top-3: 0.9939 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9980 - val_precision: 0.9947 - val_recall: 0.9845 - val_TP: 5954.0000 - val_TN: 66496.0000 - val_FP: 32.0000 - val_FN: 94.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3265 - categorical_accuracy: 0.9146 - top-3: 0.9696 - ROC-AUC: 0.9935 - PR-AUC: 0.9699 - precision: 0.9631 - recall: 0.8882 - TP: 8058.0000 - TN: 99483.0000 - FP: 309.0000 - FN: 1014.0000 - val_loss: 0.0425 - val_categorical_accuracy: 0.9911 - val_top-3: 0.9954 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9985 - val_precision: 0.9980 - val_recall: 0.9883 - val_TP: 5977.0000 - val_TN: 66516.0000 - val_FP: 12.0000 - val_FN: 71.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 194s 342ms/step - loss: 0.3369 - categorical_accuracy: 0.9087 - top-3: 0.9618 - ROC-AUC: 0.9938 - PR-AUC: 0.9687 - precision: 0.9704 - recall: 0.8847 - TP: 8026.0000 - TN: 99547.0000 - FP: 245.0000 - FN: 1046.0000 - val_loss: 0.0793 - val_categorical_accuracy: 0.9906 - val_top-3: 0.9952 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9971 - val_precision: 0.9957 - val_recall: 0.9843 - val_TP: 5953.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 95.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.3322 - categorical_accuracy: 0.9084 - top-3: 0.9568 - ROC-AUC: 0.9930 - PR-AUC: 0.9665 - precision: 0.9675 - recall: 0.8851 - TP: 8030.0000 - TN: 99522.0000 - FP: 270.0000 - FN: 1042.0000 - val_loss: 0.0798 - val_categorical_accuracy: 0.9800 - val_top-3: 0.9954 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9973 - val_precision: 0.9934 - val_recall: 0.9755 - val_TP: 5900.0000 - val_TN: 66489.0000 - val_FP: 39.0000 - val_FN: 148.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3349 - categorical_accuracy: 0.9048 - top-3: 0.9595 - ROC-AUC: 0.9939 - PR-AUC: 0.9678 - precision: 0.9711 - recall: 0.8793 - TP: 7977.0000 - TN: 99555.0000 - FP: 237.0000 - FN: 1095.0000 - val_loss: 0.0674 - val_categorical_accuracy: 0.9831 - val_top-3: 0.9926 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9974 - val_precision: 0.9931 - val_recall: 0.9773 - val_TP: 5911.0000 - val_TN: 66487.0000 - val_FP: 41.0000 - val_FN: 137.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 197s 347ms/step - loss: 0.2888 - categorical_accuracy: 0.9104 - top-3: 0.9630 - ROC-AUC: 0.9949 - PR-AUC: 0.9718 - precision: 0.9739 - recall: 0.8860 - TP: 8038.0000 - TN: 99577.0000 - FP: 215.0000 - FN: 1034.0000 - val_loss: 0.0524 - val_categorical_accuracy: 0.9871 - val_top-3: 0.9960 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9981 - val_precision: 0.9970 - val_recall: 0.9836 - val_TP: 5949.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 99.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3682 - categorical_accuracy: 0.8922 - top-3: 0.9483 - ROC-AUC: 0.9925 - PR-AUC: 0.9599 - precision: 0.9668 - recall: 0.8642 - TP: 7840.0000 - TN: 99523.0000 - FP: 269.0000 - FN: 1232.0000 - val_loss: 0.0558 - val_categorical_accuracy: 0.9869 - val_top-3: 0.9936 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9985 - val_precision: 0.9971 - val_recall: 0.9830 - val_TP: 5945.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 103.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.3093 - categorical_accuracy: 0.9074 - top-3: 0.9582 - ROC-AUC: 0.9933 - PR-AUC: 0.9674 - precision: 0.9747 - recall: 0.8751 - TP: 7939.0000 - TN: 99586.0000 - FP: 206.0000 - FN: 1133.0000 - val_loss: 0.0734 - val_categorical_accuracy: 0.9783 - val_top-3: 0.9944 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9965 - val_precision: 0.9869 - val_recall: 0.9704 - val_TP: 5869.0000 - val_TN: 66450.0000 - val_FP: 78.0000 - val_FN: 179.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3051 - categorical_accuracy: 0.9135 - top-3: 0.9597 - ROC-AUC: 0.9944 - PR-AUC: 0.9705 - precision: 0.9657 - recall: 0.8867 - TP: 8044.0000 - TN: 99506.0000 - FP: 286.0000 - FN: 1028.0000 - val_loss: 0.0932 - val_categorical_accuracy: 0.9790 - val_top-3: 0.9916 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9949 - val_precision: 0.9956 - val_recall: 0.9648 - val_TP: 5835.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 213.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 196s 345ms/step - loss: 0.3291 - categorical_accuracy: 0.9088 - top-3: 0.9509 - ROC-AUC: 0.9931 - PR-AUC: 0.9647 - precision: 0.9756 - recall: 0.8785 - TP: 7970.0000 - TN: 99593.0000 - FP: 199.0000 - FN: 1102.0000 - val_loss: 0.0889 - val_categorical_accuracy: 0.9775 - val_top-3: 0.9924 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9936 - val_precision: 0.9894 - val_recall: 0.9692 - val_TP: 5862.0000 - val_TN: 66465.0000 - val_FP: 63.0000 - val_FN: 186.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3662 - categorical_accuracy: 0.9076 - top-3: 0.9579 - ROC-AUC: 0.9922 - PR-AUC: 0.9657 - precision: 0.9694 - recall: 0.8801 - TP: 7984.0000 - TN: 99540.0000 - FP: 252.0000 - FN: 1088.0000 - val_loss: 0.1201 - val_categorical_accuracy: 0.9628 - val_top-3: 0.9897 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9934 - val_precision: 0.9910 - val_recall: 0.9516 - val_TP: 5755.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 293.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 195s 343ms/step - loss: 0.3636 - categorical_accuracy: 0.9080 - top-3: 0.9561 - ROC-AUC: 0.9936 - PR-AUC: 0.9678 - precision: 0.9726 - recall: 0.8797 - TP: 7981.0000 - TN: 99567.0000 - FP: 225.0000 - FN: 1091.0000 - val_loss: 0.0391 - val_categorical_accuracy: 0.9896 - val_top-3: 0.9962 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9988 - val_precision: 0.9972 - val_recall: 0.9854 - val_TP: 5960.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 88.0000acy: 0.9080 - top-3: 0.9562 - ROC-AUC: 0.9936 - PR-AUC: 0.9678 - precision: 0.9731 \n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3588 - categorical_accuracy: 0.9170 - top-3: 0.9636 - ROC-AUC: 0.9940 - PR-AUC: 0.9714 - precision: 0.9727 - recall: 0.8923 - TP: 8095.0000 - TN: 99565.0000 - FP: 227.0000 - FN: 977.0000 - val_loss: 0.0466 - val_categorical_accuracy: 0.9919 - val_top-3: 0.9974 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9985 - val_precision: 0.9968 - val_recall: 0.9891 - val_TP: 5982.0000 - val_TN: 66509.0000 - val_FP: 19.0000 - val_FN: 66.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.2852 - categorical_accuracy: 0.9212 - top-3: 0.9633 - ROC-AUC: 0.9943 - PR-AUC: 0.9733 - precision: 0.9749 - recall: 0.8964 - TP: 8132.0000 - TN: 99583.0000 - FP: 209.0000 - FN: 940.0000 - val_loss: 0.0551 - val_categorical_accuracy: 0.9864 - val_top-3: 0.9939 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9984 - val_precision: 0.9966 - val_recall: 0.9813 - val_TP: 5935.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 113.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.2397 - categorical_accuracy: 0.9243 - top-3: 0.9656 - ROC-AUC: 0.9956 - PR-AUC: 0.9775 - precision: 0.9843 - recall: 0.9000 - TP: 8165.0000 - TN: 99662.0000 - FP: 130.0000 - FN: 907.0000 - val_loss: 0.0585 - val_categorical_accuracy: 0.9886 - val_top-3: 0.9950 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9977 - val_precision: 0.9970 - val_recall: 0.9744 - val_TP: 5893.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 155.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 196s 346ms/step - loss: 0.3078 - categorical_accuracy: 0.9153 - top-3: 0.9606 - ROC-AUC: 0.9946 - PR-AUC: 0.9725 - precision: 0.9773 - recall: 0.8869 - TP: 8046.0000 - TN: 99605.0000 - FP: 187.0000 - FN: 1026.0000 - val_loss: 0.0422 - val_categorical_accuracy: 0.9883 - val_top-3: 0.9969 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9987 - val_precision: 0.9983 - val_recall: 0.9843 - val_TP: 5953.0000 - val_TN: 66518.0000 - val_FP: 10.0000 - val_FN: 95.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 195s 344ms/step - loss: 0.3244 - categorical_accuracy: 0.9193 - top-3: 0.9621 - ROC-AUC: 0.9948 - PR-AUC: 0.9745 - precision: 0.9755 - recall: 0.9000 - TP: 8165.0000 - TN: 99587.0000 - FP: 205.0000 - FN: 907.0000 - val_loss: 0.1029 - val_categorical_accuracy: 0.9666 - val_top-3: 0.9952 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9957 - val_precision: 0.9966 - val_recall: 0.9598 - val_TP: 5805.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 243.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 205s 362ms/step - loss: 0.3427 - categorical_accuracy: 0.9023 - top-3: 0.9504 - ROC-AUC: 0.9936 - PR-AUC: 0.9660 - precision: 0.9727 - recall: 0.8791 - TP: 7975.0000 - TN: 99568.0000 - FP: 224.0000 - FN: 1097.0000 - val_loss: 0.0997 - val_categorical_accuracy: 0.9711 - val_top-3: 0.9931 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9952 - val_precision: 0.9895 - val_recall: 0.9684 - val_TP: 5857.0000 - val_TN: 66466.0000 - val_FP: 62.0000 - val_FN: 191.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 216s 380ms/step - loss: 0.2908 - categorical_accuracy: 0.9160 - top-3: 0.9647 - ROC-AUC: 0.9947 - PR-AUC: 0.9738 - precision: 0.9772 - recall: 0.8930 - TP: 8101.0000 - TN: 99603.0000 - FP: 189.0000 - FN: 971.0000 - val_loss: 0.0848 - val_categorical_accuracy: 0.9896 - val_top-3: 0.9965 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9970 - val_precision: 0.9969 - val_recall: 0.9724 - val_TP: 5881.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 167.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 204s 359ms/step - loss: 0.2962 - categorical_accuracy: 0.9159 - top-3: 0.9630 - ROC-AUC: 0.9937 - PR-AUC: 0.9710 - precision: 0.9745 - recall: 0.8931 - TP: 8102.0000 - TN: 99580.0000 - FP: 212.0000 - FN: 970.0000 - val_loss: 0.0447 - val_categorical_accuracy: 0.9897 - val_top-3: 0.9939 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9985 - val_precision: 0.9983 - val_recall: 0.9858 - val_TP: 5962.0000 - val_TN: 66518.0000 - val_FP: 10.0000 - val_FN: 86.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 194s 343ms/step - loss: 0.3264 - categorical_accuracy: 0.9061 - top-3: 0.9543 - ROC-AUC: 0.9947 - PR-AUC: 0.9700 - precision: 0.9771 - recall: 0.8808 - TP: 7991.0000 - TN: 99605.0000 - FP: 187.0000 - FN: 1081.0000 - val_loss: 0.0655 - val_categorical_accuracy: 0.9790 - val_top-3: 0.9942 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9983 - val_precision: 0.9954 - val_recall: 0.9648 - val_TP: 5835.0000 - val_TN: 66501.0000 - val_FP: 27.0000 - val_FN: 213.0000\n",
      "-----\n",
      "(9843383.31 ms) == (164m:3s)\n",
      "-----\n",
      "\n",
      "\n",
      "17\n",
      "['mobilenetv2_1.00_128-imagenet128-16-fc12.tensorboard',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.001_0.9339_0.2159.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.002_0.9661_0.1222.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.004_0.9777_0.1090.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.007_0.9787_0.0875.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.009_0.9879_0.0517.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.019_0.9955_0.0284.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_128-imagenet128-16-fc12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_128-imagenet128-16-fc12.csv',\n",
      " 'model.mobilenetv2_1.00_128-imagenet128-16-fc12.h5',\n",
      " 'weights.mobilenetv2_1.00_128-imagenet128-16-fc12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_128-imagenet128-16-fc12\n",
    "model_13 = consecutiveModelTraining(\n",
    "    input_size=128,\n",
    "    batch_size=16,\n",
    "    weights='imagenet',\n",
    "    dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc2af03-b0c5-49d4-afdb-93672c857ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T21:13:32.460208Z",
     "iopub.status.busy": "2021-06-10T21:13:32.460208Z",
     "iopub.status.idle": "2021-06-10T21:13:32.537208Z",
     "shell.execute_reply": "2021-06-10T21:13:32.536207Z",
     "shell.execute_reply.started": "2021-06-10T21:13:32.460208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.366156</td>\n",
       "      <td>0.898122</td>\n",
       "      <td>0.956537</td>\n",
       "      <td>0.991593</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.958711</td>\n",
       "      <td>0.868598</td>\n",
       "      <td>7879.920000</td>\n",
       "      <td>99456.660000</td>\n",
       "      <td>335.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978535</td>\n",
       "      <td>0.993588</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.995232</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.969177</td>\n",
       "      <td>5861.58000</td>\n",
       "      <td>66472.040000</td>\n",
       "      <td>55.960000</td>\n",
       "      <td>186.42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104098</td>\n",
       "      <td>0.031320</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.040095</td>\n",
       "      <td>363.737898</td>\n",
       "      <td>167.627577</td>\n",
       "      <td>167.627577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.020777</td>\n",
       "      <td>125.66088</td>\n",
       "      <td>52.837433</td>\n",
       "      <td>52.837433</td>\n",
       "      <td>125.66088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.239665</td>\n",
       "      <td>0.716711</td>\n",
       "      <td>0.892196</td>\n",
       "      <td>0.958298</td>\n",
       "      <td>0.811982</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>0.638338</td>\n",
       "      <td>5791.000000</td>\n",
       "      <td>98704.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924438</td>\n",
       "      <td>0.963955</td>\n",
       "      <td>0.990778</td>\n",
       "      <td>0.966255</td>\n",
       "      <td>0.956552</td>\n",
       "      <td>0.890212</td>\n",
       "      <td>5384.00000</td>\n",
       "      <td>66279.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.893546</td>\n",
       "      <td>0.953180</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.956638</td>\n",
       "      <td>0.952694</td>\n",
       "      <td>0.864804</td>\n",
       "      <td>7845.500000</td>\n",
       "      <td>99405.500000</td>\n",
       "      <td>229.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973752</td>\n",
       "      <td>0.992601</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.994808</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>0.961682</td>\n",
       "      <td>5816.25000</td>\n",
       "      <td>66465.250000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>103.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.336975</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.958995</td>\n",
       "      <td>0.993344</td>\n",
       "      <td>0.966350</td>\n",
       "      <td>0.965901</td>\n",
       "      <td>0.879905</td>\n",
       "      <td>7982.500000</td>\n",
       "      <td>99511.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983052</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>0.997096</td>\n",
       "      <td>0.992805</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>5901.00000</td>\n",
       "      <td>66485.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>147.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.397503</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.994017</td>\n",
       "      <td>0.970635</td>\n",
       "      <td>0.972280</td>\n",
       "      <td>0.887897</td>\n",
       "      <td>8055.000000</td>\n",
       "      <td>99562.500000</td>\n",
       "      <td>386.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987806</td>\n",
       "      <td>0.996197</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.998144</td>\n",
       "      <td>0.996623</td>\n",
       "      <td>0.982887</td>\n",
       "      <td>5944.50000</td>\n",
       "      <td>66508.000000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>231.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.933249</td>\n",
       "      <td>0.924272</td>\n",
       "      <td>0.970569</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.984328</td>\n",
       "      <td>0.900022</td>\n",
       "      <td>8165.000000</td>\n",
       "      <td>99662.000000</td>\n",
       "      <td>1088.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>0.998512</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.993717</td>\n",
       "      <td>6010.00000</td>\n",
       "      <td>66518.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>664.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.366156              0.898122   0.956537   0.991593   0.959142   \n",
       "std     0.104098              0.031320   0.011824   0.005509   0.024505   \n",
       "min     0.239665              0.716711   0.892196   0.958298   0.811982   \n",
       "25%     0.311537              0.893546   0.953180   0.990745   0.956638   \n",
       "50%     0.336975              0.907407   0.958995   0.993344   0.966350   \n",
       "75%     0.397503              0.914324   0.962963   0.994017   0.970635   \n",
       "max     0.933249              0.924272   0.970569   0.995600   0.977540   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.958711   0.868598  7879.920000  99456.660000   335.340000  ...   \n",
       "std     0.023122   0.040095   363.737898    167.627577   167.627577  ...   \n",
       "min     0.841837   0.638338  5791.000000  98704.000000   130.000000  ...   \n",
       "25%     0.952694   0.864804  7845.500000  99405.500000   229.500000  ...   \n",
       "50%     0.965901   0.879905  7982.500000  99511.000000   281.000000  ...   \n",
       "75%     0.972280   0.887897  8055.000000  99562.500000   386.500000  ...   \n",
       "max     0.984328   0.900022  8165.000000  99662.000000  1088.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.978535   0.993588     0.998941    0.995232   \n",
       "std                    0.014725   0.005045     0.001388    0.005533   \n",
       "min                    0.924438   0.963955     0.990778    0.966255   \n",
       "25%                    0.973752   0.992601     0.998960    0.994808   \n",
       "50%                    0.983052   0.994709     0.999311    0.997096   \n",
       "75%                    0.987806   0.996197     0.999577    0.998144   \n",
       "max                    0.995536   0.998512     0.999883    0.999445   \n",
       "\n",
       "       val_precision  val_recall      val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.00000     50.000000   50.000000   \n",
       "mean        0.990476    0.969177  5861.58000  66472.040000   55.960000   \n",
       "std         0.009150    0.020777   125.66088     52.837433   52.837433   \n",
       "min         0.956552    0.890212  5384.00000  66279.000000   10.000000   \n",
       "25%         0.989407    0.961682  5816.25000  66465.250000   20.000000   \n",
       "50%         0.992805    0.975694  5901.00000  66485.000000   43.000000   \n",
       "75%         0.996623    0.982887  5944.50000  66508.000000   62.750000   \n",
       "max         0.998326    0.993717  6010.00000  66518.000000  249.000000   \n",
       "\n",
       "          val_FN  \n",
       "count   50.00000  \n",
       "mean   186.42000  \n",
       "std    125.66088  \n",
       "min     38.00000  \n",
       "25%    103.50000  \n",
       "50%    147.00000  \n",
       "75%    231.75000  \n",
       "max    664.00000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_13['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566bd85-0ace-47c6-8e80-3f221a2b5ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b83e81-b336-4e7a-b6ad-15e4d1066abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T10:11:09.914866Z",
     "iopub.status.busy": "2021-06-10T10:11:09.914866Z",
     "iopub.status.idle": "2021-06-10T12:15:27.242760Z",
     "shell.execute_reply": "2021-06-10T12:15:27.241765Z",
     "shell.execute_reply.started": "2021-06-10T10:11:09.914866Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_32-16-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_32-16-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_32 (Functio (None, 1, 1, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 2,239,244\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_32-16-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_32-16-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_32-16-12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 54:47 - loss: 5.0253 - categorical_accuracy: 0.1875 - top-3: 0.2500 - ROC-AUC: 0.4945 - PR-AUC: 0.0850 - precision: 0.0667 - recall: 0.0312 - TP: 1.0000 - TN: 338.0000 - FP: 14.0000 - FN: 31.0000        WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1790s vs `on_train_batch_end` time: 11.4539s). Check your callbacks.\n",
      "567/567 [==============================] - 164s 290ms/step - loss: 2.9443 - categorical_accuracy: 0.1464 - top-3: 0.3934 - ROC-AUC: 0.6375 - PR-AUC: 0.1351 - precision: 0.2350 - recall: 0.0238 - TP: 216.0000 - TN: 99089.0000 - FP: 703.0000 - FN: 8856.0000 - val_loss: 2.2150 - val_categorical_accuracy: 0.2169 - val_top-3: 0.5071 - val_ROC-AUC: 0.7374 - val_PR-AUC: 0.2064 - val_precision: 0.3005 - val_recall: 0.0212 - val_TP: 128.0000 - val_TN: 66230.0000 - val_FP: 298.0000 - val_FN: 5920.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 1.9152 - categorical_accuracy: 0.2701 - top-3: 0.6281 - ROC-AUC: 0.8107 - PR-AUC: 0.2802 - precision: 0.5343 - recall: 0.0746 - TP: 677.0000 - TN: 99202.0000 - FP: 590.0000 - FN: 8395.0000 - val_loss: 1.7579 - val_categorical_accuracy: 0.2989 - val_top-3: 0.6860 - val_ROC-AUC: 0.8458 - val_PR-AUC: 0.3179 - val_precision: 0.5347 - val_recall: 0.1007 - val_TP: 609.0000 - val_TN: 65998.0000 - val_FP: 530.0000 - val_FN: 5439.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 1.4124 - categorical_accuracy: 0.4635 - top-3: 0.8022 - ROC-AUC: 0.9055 - PR-AUC: 0.5415 - precision: 0.7231 - recall: 0.2842 - TP: 2578.0000 - TN: 98805.0000 - FP: 987.0000 - FN: 6494.0000 - val_loss: 1.0011 - val_categorical_accuracy: 0.6106 - val_top-3: 0.9211 - val_ROC-AUC: 0.9541 - val_PR-AUC: 0.7123 - val_precision: 0.7273 - val_recall: 0.4560 - val_TP: 2758.0000 - val_TN: 65494.0000 - val_FP: 1034.0000 - val_FN: 3290.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 147s 260ms/step - loss: 1.0137 - categorical_accuracy: 0.6378 - top-3: 0.9205 - ROC-AUC: 0.9509 - PR-AUC: 0.7215 - precision: 0.7489 - recall: 0.5023 - TP: 4557.0000 - TN: 98264.0000 - FP: 1528.0000 - FN: 4515.0000 - val_loss: 0.8713 - val_categorical_accuracy: 0.7111 - val_top-3: 0.9296 - val_ROC-AUC: 0.9632 - val_PR-AUC: 0.7924 - val_precision: 0.8058 - val_recall: 0.6045 - val_TP: 3656.0000 - val_TN: 65647.0000 - val_FP: 881.0000 - val_FN: 2392.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 149s 263ms/step - loss: 0.7699 - categorical_accuracy: 0.7353 - top-3: 0.9586 - ROC-AUC: 0.9697 - PR-AUC: 0.8145 - precision: 0.7938 - recall: 0.6604 - TP: 5991.0000 - TN: 98236.0000 - FP: 1556.0000 - FN: 3081.0000 - val_loss: 0.6489 - val_categorical_accuracy: 0.7728 - val_top-3: 0.9711 - val_ROC-AUC: 0.9792 - val_PR-AUC: 0.8576 - val_precision: 0.8125 - val_recall: 0.7229 - val_TP: 4372.0000 - val_TN: 65519.0000 - val_FP: 1009.0000 - val_FN: 1676.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 0.5825 - categorical_accuracy: 0.8122 - top-3: 0.9707 - ROC-AUC: 0.9803 - PR-AUC: 0.8862 - precision: 0.8489 - recall: 0.7763 - TP: 7043.0000 - TN: 98538.0000 - FP: 1254.0000 - FN: 2029.0000 - val_loss: 0.5244 - val_categorical_accuracy: 0.8406 - val_top-3: 0.9772 - val_ROC-AUC: 0.9825 - val_PR-AUC: 0.8966 - val_precision: 0.8654 - val_recall: 0.8145 - val_TP: 4926.0000 - val_TN: 65762.0000 - val_FP: 766.0000 - val_FN: 1122.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 145s 255ms/step - loss: 0.4461 - categorical_accuracy: 0.8681 - top-3: 0.9770 - ROC-AUC: 0.9868 - PR-AUC: 0.9280 - precision: 0.8967 - recall: 0.8423 - TP: 7641.0000 - TN: 98912.0000 - FP: 880.0000 - FN: 1431.0000 - val_loss: 0.2764 - val_categorical_accuracy: 0.9168 - val_top-3: 0.9854 - val_ROC-AUC: 0.9943 - val_PR-AUC: 0.9703 - val_precision: 0.9362 - val_recall: 0.8973 - val_TP: 5427.0000 - val_TN: 66158.0000 - val_FP: 370.0000 - val_FN: 621.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 0.3824 - categorical_accuracy: 0.8969 - top-3: 0.9803 - ROC-AUC: 0.9880 - PR-AUC: 0.9443 - precision: 0.9179 - recall: 0.8751 - TP: 7939.0000 - TN: 99082.0000 - FP: 710.0000 - FN: 1133.0000 - val_loss: 0.2693 - val_categorical_accuracy: 0.9233 - val_top-3: 0.9858 - val_ROC-AUC: 0.9936 - val_PR-AUC: 0.9686 - val_precision: 0.9382 - val_recall: 0.9105 - val_TP: 5507.0000 - val_TN: 66165.0000 - val_FP: 363.0000 - val_FN: 541.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 145s 255ms/step - loss: 0.2912 - categorical_accuracy: 0.9170 - top-3: 0.9854 - ROC-AUC: 0.9927 - PR-AUC: 0.9638 - precision: 0.9354 - recall: 0.9016 - TP: 8179.0000 - TN: 99227.0000 - FP: 565.0000 - FN: 893.0000 - val_loss: 0.2075 - val_categorical_accuracy: 0.9423 - val_top-3: 0.9906 - val_ROC-AUC: 0.9948 - val_PR-AUC: 0.9783 - val_precision: 0.9525 - val_recall: 0.9311 - val_TP: 5631.0000 - val_TN: 66247.0000 - val_FP: 281.0000 - val_FN: 417.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.2870 - categorical_accuracy: 0.9214 - top-3: 0.9857 - ROC-AUC: 0.9921 - PR-AUC: 0.9641 - precision: 0.9366 - recall: 0.9075 - TP: 8233.0000 - TN: 99235.0000 - FP: 557.0000 - FN: 839.0000 - val_loss: 0.1724 - val_categorical_accuracy: 0.9539 - val_top-3: 0.9922 - val_ROC-AUC: 0.9967 - val_PR-AUC: 0.9844 - val_precision: 0.9661 - val_recall: 0.9435 - val_TP: 5706.0000 - val_TN: 66328.0000 - val_FP: 200.0000 - val_FN: 342.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 145s 255ms/step - loss: 0.2109 - categorical_accuracy: 0.9417 - top-3: 0.9896 - ROC-AUC: 0.9950 - PR-AUC: 0.9784 - precision: 0.9527 - recall: 0.9322 - TP: 8457.0000 - TN: 99372.0000 - FP: 420.0000 - FN: 615.0000 - val_loss: 0.1417 - val_categorical_accuracy: 0.9623 - val_top-3: 0.9969 - val_ROC-AUC: 0.9976 - val_PR-AUC: 0.9883 - val_precision: 0.9724 - val_recall: 0.9511 - val_TP: 5752.0000 - val_TN: 66365.0000 - val_FP: 163.0000 - val_FN: 296.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.2299 - categorical_accuracy: 0.9392 - top-3: 0.9877 - ROC-AUC: 0.9946 - PR-AUC: 0.9759 - precision: 0.9514 - recall: 0.9281 - TP: 8420.0000 - TN: 99362.0000 - FP: 430.0000 - FN: 652.0000 - val_loss: 0.1649 - val_categorical_accuracy: 0.9582 - val_top-3: 0.9921 - val_ROC-AUC: 0.9966 - val_PR-AUC: 0.9861 - val_precision: 0.9690 - val_recall: 0.9456 - val_TP: 5719.0000 - val_TN: 66345.0000 - val_FP: 183.0000 - val_FN: 329.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 144s 254ms/step - loss: 0.2099 - categorical_accuracy: 0.9465 - top-3: 0.9907 - ROC-AUC: 0.9945 - PR-AUC: 0.9767 - precision: 0.9573 - recall: 0.9369 - TP: 8500.0000 - TN: 99413.0000 - FP: 379.0000 - FN: 572.0000 - val_loss: 0.1917 - val_categorical_accuracy: 0.9435 - val_top-3: 0.9927 - val_ROC-AUC: 0.9962 - val_PR-AUC: 0.9805 - val_precision: 0.9516 - val_recall: 0.9337 - val_TP: 5647.0000 - val_TN: 66241.0000 - val_FP: 287.0000 - val_FN: 401.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 146s 257ms/step - loss: 0.1950 - categorical_accuracy: 0.9469 - top-3: 0.9906 - ROC-AUC: 0.9953 - PR-AUC: 0.9805 - precision: 0.9587 - recall: 0.9381 - TP: 8510.0000 - TN: 99425.0000 - FP: 367.0000 - FN: 562.0000 - val_loss: 0.2026 - val_categorical_accuracy: 0.9469 - val_top-3: 0.9931 - val_ROC-AUC: 0.9939 - val_PR-AUC: 0.9749 - val_precision: 0.9541 - val_recall: 0.9415 - val_TP: 5694.0000 - val_TN: 66254.0000 - val_FP: 274.0000 - val_FN: 354.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.1504 - categorical_accuracy: 0.9606 - top-3: 0.9939 - ROC-AUC: 0.9966 - PR-AUC: 0.9865 - precision: 0.9675 - recall: 0.9555 - TP: 8668.0000 - TN: 99501.0000 - FP: 291.0000 - FN: 404.0000 - val_loss: 0.3794 - val_categorical_accuracy: 0.9101 - val_top-3: 0.9873 - val_ROC-AUC: 0.9863 - val_PR-AUC: 0.9457 - val_precision: 0.9164 - val_recall: 0.9046 - val_TP: 5471.0000 - val_TN: 66029.0000 - val_FP: 499.0000 - val_FN: 577.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.1607 - categorical_accuracy: 0.9555 - top-3: 0.9915 - ROC-AUC: 0.9960 - PR-AUC: 0.9854 - precision: 0.9649 - recall: 0.9495 - TP: 8614.0000 - TN: 99479.0000 - FP: 313.0000 - FN: 458.0000 - val_loss: 0.1554 - val_categorical_accuracy: 0.9631 - val_top-3: 0.9939 - val_ROC-AUC: 0.9952 - val_PR-AUC: 0.9854 - val_precision: 0.9690 - val_recall: 0.9603 - val_TP: 5808.0000 - val_TN: 66342.0000 - val_FP: 186.0000 - val_FN: 240.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 145s 257ms/step - loss: 0.1392 - categorical_accuracy: 0.9621 - top-3: 0.9942 - ROC-AUC: 0.9969 - PR-AUC: 0.9876 - precision: 0.9687 - recall: 0.9575 - TP: 8686.0000 - TN: 99511.0000 - FP: 281.0000 - FN: 386.0000 - val_loss: 0.0822 - val_categorical_accuracy: 0.9777 - val_top-3: 0.9969 - val_ROC-AUC: 0.9984 - val_PR-AUC: 0.9947 - val_precision: 0.9804 - val_recall: 0.9757 - val_TP: 5901.0000 - val_TN: 66410.0000 - val_FP: 118.0000 - val_FN: 147.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.1101 - categorical_accuracy: 0.9727 - top-3: 0.9965 - ROC-AUC: 0.9974 - PR-AUC: 0.9910 - precision: 0.9776 - recall: 0.9669 - TP: 8772.0000 - TN: 99591.0000 - FP: 201.0000 - FN: 300.0000 - val_loss: 0.0784 - val_categorical_accuracy: 0.9767 - val_top-3: 0.9965 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9949 - val_precision: 0.9820 - val_recall: 0.9740 - val_TP: 5891.0000 - val_TN: 66420.0000 - val_FP: 108.0000 - val_FN: 157.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 145s 255ms/step - loss: 0.1182 - categorical_accuracy: 0.9696 - top-3: 0.9959 - ROC-AUC: 0.9973 - PR-AUC: 0.9903 - precision: 0.9752 - recall: 0.9653 - TP: 8757.0000 - TN: 99569.0000 - FP: 223.0000 - FN: 315.0000 - val_loss: 0.0987 - val_categorical_accuracy: 0.9712 - val_top-3: 0.9965 - val_ROC-AUC: 0.9983 - val_PR-AUC: 0.9927 - val_precision: 0.9760 - val_recall: 0.9684 - val_TP: 5857.0000 - val_TN: 66384.0000 - val_FP: 144.0000 - val_FN: 191.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 0.0929 - categorical_accuracy: 0.9743 - top-3: 0.9965 - ROC-AUC: 0.9985 - PR-AUC: 0.9942 - precision: 0.9787 - recall: 0.9708 - TP: 8807.0000 - TN: 99600.0000 - FP: 192.0000 - FN: 265.0000 - val_loss: 0.0540 - val_categorical_accuracy: 0.9841 - val_top-3: 0.9975 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9975 - val_precision: 0.9869 - val_recall: 0.9825 - val_TP: 5942.0000 - val_TN: 66449.0000 - val_FP: 79.0000 - val_FN: 106.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.1002 - categorical_accuracy: 0.9744 - top-3: 0.9969 - ROC-AUC: 0.9979 - PR-AUC: 0.9924 - precision: 0.9780 - recall: 0.9709 - TP: 8808.0000 - TN: 99594.0000 - FP: 198.0000 - FN: 264.0000 - val_loss: 0.0489 - val_categorical_accuracy: 0.9883 - val_top-3: 0.9983 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9969 - val_precision: 0.9900 - val_recall: 0.9863 - val_TP: 5965.0000 - val_TN: 66468.0000 - val_FP: 60.0000 - val_FN: 83.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 147s 258ms/step - loss: 0.0890 - categorical_accuracy: 0.9761 - top-3: 0.9964 - ROC-AUC: 0.9984 - PR-AUC: 0.9941 - precision: 0.9803 - recall: 0.9730 - TP: 8827.0000 - TN: 99615.0000 - FP: 177.0000 - FN: 245.0000 - val_loss: 0.0595 - val_categorical_accuracy: 0.9816 - val_top-3: 0.9983 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9962 - val_precision: 0.9834 - val_recall: 0.9802 - val_TP: 5928.0000 - val_TN: 66428.0000 - val_FP: 100.0000 - val_FN: 120.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.1392 - categorical_accuracy: 0.9666 - top-3: 0.9936 - ROC-AUC: 0.9967 - PR-AUC: 0.9877 - precision: 0.9719 - recall: 0.9620 - TP: 8727.0000 - TN: 99540.0000 - FP: 252.0000 - FN: 345.0000 - val_loss: 0.0630 - val_categorical_accuracy: 0.9818 - val_top-3: 0.9987 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9959 - val_precision: 0.9842 - val_recall: 0.9798 - val_TP: 5926.0000 - val_TN: 66433.0000 - val_FP: 95.0000 - val_FN: 122.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 167s 294ms/step - loss: 0.0790 - categorical_accuracy: 0.9796 - top-3: 0.9971 - ROC-AUC: 0.9983 - PR-AUC: 0.9945 - precision: 0.9823 - recall: 0.9766 - TP: 8860.0000 - TN: 99632.0000 - FP: 160.0000 - FN: 212.0000 - val_loss: 0.0497 - val_categorical_accuracy: 0.9859 - val_top-3: 0.9983 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9979 - val_precision: 0.9884 - val_recall: 0.9841 - val_TP: 5952.0000 - val_TN: 66458.0000 - val_FP: 70.0000 - val_FN: 96.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 165s 291ms/step - loss: 0.0947 - categorical_accuracy: 0.9756 - top-3: 0.9976 - ROC-AUC: 0.9982 - PR-AUC: 0.9928 - precision: 0.9787 - recall: 0.9729 - TP: 8826.0000 - TN: 99600.0000 - FP: 192.0000 - FN: 246.0000 - val_loss: 0.0723 - val_categorical_accuracy: 0.9790 - val_top-3: 0.9983 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9959 - val_precision: 0.9804 - val_recall: 0.9769 - val_TP: 5908.0000 - val_TN: 66410.0000 - val_FP: 118.0000 - val_FN: 140.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 168s 296ms/step - loss: 0.0597 - categorical_accuracy: 0.9839 - top-3: 0.9977 - ROC-AUC: 0.9989 - PR-AUC: 0.9966 - precision: 0.9863 - recall: 0.9825 - TP: 8913.0000 - TN: 99668.0000 - FP: 124.0000 - FN: 159.0000 - val_loss: 0.0281 - val_categorical_accuracy: 0.9919 - val_top-3: 0.9988 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9990 - val_precision: 0.9937 - val_recall: 0.9916 - val_TP: 5997.0000 - val_TN: 66490.0000 - val_FP: 38.0000 - val_FN: 51.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 150s 265ms/step - loss: 0.0656 - categorical_accuracy: 0.9835 - top-3: 0.9980 - ROC-AUC: 0.9982 - PR-AUC: 0.9945 - precision: 0.9854 - recall: 0.9809 - TP: 8899.0000 - TN: 99660.0000 - FP: 132.0000 - FN: 173.0000 - val_loss: 0.0324 - val_categorical_accuracy: 0.9917 - val_top-3: 0.9983 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9987 - val_precision: 0.9934 - val_recall: 0.9911 - val_TP: 5994.0000 - val_TN: 66488.0000 - val_FP: 40.0000 - val_FN: 54.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 148s 262ms/step - loss: 0.0670 - categorical_accuracy: 0.9826 - top-3: 0.9980 - ROC-AUC: 0.9987 - PR-AUC: 0.9959 - precision: 0.9858 - recall: 0.9813 - TP: 8902.0000 - TN: 99664.0000 - FP: 128.0000 - FN: 170.0000 - val_loss: 0.0483 - val_categorical_accuracy: 0.9881 - val_top-3: 0.9987 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9974 - val_precision: 0.9896 - val_recall: 0.9871 - val_TP: 5970.0000 - val_TN: 66465.0000 - val_FP: 63.0000 - val_FN: 78.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 151s 266ms/step - loss: 0.0562 - categorical_accuracy: 0.9856 - top-3: 0.9976 - ROC-AUC: 0.9986 - PR-AUC: 0.9959 - precision: 0.9887 - recall: 0.9835 - TP: 8922.0000 - TN: 99690.0000 - FP: 102.0000 - FN: 150.0000 - val_loss: 0.0318 - val_categorical_accuracy: 0.9909 - val_top-3: 0.9990 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9984 - val_precision: 0.9927 - val_recall: 0.9904 - val_TP: 5990.0000 - val_TN: 66484.0000 - val_FP: 44.0000 - val_FN: 58.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 150s 265ms/step - loss: 0.0744 - categorical_accuracy: 0.9798 - top-3: 0.9974 - ROC-AUC: 0.9985 - PR-AUC: 0.9950 - precision: 0.9827 - recall: 0.9774 - TP: 8867.0000 - TN: 99636.0000 - FP: 156.0000 - FN: 205.0000 - val_loss: 0.0375 - val_categorical_accuracy: 0.9888 - val_top-3: 0.9990 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9981 - val_precision: 0.9899 - val_recall: 0.9881 - val_TP: 5976.0000 - val_TN: 66467.0000 - val_FP: 61.0000 - val_FN: 72.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 150s 265ms/step - loss: 0.0578 - categorical_accuracy: 0.9856 - top-3: 0.9988 - ROC-AUC: 0.9987 - PR-AUC: 0.9958 - precision: 0.9876 - recall: 0.9839 - TP: 8926.0000 - TN: 99680.0000 - FP: 112.0000 - FN: 146.0000 - val_loss: 0.0434 - val_categorical_accuracy: 0.9909 - val_top-3: 0.9985 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9962 - val_precision: 0.9922 - val_recall: 0.9906 - val_TP: 5991.0000 - val_TN: 66481.0000 - val_FP: 47.0000 - val_FN: 57.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 150s 264ms/step - loss: 0.0714 - categorical_accuracy: 0.9829 - top-3: 0.9972 - ROC-AUC: 0.9983 - PR-AUC: 0.9955 - precision: 0.9847 - recall: 0.9813 - TP: 8902.0000 - TN: 99654.0000 - FP: 138.0000 - FN: 170.0000 - val_loss: 0.0328 - val_categorical_accuracy: 0.9907 - val_top-3: 0.9993 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9979 - val_precision: 0.9922 - val_recall: 0.9901 - val_TP: 5988.0000 - val_TN: 66481.0000 - val_FP: 47.0000 - val_FN: 60.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.0421 - categorical_accuracy: 0.9901 - top-3: 0.9993 - ROC-AUC: 0.9991 - PR-AUC: 0.9968 - precision: 0.9914 - recall: 0.9892 - TP: 8974.0000 - TN: 99714.0000 - FP: 78.0000 - FN: 98.0000 - val_loss: 0.0750 - val_categorical_accuracy: 0.9823 - val_top-3: 0.9983 - val_ROC-AUC: 0.9980 - val_PR-AUC: 0.9945 - val_precision: 0.9829 - val_recall: 0.9810 - val_TP: 5933.0000 - val_TN: 66425.0000 - val_FP: 103.0000 - val_FN: 115.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 145s 257ms/step - loss: 0.0450 - categorical_accuracy: 0.9884 - top-3: 0.9987 - ROC-AUC: 0.9992 - PR-AUC: 0.9975 - precision: 0.9903 - recall: 0.9867 - TP: 8951.0000 - TN: 99704.0000 - FP: 88.0000 - FN: 121.0000 - val_loss: 0.0653 - val_categorical_accuracy: 0.9808 - val_top-3: 0.9992 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9946 - val_precision: 0.9819 - val_recall: 0.9802 - val_TP: 5928.0000 - val_TN: 66419.0000 - val_FP: 109.0000 - val_FN: 120.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 0.0589 - categorical_accuracy: 0.9841 - top-3: 0.9979 - ROC-AUC: 0.9987 - PR-AUC: 0.9961 - precision: 0.9865 - recall: 0.9825 - TP: 8913.0000 - TN: 99670.0000 - FP: 122.0000 - FN: 159.0000 - val_loss: 0.0206 - val_categorical_accuracy: 0.9936 - val_top-3: 1.0000 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9994 - val_precision: 0.9942 - val_recall: 0.9927 - val_TP: 6004.0000 - val_TN: 66493.0000 - val_FP: 35.0000 - val_FN: 44.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 145s 255ms/step - loss: 0.0618 - categorical_accuracy: 0.9856 - top-3: 0.9975 - ROC-AUC: 0.9986 - PR-AUC: 0.9958 - precision: 0.9874 - recall: 0.9840 - TP: 8927.0000 - TN: 99678.0000 - FP: 114.0000 - FN: 145.0000 - val_loss: 0.1009 - val_categorical_accuracy: 0.9783 - val_top-3: 0.9983 - val_ROC-AUC: 0.9972 - val_PR-AUC: 0.9897 - val_precision: 0.9806 - val_recall: 0.9755 - val_TP: 5900.0000 - val_TN: 66411.0000 - val_FP: 117.0000 - val_FN: 148.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.0751 - categorical_accuracy: 0.9828 - top-3: 0.9976 - ROC-AUC: 0.9984 - PR-AUC: 0.9944 - precision: 0.9849 - recall: 0.9805 - TP: 8895.0000 - TN: 99656.0000 - FP: 136.0000 - FN: 177.0000 - val_loss: 0.0871 - val_categorical_accuracy: 0.9750 - val_top-3: 0.9977 - val_ROC-AUC: 0.9977 - val_PR-AUC: 0.9918 - val_precision: 0.9779 - val_recall: 0.9737 - val_TP: 5889.0000 - val_TN: 66395.0000 - val_FP: 133.0000 - val_FN: 159.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 0.0458 - categorical_accuracy: 0.9881 - top-3: 0.9987 - ROC-AUC: 0.9991 - PR-AUC: 0.9973 - precision: 0.9893 - recall: 0.9870 - TP: 8954.0000 - TN: 99695.0000 - FP: 97.0000 - FN: 118.0000 - val_loss: 0.0191 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9992 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9993 - val_precision: 0.9952 - val_recall: 0.9945 - val_TP: 6015.0000 - val_TN: 66499.0000 - val_FP: 29.0000 - val_FN: 33.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 0.0351 - categorical_accuracy: 0.9896 - top-3: 0.9988 - ROC-AUC: 0.9991 - PR-AUC: 0.9975 - precision: 0.9919 - recall: 0.9889 - TP: 8971.0000 - TN: 99719.0000 - FP: 73.0000 - FN: 101.0000 - val_loss: 0.0293 - val_categorical_accuracy: 0.9934 - val_top-3: 0.9982 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9985 - val_precision: 0.9937 - val_recall: 0.9929 - val_TP: 6005.0000 - val_TN: 66490.0000 - val_FP: 38.0000 - val_FN: 43.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.0363 - categorical_accuracy: 0.9910 - top-3: 0.9992 - ROC-AUC: 0.9994 - PR-AUC: 0.9979 - precision: 0.9919 - recall: 0.9906 - TP: 8987.0000 - TN: 99719.0000 - FP: 73.0000 - FN: 85.0000 - val_loss: 0.0467 - val_categorical_accuracy: 0.9899 - val_top-3: 0.9988 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9973 - val_precision: 0.9907 - val_recall: 0.9893 - val_TP: 5983.0000 - val_TN: 66472.0000 - val_FP: 56.0000 - val_FN: 65.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.0372 - categorical_accuracy: 0.9892 - top-3: 0.9990 - ROC-AUC: 0.9994 - PR-AUC: 0.9981 - precision: 0.9909 - recall: 0.9889 - TP: 8971.0000 - TN: 99710.0000 - FP: 82.0000 - FN: 101.0000 - val_loss: 0.0560 - val_categorical_accuracy: 0.9854 - val_top-3: 0.9975 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9967 - val_precision: 0.9880 - val_recall: 0.9841 - val_TP: 5952.0000 - val_TN: 66456.0000 - val_FP: 72.0000 - val_FN: 96.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 0.0441 - categorical_accuracy: 0.9878 - top-3: 0.9991 - ROC-AUC: 0.9991 - PR-AUC: 0.9973 - precision: 0.9893 - recall: 0.9863 - TP: 8948.0000 - TN: 99695.0000 - FP: 97.0000 - FN: 124.0000 - val_loss: 0.0261 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9987 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9989 - val_precision: 0.9937 - val_recall: 0.9924 - val_TP: 6002.0000 - val_TN: 66490.0000 - val_FP: 38.0000 - val_FN: 46.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 146s 257ms/step - loss: 0.0671 - categorical_accuracy: 0.9830 - top-3: 0.9979 - ROC-AUC: 0.9987 - PR-AUC: 0.9960 - precision: 0.9858 - recall: 0.9809 - TP: 8899.0000 - TN: 99664.0000 - FP: 128.0000 - FN: 173.0000 - val_loss: 0.0213 - val_categorical_accuracy: 0.9937 - val_top-3: 0.9997 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9992 - val_precision: 0.9947 - val_recall: 0.9926 - val_TP: 6003.0000 - val_TN: 66496.0000 - val_FP: 32.0000 - val_FN: 45.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.0289 - categorical_accuracy: 0.9924 - top-3: 0.9993 - ROC-AUC: 0.9996 - PR-AUC: 0.9988 - precision: 0.9932 - recall: 0.9915 - TP: 8995.0000 - TN: 99730.0000 - FP: 62.0000 - FN: 77.0000 - val_loss: 0.0394 - val_categorical_accuracy: 0.9894 - val_top-3: 0.9987 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9975 - val_precision: 0.9919 - val_recall: 0.9886 - val_TP: 5979.0000 - val_TN: 66479.0000 - val_FP: 49.0000 - val_FN: 69.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 148s 260ms/step - loss: 0.0466 - categorical_accuracy: 0.9884 - top-3: 0.9983 - ROC-AUC: 0.9989 - PR-AUC: 0.9970 - precision: 0.9898 - recall: 0.9878 - TP: 8961.0000 - TN: 99700.0000 - FP: 92.0000 - FN: 111.0000 - val_loss: 0.0185 - val_categorical_accuracy: 0.9954 - val_top-3: 0.9997 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9988 - val_precision: 0.9955 - val_recall: 0.9949 - val_TP: 6017.0000 - val_TN: 66501.0000 - val_FP: 27.0000 - val_FN: 31.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 147s 259ms/step - loss: 0.0376 - categorical_accuracy: 0.9923 - top-3: 0.9992 - ROC-AUC: 0.9993 - PR-AUC: 0.9976 - precision: 0.9930 - recall: 0.9914 - TP: 8994.0000 - TN: 99729.0000 - FP: 63.0000 - FN: 78.0000 - val_loss: 0.0208 - val_categorical_accuracy: 0.9939 - val_top-3: 0.9998 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9995 - val_precision: 0.9944 - val_recall: 0.9937 - val_TP: 6010.0000 - val_TN: 66494.0000 - val_FP: 34.0000 - val_FN: 38.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 148s 261ms/step - loss: 0.0302 - categorical_accuracy: 0.9933 - top-3: 0.9993 - ROC-AUC: 0.9993 - PR-AUC: 0.9981 - precision: 0.9937 - recall: 0.9929 - TP: 9008.0000 - TN: 99735.0000 - FP: 57.0000 - FN: 64.0000 - val_loss: 0.0446 - val_categorical_accuracy: 0.9876 - val_top-3: 0.9993 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9972 - val_precision: 0.9882 - val_recall: 0.9868 - val_TP: 5968.0000 - val_TN: 66457.0000 - val_FP: 71.0000 - val_FN: 80.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.0449 - categorical_accuracy: 0.9880 - top-3: 0.9989 - ROC-AUC: 0.9990 - PR-AUC: 0.9968 - precision: 0.9894 - recall: 0.9873 - TP: 8957.0000 - TN: 99696.0000 - FP: 96.0000 - FN: 115.0000 - val_loss: 0.0472 - val_categorical_accuracy: 0.9873 - val_top-3: 0.9987 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9963 - val_precision: 0.9892 - val_recall: 0.9864 - val_TP: 5966.0000 - val_TN: 66463.0000 - val_FP: 65.0000 - val_FN: 82.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 145s 256ms/step - loss: 0.0468 - categorical_accuracy: 0.9878 - top-3: 0.9987 - ROC-AUC: 0.9990 - PR-AUC: 0.9966 - precision: 0.9892 - recall: 0.9867 - TP: 8951.0000 - TN: 99694.0000 - FP: 98.0000 - FN: 121.0000 - val_loss: 0.0186 - val_categorical_accuracy: 0.9954 - val_top-3: 0.9997 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9989 - val_precision: 0.9960 - val_recall: 0.9945 - val_TP: 6015.0000 - val_TN: 66504.0000 - val_FP: 24.0000 - val_FN: 33.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 146s 258ms/step - loss: 0.0487 - categorical_accuracy: 0.9895 - top-3: 0.9990 - ROC-AUC: 0.9987 - PR-AUC: 0.9961 - precision: 0.9906 - recall: 0.9888 - TP: 8970.0000 - TN: 99707.0000 - FP: 85.0000 - FN: 102.0000 - val_loss: 0.0756 - val_categorical_accuracy: 0.9802 - val_top-3: 0.9985 - val_ROC-AUC: 0.9977 - val_PR-AUC: 0.9923 - val_precision: 0.9813 - val_recall: 0.9797 - val_TP: 5925.0000 - val_TN: 66415.0000 - val_FP: 113.0000 - val_FN: 123.0000\n",
      "-----\n",
      "(7452713.55 ms) == (124m:12s)\n",
      "-----\n",
      "\n",
      "\n",
      "31\n",
      "['mobilenetv2_1.00_32-16-12.tensorboard',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.001_0.2169_2.2150.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.002_0.2989_1.7579.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.003_0.6106_1.0011.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.004_0.7111_0.8713.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.005_0.7728_0.6489.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.006_0.8406_0.5244.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.007_0.9168_0.2764.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.008_0.9233_0.2693.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.009_0.9423_0.2075.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.010_0.9539_0.1724.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.011_0.9623_0.1417.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.016_0.9631_0.1554.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.017_0.9777_0.0822.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.018_0.9767_0.0784.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.020_0.9841_0.0540.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.021_0.9883_0.0489.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.026_0.9919_0.0281.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.035_0.9936_0.0206.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.038_0.9945_0.0191.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.045_0.9954_0.0185.hdf5',\n",
      " 'mobilenetv2_1.00_32-16-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_32-16-12.csv',\n",
      " 'model.mobilenetv2_1.00_32-16-12.h5',\n",
      " 'weights.mobilenetv2_1.00_32-16-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_32-16-12\n",
    "model_5 = consecutiveModelTraining(\n",
    "    input_size=32,\n",
    "    batch_size=16,\n",
    "    weights=None,\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b6361a-e60f-4720-8aeb-5934009dca93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T12:15:27.243768Z",
     "iopub.status.busy": "2021-06-10T12:15:27.243768Z",
     "iopub.status.idle": "2021-06-10T12:15:27.321771Z",
     "shell.execute_reply": "2021-06-10T12:15:27.321771Z",
     "shell.execute_reply.started": "2021-06-10T12:15:27.243768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.268970</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.969436</td>\n",
       "      <td>0.982766</td>\n",
       "      <td>0.938048</td>\n",
       "      <td>0.936689</td>\n",
       "      <td>0.896936</td>\n",
       "      <td>8137.000000</td>\n",
       "      <td>99473.220000</td>\n",
       "      <td>318.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928393</td>\n",
       "      <td>0.977063</td>\n",
       "      <td>0.987454</td>\n",
       "      <td>0.948693</td>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.910982</td>\n",
       "      <td>5509.620000</td>\n",
       "      <td>66333.980000</td>\n",
       "      <td>194.020000</td>\n",
       "      <td>538.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.526670</td>\n",
       "      <td>0.174939</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.058148</td>\n",
       "      <td>0.170451</td>\n",
       "      <td>0.131785</td>\n",
       "      <td>0.216617</td>\n",
       "      <td>1965.151861</td>\n",
       "      <td>363.387143</td>\n",
       "      <td>363.387143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156797</td>\n",
       "      <td>0.081915</td>\n",
       "      <td>0.042740</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.123135</td>\n",
       "      <td>0.201692</td>\n",
       "      <td>1219.831937</td>\n",
       "      <td>248.775162</td>\n",
       "      <td>248.775162</td>\n",
       "      <td>1219.831937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.146384</td>\n",
       "      <td>0.393408</td>\n",
       "      <td>0.637517</td>\n",
       "      <td>0.135074</td>\n",
       "      <td>0.235038</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>98236.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216931</td>\n",
       "      <td>0.507110</td>\n",
       "      <td>0.737408</td>\n",
       "      <td>0.206371</td>\n",
       "      <td>0.300469</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>65494.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.047280</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>0.990658</td>\n",
       "      <td>0.995089</td>\n",
       "      <td>0.978937</td>\n",
       "      <td>0.957651</td>\n",
       "      <td>0.937224</td>\n",
       "      <td>8502.500000</td>\n",
       "      <td>99416.000000</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954944</td>\n",
       "      <td>0.992808</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>0.984651</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.943990</td>\n",
       "      <td>5709.250000</td>\n",
       "      <td>66331.500000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>61.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.077058</td>\n",
       "      <td>0.979718</td>\n",
       "      <td>0.997299</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>0.982486</td>\n",
       "      <td>0.977017</td>\n",
       "      <td>8863.500000</td>\n",
       "      <td>99634.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981730</td>\n",
       "      <td>0.998347</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.995921</td>\n",
       "      <td>0.983173</td>\n",
       "      <td>0.980159</td>\n",
       "      <td>5928.000000</td>\n",
       "      <td>66426.500000</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.206202</td>\n",
       "      <td>0.987765</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.996638</td>\n",
       "      <td>0.989249</td>\n",
       "      <td>0.986580</td>\n",
       "      <td>8950.250000</td>\n",
       "      <td>99694.750000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990534</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>5986.750000</td>\n",
       "      <td>66480.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>338.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.944268</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>0.992945</td>\n",
       "      <td>9008.000000</td>\n",
       "      <td>99735.000000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>0.996026</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>6017.000000</td>\n",
       "      <td>66504.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>5920.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.268970              0.915703   0.969436   0.982766   0.938048   \n",
       "std     0.526670              0.174939   0.101987   0.058148   0.170451   \n",
       "min     0.028907              0.146384   0.393408   0.637517   0.135074   \n",
       "25%     0.047280              0.946621   0.990658   0.995089   0.978937   \n",
       "50%     0.077058              0.979718   0.997299   0.998350   0.994425   \n",
       "75%     0.206202              0.987765   0.998677   0.998898   0.996638   \n",
       "max     2.944268              0.993276   0.999339   0.999570   0.998846   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.936689   0.896936  8137.000000  99473.220000   318.780000  ...   \n",
       "std     0.131785   0.216617  1965.151861    363.387143   363.387143  ...   \n",
       "min     0.235038   0.023810   216.000000  98236.000000    57.000000  ...   \n",
       "25%     0.957651   0.937224  8502.500000  99416.000000    97.250000  ...   \n",
       "50%     0.982486   0.977017  8863.500000  99634.000000   158.000000  ...   \n",
       "75%     0.989249   0.986580  8950.250000  99694.750000   376.000000  ...   \n",
       "max     0.993712   0.992945  9008.000000  99735.000000  1556.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.928393   0.977063     0.987454    0.948693   \n",
       "std                    0.156797   0.081915     0.042740    0.151721   \n",
       "min                    0.216931   0.507110     0.737408    0.206371   \n",
       "25%                    0.954944   0.992808     0.996331    0.984651   \n",
       "50%                    0.981730   0.998347     0.998643    0.995921   \n",
       "75%                    0.990534   0.998801     0.999340    0.997927   \n",
       "max                    0.995370   1.000000     0.999892    0.999517   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN       val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000    50.000000   \n",
       "mean        0.943546    0.910982  5509.620000  66333.980000   194.020000   \n",
       "std         0.123135    0.201692  1219.831937    248.775162   248.775162   \n",
       "min         0.300469    0.021164   128.000000  65494.000000    24.000000   \n",
       "25%         0.966844    0.943990  5709.250000  66331.500000    47.500000   \n",
       "50%         0.983173    0.980159  5928.000000  66426.500000   101.500000   \n",
       "75%         0.992127    0.989873  5986.750000  66480.500000   196.500000   \n",
       "max         0.996026    0.994874  6017.000000  66504.000000  1034.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean    538.380000  \n",
       "std    1219.831937  \n",
       "min      31.000000  \n",
       "25%      61.250000  \n",
       "50%     120.000000  \n",
       "75%     338.750000  \n",
       "max    5920.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2befcee-8908-4dc6-b98b-05ecdb54d1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dafeaf9-c920-4e6e-8cc5-6fa35aa86172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T15:36:03.798765Z",
     "iopub.status.busy": "2021-06-09T15:36:03.798765Z",
     "iopub.status.idle": "2021-06-09T17:25:04.792791Z",
     "shell.execute_reply": "2021-06-09T17:25:04.791793Z",
     "shell.execute_reply.started": "2021-06-09T15:36:03.798765Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "mobilenetv2_1.00_32-imagenet224-32-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_32-imagenet224-32-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 1, 1, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 15,372\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 32,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 283,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 189}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_32-imagenet224-32-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_32-imagenet224-32-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_32-imagenet224-32-12\n",
      "Epoch 1/50\n",
      "  1/283 [..............................] - ETA: 0s - loss: 2.5255 - categorical_accuracy: 0.1250 - top-3: 0.5625 - ROC-AUC: 0.4426 - PR-AUC: 0.0717 - precision: 0.0000e+00 - recall: 0.0000e+00 - TP: 0.0000e+00 - TN: 352.0000 - FP: 0.0000e+00 - FN: 32.0000WARNING:tensorflow:From X:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "283/283 [==============================] - 133s 470ms/step - loss: 2.1577 - categorical_accuracy: 0.2658 - top-3: 0.4962 - ROC-AUC: 0.7207 - PR-AUC: 0.2795 - precision: 0.8285 - recall: 0.0636 - TP: 575.0000 - TN: 99321.0000 - FP: 119.0000 - FN: 8465.0000 - val_loss: 2.1470 - val_categorical_accuracy: 0.2502 - val_top-3: 0.4783 - val_ROC-AUC: 0.7101 - val_PR-AUC: 0.2886 - val_precision: 0.8692 - val_recall: 0.0802 - val_TP: 485.0000 - val_TN: 66455.0000 - val_FP: 73.0000 - val_FN: 5563.0000\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 130s 458ms/step - loss: 2.0407 - categorical_accuracy: 0.2894 - top-3: 0.5334 - ROC-AUC: 0.7548 - PR-AUC: 0.3261 - precision: 0.7692 - recall: 0.1132 - TP: 1023.0000 - TN: 99133.0000 - FP: 307.0000 - FN: 8017.0000 - val_loss: 2.1322 - val_categorical_accuracy: 0.2674 - val_top-3: 0.4772 - val_ROC-AUC: 0.7112 - val_PR-AUC: 0.2968 - val_precision: 0.8660 - val_recall: 0.0919 - val_TP: 556.0000 - val_TN: 66442.0000 - val_FP: 86.0000 - val_FN: 5492.0000\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 131s 461ms/step - loss: 2.0272 - categorical_accuracy: 0.3003 - top-3: 0.5372 - ROC-AUC: 0.7585 - PR-AUC: 0.3324 - precision: 0.7383 - recall: 0.1236 - TP: 1117.0000 - TN: 99044.0000 - FP: 396.0000 - FN: 7923.0000 - val_loss: 2.0992 - val_categorical_accuracy: 0.2708 - val_top-3: 0.4916 - val_ROC-AUC: 0.7208 - val_PR-AUC: 0.3098 - val_precision: 0.8684 - val_recall: 0.1004 - val_TP: 607.0000 - val_TN: 66436.0000 - val_FP: 92.0000 - val_FN: 5441.0000\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 133s 470ms/step - loss: 2.0154 - categorical_accuracy: 0.3009 - top-3: 0.5410 - ROC-AUC: 0.7629 - PR-AUC: 0.3327 - precision: 0.7324 - recall: 0.1244 - TP: 1125.0000 - TN: 99029.0000 - FP: 411.0000 - FN: 7915.0000 - val_loss: 2.1214 - val_categorical_accuracy: 0.2546 - val_top-3: 0.4729 - val_ROC-AUC: 0.7128 - val_PR-AUC: 0.2937 - val_precision: 0.8416 - val_recall: 0.0957 - val_TP: 579.0000 - val_TN: 66419.0000 - val_FP: 109.0000 - val_FN: 5469.0000\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 133s 471ms/step - loss: 2.0060 - categorical_accuracy: 0.3077 - top-3: 0.5441 - ROC-AUC: 0.7643 - PR-AUC: 0.3436 - precision: 0.7436 - recall: 0.1347 - TP: 1218.0000 - TN: 99020.0000 - FP: 420.0000 - FN: 7822.0000 - val_loss: 2.1101 - val_categorical_accuracy: 0.2736 - val_top-3: 0.4912 - val_ROC-AUC: 0.7186 - val_PR-AUC: 0.3050 - val_precision: 0.8286 - val_recall: 0.1055 - val_TP: 638.0000 - val_TN: 66396.0000 - val_FP: 132.0000 - val_FN: 5410.0000\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 134s 475ms/step - loss: 2.0027 - categorical_accuracy: 0.3129 - top-3: 0.5454 - ROC-AUC: 0.7646 - PR-AUC: 0.3426 - precision: 0.7294 - recall: 0.1368 - TP: 1237.0000 - TN: 98981.0000 - FP: 459.0000 - FN: 7803.0000 - val_loss: 2.0891 - val_categorical_accuracy: 0.2745 - val_top-3: 0.4800 - val_ROC-AUC: 0.7233 - val_PR-AUC: 0.3098 - val_precision: 0.8296 - val_recall: 0.1055 - val_TP: 638.0000 - val_TN: 66397.0000 - val_FP: 131.0000 - val_FN: 5410.0000\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 129s 455ms/step - loss: 1.9974 - categorical_accuracy: 0.3128 - top-3: 0.5450 - ROC-AUC: 0.7661 - PR-AUC: 0.3488 - precision: 0.7392 - recall: 0.1433 - TP: 1295.0000 - TN: 98983.0000 - FP: 457.0000 - FN: 7745.0000 - val_loss: 2.0711 - val_categorical_accuracy: 0.2768 - val_top-3: 0.4921 - val_ROC-AUC: 0.7286 - val_PR-AUC: 0.3232 - val_precision: 0.8641 - val_recall: 0.1146 - val_TP: 693.0000 - val_TN: 66419.0000 - val_FP: 109.0000 - val_FN: 5355.0000\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 129s 454ms/step - loss: 1.9972 - categorical_accuracy: 0.3156 - top-3: 0.5496 - ROC-AUC: 0.7654 - PR-AUC: 0.3485 - precision: 0.7423 - recall: 0.1437 - TP: 1299.0000 - TN: 98989.0000 - FP: 451.0000 - FN: 7741.0000 - val_loss: 2.0937 - val_categorical_accuracy: 0.2758 - val_top-3: 0.4838 - val_ROC-AUC: 0.7195 - val_PR-AUC: 0.3099 - val_precision: 0.8476 - val_recall: 0.1066 - val_TP: 645.0000 - val_TN: 66412.0000 - val_FP: 116.0000 - val_FN: 5403.0000\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 126s 445ms/step - loss: 2.0062 - categorical_accuracy: 0.3064 - top-3: 0.5375 - ROC-AUC: 0.7627 - PR-AUC: 0.3438 - precision: 0.7363 - recall: 0.1424 - TP: 1287.0000 - TN: 98979.0000 - FP: 461.0000 - FN: 7753.0000 - val_loss: 2.1025 - val_categorical_accuracy: 0.2722 - val_top-3: 0.4790 - val_ROC-AUC: 0.7186 - val_PR-AUC: 0.3050 - val_precision: 0.8253 - val_recall: 0.1078 - val_TP: 652.0000 - val_TN: 66390.0000 - val_FP: 138.0000 - val_FN: 5396.0000\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 128s 454ms/step - loss: 2.0009 - categorical_accuracy: 0.3111 - top-3: 0.5435 - ROC-AUC: 0.7654 - PR-AUC: 0.3455 - precision: 0.7354 - recall: 0.1463 - TP: 1323.0000 - TN: 98964.0000 - FP: 476.0000 - FN: 7717.0000 - val_loss: 2.0833 - val_categorical_accuracy: 0.2827 - val_top-3: 0.4909 - val_ROC-AUC: 0.7227 - val_PR-AUC: 0.3148 - val_precision: 0.8716 - val_recall: 0.1055 - val_TP: 638.0000 - val_TN: 66434.0000 - val_FP: 94.0000 - val_FN: 5410.0000\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 154s 545ms/step - loss: 2.0067 - categorical_accuracy: 0.3104 - top-3: 0.5437 - ROC-AUC: 0.7646 - PR-AUC: 0.3440 - precision: 0.7312 - recall: 0.1433 - TP: 1295.0000 - TN: 98964.0000 - FP: 476.0000 - FN: 7745.0000 - val_loss: 2.0856 - val_categorical_accuracy: 0.2760 - val_top-3: 0.4864 - val_ROC-AUC: 0.7248 - val_PR-AUC: 0.3136 - val_precision: 0.8239 - val_recall: 0.1106 - val_TP: 669.0000 - val_TN: 66385.0000 - val_FP: 143.0000 - val_FN: 5379.0000\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 140s 495ms/step - loss: 1.9785 - categorical_accuracy: 0.3189 - top-3: 0.5559 - ROC-AUC: 0.7732 - PR-AUC: 0.3568 - precision: 0.7403 - recall: 0.1482 - TP: 1340.0000 - TN: 98970.0000 - FP: 470.0000 - FN: 7700.0000 - val_loss: 2.0890 - val_categorical_accuracy: 0.2735 - val_top-3: 0.4759 - val_ROC-AUC: 0.7206 - val_PR-AUC: 0.3125 - val_precision: 0.8339 - val_recall: 0.1179 - val_TP: 713.0000 - val_TN: 66386.0000 - val_FP: 142.0000 - val_FN: 5335.0000\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 134s 474ms/step - loss: 1.9936 - categorical_accuracy: 0.3153 - top-3: 0.5513 - ROC-AUC: 0.7678 - PR-AUC: 0.3493 - precision: 0.7368 - recall: 0.1430 - TP: 1293.0000 - TN: 98978.0000 - FP: 462.0000 - FN: 7747.0000 - val_loss: 2.0625 - val_categorical_accuracy: 0.2860 - val_top-3: 0.4990 - val_ROC-AUC: 0.7289 - val_PR-AUC: 0.3274 - val_precision: 0.8528 - val_recall: 0.1207 - val_TP: 730.0000 - val_TN: 66402.0000 - val_FP: 126.0000 - val_FN: 5318.0000\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 136s 482ms/step - loss: 2.0095 - categorical_accuracy: 0.3085 - top-3: 0.5423 - ROC-AUC: 0.7634 - PR-AUC: 0.3435 - precision: 0.7293 - recall: 0.1460 - TP: 1320.0000 - TN: 98950.0000 - FP: 490.0000 - FN: 7720.0000 - val_loss: 2.0741 - val_categorical_accuracy: 0.2799 - val_top-3: 0.4950 - val_ROC-AUC: 0.7257 - val_PR-AUC: 0.3200 - val_precision: 0.8483 - val_recall: 0.1184 - val_TP: 716.0000 - val_TN: 66400.0000 - val_FP: 128.0000 - val_FN: 5332.0000\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 134s 472ms/step - loss: 2.0019 - categorical_accuracy: 0.3084 - top-3: 0.5497 - ROC-AUC: 0.7641 - PR-AUC: 0.3434 - precision: 0.7228 - recall: 0.1442 - TP: 1304.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7736.0000 - val_loss: 2.0784 - val_categorical_accuracy: 0.2826 - val_top-3: 0.4995 - val_ROC-AUC: 0.7258 - val_PR-AUC: 0.3195 - val_precision: 0.8646 - val_recall: 0.1129 - val_TP: 683.0000 - val_TN: 66421.0000 - val_FP: 107.0000 - val_FN: 5365.0000\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 136s 482ms/step - loss: 1.9830 - categorical_accuracy: 0.3164 - top-3: 0.5552 - ROC-AUC: 0.7701 - PR-AUC: 0.3541 - precision: 0.7368 - recall: 0.1456 - TP: 1316.0000 - TN: 98970.0000 - FP: 470.0000 - FN: 7724.0000 - val_loss: 2.0800 - val_categorical_accuracy: 0.2796 - val_top-3: 0.4969 - val_ROC-AUC: 0.7247 - val_PR-AUC: 0.3148 - val_precision: 0.8401 - val_recall: 0.1129 - val_TP: 683.0000 - val_TN: 66398.0000 - val_FP: 130.0000 - val_FN: 5365.0000\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 138s 488ms/step - loss: 1.9918 - categorical_accuracy: 0.3150 - top-3: 0.5498 - ROC-AUC: 0.7674 - PR-AUC: 0.3531 - precision: 0.7382 - recall: 0.1507 - TP: 1362.0000 - TN: 98957.0000 - FP: 483.0000 - FN: 7678.0000 - val_loss: 2.0988 - val_categorical_accuracy: 0.2750 - val_top-3: 0.4845 - val_ROC-AUC: 0.7184 - val_PR-AUC: 0.3108 - val_precision: 0.8379 - val_recall: 0.1111 - val_TP: 672.0000 - val_TN: 66398.0000 - val_FP: 130.0000 - val_FN: 5376.0000\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 133s 471ms/step - loss: 1.9886 - categorical_accuracy: 0.3154 - top-3: 0.5528 - ROC-AUC: 0.7682 - PR-AUC: 0.3521 - precision: 0.7229 - recall: 0.1469 - TP: 1328.0000 - TN: 98931.0000 - FP: 509.0000 - FN: 7712.0000 - val_loss: 2.0818 - val_categorical_accuracy: 0.2824 - val_top-3: 0.4939 - val_ROC-AUC: 0.7244 - val_PR-AUC: 0.3189 - val_precision: 0.8481 - val_recall: 0.1154 - val_TP: 698.0000 - val_TN: 66403.0000 - val_FP: 125.0000 - val_FN: 5350.0000\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 134s 473ms/step - loss: 1.9902 - categorical_accuracy: 0.3150 - top-3: 0.5564 - ROC-AUC: 0.7715 - PR-AUC: 0.3511 - precision: 0.7222 - recall: 0.1444 - TP: 1305.0000 - TN: 98938.0000 - FP: 502.0000 - FN: 7735.0000 - val_loss: 2.0692 - val_categorical_accuracy: 0.2834 - val_top-3: 0.4962 - val_ROC-AUC: 0.7284 - val_PR-AUC: 0.3203 - val_precision: 0.8400 - val_recall: 0.1146 - val_TP: 693.0000 - val_TN: 66396.0000 - val_FP: 132.0000 - val_FN: 5355.0000\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 136s 481ms/step - loss: 1.9870 - categorical_accuracy: 0.3118 - top-3: 0.5496 - ROC-AUC: 0.7688 - PR-AUC: 0.3508 - precision: 0.7363 - recall: 0.1482 - TP: 1340.0000 - TN: 98960.0000 - FP: 480.0000 - FN: 7700.0000 - val_loss: 2.0713 - val_categorical_accuracy: 0.2872 - val_top-3: 0.4921 - val_ROC-AUC: 0.7282 - val_PR-AUC: 0.3237 - val_precision: 0.8291 - val_recall: 0.1227 - val_TP: 742.0000 - val_TN: 66375.0000 - val_FP: 153.0000 - val_FN: 5306.0000\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 136s 480ms/step - loss: 1.9883 - categorical_accuracy: 0.3152 - top-3: 0.5486 - ROC-AUC: 0.7697 - PR-AUC: 0.3518 - precision: 0.7305 - recall: 0.1499 - TP: 1355.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7685.0000 - val_loss: 2.0705 - val_categorical_accuracy: 0.2793 - val_top-3: 0.4931 - val_ROC-AUC: 0.7302 - val_PR-AUC: 0.3197 - val_precision: 0.8450 - val_recall: 0.1162 - val_TP: 703.0000 - val_TN: 66399.0000 - val_FP: 129.0000 - val_FN: 5345.0000\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 130s 459ms/step - loss: 1.9850 - categorical_accuracy: 0.3126 - top-3: 0.5490 - ROC-AUC: 0.7693 - PR-AUC: 0.3528 - precision: 0.7243 - recall: 0.1520 - TP: 1374.0000 - TN: 98917.0000 - FP: 523.0000 - FN: 7666.0000 - val_loss: 2.0892 - val_categorical_accuracy: 0.2735 - val_top-3: 0.4886 - val_ROC-AUC: 0.7241 - val_PR-AUC: 0.3128 - val_precision: 0.8325 - val_recall: 0.1126 - val_TP: 681.0000 - val_TN: 66391.0000 - val_FP: 137.0000 - val_FN: 5367.0000\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 128s 452ms/step - loss: 2.0096 - categorical_accuracy: 0.3094 - top-3: 0.5416 - ROC-AUC: 0.7619 - PR-AUC: 0.3452 - precision: 0.7330 - recall: 0.1439 - TP: 1301.0000 - TN: 98966.0000 - FP: 474.0000 - FN: 7739.0000 - val_loss: 2.0805 - val_categorical_accuracy: 0.2766 - val_top-3: 0.4871 - val_ROC-AUC: 0.7241 - val_PR-AUC: 0.3137 - val_precision: 0.8347 - val_recall: 0.1161 - val_TP: 702.0000 - val_TN: 66389.0000 - val_FP: 139.0000 - val_FN: 5346.0000\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 130s 459ms/step - loss: 1.9960 - categorical_accuracy: 0.3152 - top-3: 0.5514 - ROC-AUC: 0.7669 - PR-AUC: 0.3485 - precision: 0.7276 - recall: 0.1510 - TP: 1365.0000 - TN: 98929.0000 - FP: 511.0000 - FN: 7675.0000 - val_loss: 2.0695 - val_categorical_accuracy: 0.2783 - val_top-3: 0.4889 - val_ROC-AUC: 0.7275 - val_PR-AUC: 0.3223 - val_precision: 0.8453 - val_recall: 0.1210 - val_TP: 732.0000 - val_TN: 66394.0000 - val_FP: 134.0000 - val_FN: 5316.0000\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 133s 471ms/step - loss: 1.9944 - categorical_accuracy: 0.3054 - top-3: 0.5427 - ROC-AUC: 0.7682 - PR-AUC: 0.3509 - precision: 0.7239 - recall: 0.1517 - TP: 1371.0000 - TN: 98917.0000 - FP: 523.0000 - FN: 7669.0000 - val_loss: 2.0678 - val_categorical_accuracy: 0.2821 - val_top-3: 0.4944 - val_ROC-AUC: 0.7263 - val_PR-AUC: 0.3242 - val_precision: 0.8444 - val_recall: 0.1194 - val_TP: 722.0000 - val_TN: 66395.0000 - val_FP: 133.0000 - val_FN: 5326.0000\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 133s 469ms/step - loss: 1.9904 - categorical_accuracy: 0.3138 - top-3: 0.5476 - ROC-AUC: 0.7681 - PR-AUC: 0.3514 - precision: 0.7452 - recall: 0.1498 - TP: 1354.0000 - TN: 98977.0000 - FP: 463.0000 - FN: 7686.0000 - val_loss: 2.0599 - val_categorical_accuracy: 0.2847 - val_top-3: 0.4883 - val_ROC-AUC: 0.7326 - val_PR-AUC: 0.3260 - val_precision: 0.8583 - val_recall: 0.1242 - val_TP: 751.0000 - val_TN: 66404.0000 - val_FP: 124.0000 - val_FN: 5297.0000\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 134s 473ms/step - loss: 1.9671 - categorical_accuracy: 0.3177 - top-3: 0.5543 - ROC-AUC: 0.7740 - PR-AUC: 0.3623 - precision: 0.7410 - recall: 0.1529 - TP: 1382.0000 - TN: 98957.0000 - FP: 483.0000 - FN: 7658.0000 - val_loss: 2.0843 - val_categorical_accuracy: 0.2799 - val_top-3: 0.4922 - val_ROC-AUC: 0.7227 - val_PR-AUC: 0.3147 - val_precision: 0.8497 - val_recall: 0.1131 - val_TP: 684.0000 - val_TN: 66407.0000 - val_FP: 121.0000 - val_FN: 5364.0000\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 135s 478ms/step - loss: 1.9771 - categorical_accuracy: 0.3142 - top-3: 0.5507 - ROC-AUC: 0.7707 - PR-AUC: 0.3587 - precision: 0.7402 - recall: 0.1566 - TP: 1416.0000 - TN: 98943.0000 - FP: 497.0000 - FN: 7624.0000 - val_loss: 2.0828 - val_categorical_accuracy: 0.2776 - val_top-3: 0.4792 - val_ROC-AUC: 0.7259 - val_PR-AUC: 0.3154 - val_precision: 0.8226 - val_recall: 0.1143 - val_TP: 691.0000 - val_TN: 66379.0000 - val_FP: 149.0000 - val_FN: 5357.0000\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 130s 460ms/step - loss: 1.9930 - categorical_accuracy: 0.3111 - top-3: 0.5513 - ROC-AUC: 0.7693 - PR-AUC: 0.3509 - precision: 0.7231 - recall: 0.1511 - TP: 1366.0000 - TN: 98917.0000 - FP: 523.0000 - FN: 7674.0000 - val_loss: 2.0665 - val_categorical_accuracy: 0.2862 - val_top-3: 0.4922 - val_ROC-AUC: 0.7268 - val_PR-AUC: 0.3239 - val_precision: 0.8520 - val_recall: 0.1181 - val_TP: 714.0000 - val_TN: 66404.0000 - val_FP: 124.0000 - val_FN: 5334.0000\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 129s 457ms/step - loss: 1.9846 - categorical_accuracy: 0.3230 - top-3: 0.5559 - ROC-AUC: 0.7699 - PR-AUC: 0.3582 - precision: 0.7440 - recall: 0.1575 - TP: 1424.0000 - TN: 98950.0000 - FP: 490.0000 - FN: 7616.0000 - val_loss: 2.0953 - val_categorical_accuracy: 0.2705 - val_top-3: 0.4866 - val_ROC-AUC: 0.7205 - val_PR-AUC: 0.3088 - val_precision: 0.8262 - val_recall: 0.1124 - val_TP: 680.0000 - val_TN: 66385.0000 - val_FP: 143.0000 - val_FN: 5368.0000\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 135s 476ms/step - loss: 1.9808 - categorical_accuracy: 0.3152 - top-3: 0.5566 - ROC-AUC: 0.7716 - PR-AUC: 0.3534 - precision: 0.7176 - recall: 0.1538 - TP: 1390.0000 - TN: 98893.0000 - FP: 547.0000 - FN: 7650.0000 - val_loss: 2.0564 - val_categorical_accuracy: 0.2879 - val_top-3: 0.4954 - val_ROC-AUC: 0.7320 - val_PR-AUC: 0.3263 - val_precision: 0.8417 - val_recall: 0.1187 - val_TP: 718.0000 - val_TN: 66393.0000 - val_FP: 135.0000 - val_FN: 5330.0000\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 128s 452ms/step - loss: 1.9889 - categorical_accuracy: 0.3202 - top-3: 0.5552 - ROC-AUC: 0.7703 - PR-AUC: 0.3569 - precision: 0.7379 - recall: 0.1558 - TP: 1408.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7632.0000 - val_loss: 2.0777 - val_categorical_accuracy: 0.2806 - val_top-3: 0.4962 - val_ROC-AUC: 0.7265 - val_PR-AUC: 0.3169 - val_precision: 0.8341 - val_recall: 0.1139 - val_TP: 689.0000 - val_TN: 66391.0000 - val_FP: 137.0000 - val_FN: 5359.0000\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 125s 442ms/step - loss: 1.9991 - categorical_accuracy: 0.3136 - top-3: 0.5507 - ROC-AUC: 0.7660 - PR-AUC: 0.3477 - precision: 0.7166 - recall: 0.1482 - TP: 1340.0000 - TN: 98910.0000 - FP: 530.0000 - FN: 7700.0000 - val_loss: 2.0630 - val_categorical_accuracy: 0.2753 - val_top-3: 0.4853 - val_ROC-AUC: 0.7303 - val_PR-AUC: 0.3227 - val_precision: 0.8335 - val_recall: 0.1225 - val_TP: 741.0000 - val_TN: 66380.0000 - val_FP: 148.0000 - val_FN: 5307.0000\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 123s 436ms/step - loss: 1.9800 - categorical_accuracy: 0.3163 - top-3: 0.5560 - ROC-AUC: 0.7715 - PR-AUC: 0.3546 - precision: 0.7356 - recall: 0.1558 - TP: 1408.0000 - TN: 98934.0000 - FP: 506.0000 - FN: 7632.0000 - val_loss: 2.0910 - val_categorical_accuracy: 0.2725 - val_top-3: 0.4917 - val_ROC-AUC: 0.7234 - val_PR-AUC: 0.3111 - val_precision: 0.8313 - val_recall: 0.1124 - val_TP: 680.0000 - val_TN: 66390.0000 - val_FP: 138.0000 - val_FN: 5368.0000\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 124s 438ms/step - loss: 2.0003 - categorical_accuracy: 0.3114 - top-3: 0.5538 - ROC-AUC: 0.7676 - PR-AUC: 0.3472 - precision: 0.7154 - recall: 0.1477 - TP: 1335.0000 - TN: 98909.0000 - FP: 531.0000 - FN: 7705.0000 - val_loss: 2.0793 - val_categorical_accuracy: 0.2761 - val_top-3: 0.4878 - val_ROC-AUC: 0.7245 - val_PR-AUC: 0.3134 - val_precision: 0.8315 - val_recall: 0.1109 - val_TP: 671.0000 - val_TN: 66392.0000 - val_FP: 136.0000 - val_FN: 5377.0000\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 124s 440ms/step - loss: 1.9847 - categorical_accuracy: 0.3146 - top-3: 0.5466 - ROC-AUC: 0.7689 - PR-AUC: 0.3538 - precision: 0.7258 - recall: 0.1529 - TP: 1382.0000 - TN: 98918.0000 - FP: 522.0000 - FN: 7658.0000 - val_loss: 2.0794 - val_categorical_accuracy: 0.2770 - val_top-3: 0.4914 - val_ROC-AUC: 0.7269 - val_PR-AUC: 0.3171 - val_precision: 0.8445 - val_recall: 0.1123 - val_TP: 679.0000 - val_TN: 66403.0000 - val_FP: 125.0000 - val_FN: 5369.0000\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 125s 442ms/step - loss: 1.9715 - categorical_accuracy: 0.3207 - top-3: 0.5584 - ROC-AUC: 0.7753 - PR-AUC: 0.3616 - precision: 0.7430 - recall: 0.1551 - TP: 1402.0000 - TN: 98955.0000 - FP: 485.0000 - FN: 7638.0000 - val_loss: 2.0653 - val_categorical_accuracy: 0.2786 - val_top-3: 0.4962 - val_ROC-AUC: 0.7278 - val_PR-AUC: 0.3196 - val_precision: 0.8319 - val_recall: 0.1129 - val_TP: 683.0000 - val_TN: 66390.0000 - val_FP: 138.0000 - val_FN: 5365.0000\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 124s 439ms/step - loss: 1.9871 - categorical_accuracy: 0.3153 - top-3: 0.5593 - ROC-AUC: 0.7734 - PR-AUC: 0.3523 - precision: 0.7099 - recall: 0.1483 - TP: 1341.0000 - TN: 98892.0000 - FP: 548.0000 - FN: 7699.0000 - val_loss: 2.0642 - val_categorical_accuracy: 0.2793 - val_top-3: 0.4861 - val_ROC-AUC: 0.7270 - val_PR-AUC: 0.3222 - val_precision: 0.8363 - val_recall: 0.1233 - val_TP: 746.0000 - val_TN: 66382.0000 - val_FP: 146.0000 - val_FN: 5302.0000\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 123s 435ms/step - loss: 1.9977 - categorical_accuracy: 0.3157 - top-3: 0.5507 - ROC-AUC: 0.7671 - PR-AUC: 0.3543 - precision: 0.7402 - recall: 0.1510 - TP: 1365.0000 - TN: 98961.0000 - FP: 479.0000 - FN: 7675.0000 - val_loss: 2.0802 - val_categorical_accuracy: 0.2710 - val_top-3: 0.4959 - val_ROC-AUC: 0.7270 - val_PR-AUC: 0.3169 - val_precision: 0.8272 - val_recall: 0.1195 - val_TP: 723.0000 - val_TN: 66377.0000 - val_FP: 151.0000 - val_FN: 5325.0000\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 126s 444ms/step - loss: 1.9701 - categorical_accuracy: 0.3158 - top-3: 0.5582 - ROC-AUC: 0.7737 - PR-AUC: 0.3600 - precision: 0.7457 - recall: 0.1551 - TP: 1402.0000 - TN: 98962.0000 - FP: 478.0000 - FN: 7638.0000 - val_loss: 2.0767 - val_categorical_accuracy: 0.2774 - val_top-3: 0.4950 - val_ROC-AUC: 0.7281 - val_PR-AUC: 0.3190 - val_precision: 0.8169 - val_recall: 0.1181 - val_TP: 714.0000 - val_TN: 66368.0000 - val_FP: 160.0000 - val_FN: 5334.0000\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 125s 441ms/step - loss: 1.9954 - categorical_accuracy: 0.3199 - top-3: 0.5449 - ROC-AUC: 0.7665 - PR-AUC: 0.3522 - precision: 0.7342 - recall: 0.1528 - TP: 1381.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7659.0000 - val_loss: 2.0779 - val_categorical_accuracy: 0.2811 - val_top-3: 0.4904 - val_ROC-AUC: 0.7262 - val_PR-AUC: 0.3176 - val_precision: 0.8383 - val_recall: 0.1157 - val_TP: 700.0000 - val_TN: 66393.0000 - val_FP: 135.0000 - val_FN: 5348.0000\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 128s 452ms/step - loss: 1.9990 - categorical_accuracy: 0.3123 - top-3: 0.5533 - ROC-AUC: 0.7686 - PR-AUC: 0.3458 - precision: 0.7128 - recall: 0.1482 - TP: 1340.0000 - TN: 98900.0000 - FP: 540.0000 - FN: 7700.0000 - val_loss: 2.0710 - val_categorical_accuracy: 0.2816 - val_top-3: 0.4967 - val_ROC-AUC: 0.7278 - val_PR-AUC: 0.3187 - val_precision: 0.8267 - val_recall: 0.1136 - val_TP: 687.0000 - val_TN: 66384.0000 - val_FP: 144.0000 - val_FN: 5361.0000\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 124s 439ms/step - loss: 1.9740 - categorical_accuracy: 0.3210 - top-3: 0.5485 - ROC-AUC: 0.7717 - PR-AUC: 0.3576 - precision: 0.7401 - recall: 0.1556 - TP: 1407.0000 - TN: 98946.0000 - FP: 494.0000 - FN: 7633.0000 - val_loss: 2.0759 - val_categorical_accuracy: 0.2832 - val_top-3: 0.4861 - val_ROC-AUC: 0.7248 - val_PR-AUC: 0.3188 - val_precision: 0.8520 - val_recall: 0.1181 - val_TP: 714.0000 - val_TN: 66404.0000 - val_FP: 124.0000 - val_FN: 5334.0000\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 124s 439ms/step - loss: 1.9967 - categorical_accuracy: 0.3147 - top-3: 0.5548 - ROC-AUC: 0.7686 - PR-AUC: 0.3514 - precision: 0.7131 - recall: 0.1518 - TP: 1372.0000 - TN: 98888.0000 - FP: 552.0000 - FN: 7668.0000 - val_loss: 2.0608 - val_categorical_accuracy: 0.2852 - val_top-3: 0.4992 - val_ROC-AUC: 0.7308 - val_PR-AUC: 0.3245 - val_precision: 0.8320 - val_recall: 0.1187 - val_TP: 718.0000 - val_TN: 66383.0000 - val_FP: 145.0000 - val_FN: 5330.0000\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 127s 450ms/step - loss: 1.9853 - categorical_accuracy: 0.3190 - top-3: 0.5580 - ROC-AUC: 0.7730 - PR-AUC: 0.3555 - precision: 0.7233 - recall: 0.1489 - TP: 1346.0000 - TN: 98925.0000 - FP: 515.0000 - FN: 7694.0000 - val_loss: 2.0841 - val_categorical_accuracy: 0.2816 - val_top-3: 0.4950 - val_ROC-AUC: 0.7243 - val_PR-AUC: 0.3154 - val_precision: 0.8337 - val_recall: 0.1136 - val_TP: 687.0000 - val_TN: 66391.0000 - val_FP: 137.0000 - val_FN: 5361.0000\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 123s 436ms/step - loss: 1.9803 - categorical_accuracy: 0.3231 - top-3: 0.5525 - ROC-AUC: 0.7719 - PR-AUC: 0.3580 - precision: 0.7326 - recall: 0.1515 - TP: 1370.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7670.0000 - val_loss: 2.0564 - val_categorical_accuracy: 0.2784 - val_top-3: 0.4916 - val_ROC-AUC: 0.7329 - val_PR-AUC: 0.3248 - val_precision: 0.8425 - val_recall: 0.1194 - val_TP: 722.0000 - val_TN: 66393.0000 - val_FP: 135.0000 - val_FN: 5326.0000\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 125s 442ms/step - loss: 1.9839 - categorical_accuracy: 0.3060 - top-3: 0.5442 - ROC-AUC: 0.7686 - PR-AUC: 0.3499 - precision: 0.7335 - recall: 0.1504 - TP: 1360.0000 - TN: 98946.0000 - FP: 494.0000 - FN: 7680.0000 - val_loss: 2.0507 - val_categorical_accuracy: 0.2966 - val_top-3: 0.5124 - val_ROC-AUC: 0.7339 - val_PR-AUC: 0.3326 - val_precision: 0.8461 - val_recall: 0.1209 - val_TP: 731.0000 - val_TN: 66395.0000 - val_FP: 133.0000 - val_FN: 5317.0000\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 126s 446ms/step - loss: 1.9778 - categorical_accuracy: 0.3204 - top-3: 0.5552 - ROC-AUC: 0.7710 - PR-AUC: 0.3564 - precision: 0.7346 - recall: 0.1531 - TP: 1384.0000 - TN: 98940.0000 - FP: 500.0000 - FN: 7656.0000 - val_loss: 2.0698 - val_categorical_accuracy: 0.2874 - val_top-3: 0.4846 - val_ROC-AUC: 0.7275 - val_PR-AUC: 0.3225 - val_precision: 0.8497 - val_recall: 0.1233 - val_TP: 746.0000 - val_TN: 66396.0000 - val_FP: 132.0000 - val_FN: 5302.0000\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 124s 439ms/step - loss: 1.9743 - categorical_accuracy: 0.3242 - top-3: 0.5550 - ROC-AUC: 0.7721 - PR-AUC: 0.3594 - precision: 0.7376 - recall: 0.1561 - TP: 1411.0000 - TN: 98938.0000 - FP: 502.0000 - FN: 7629.0000 - val_loss: 2.0914 - val_categorical_accuracy: 0.2703 - val_top-3: 0.4797 - val_ROC-AUC: 0.7210 - val_PR-AUC: 0.3117 - val_precision: 0.8337 - val_recall: 0.1177 - val_TP: 712.0000 - val_TN: 66386.0000 - val_FP: 142.0000 - val_FN: 5336.0000\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 126s 447ms/step - loss: 1.9840 - categorical_accuracy: 0.3209 - top-3: 0.5506 - ROC-AUC: 0.7706 - PR-AUC: 0.3594 - precision: 0.7324 - recall: 0.1577 - TP: 1426.0000 - TN: 98919.0000 - FP: 521.0000 - FN: 7614.0000 - val_loss: 2.0735 - val_categorical_accuracy: 0.2765 - val_top-3: 0.4985 - val_ROC-AUC: 0.7281 - val_PR-AUC: 0.3182 - val_precision: 0.8306 - val_recall: 0.1159 - val_TP: 701.0000 - val_TN: 66385.0000 - val_FP: 143.0000 - val_FN: 5347.0000\n",
      "-----\n",
      "(6536614.70 ms) == (108m:56s)\n",
      "-----\n",
      "\n",
      "\n",
      "23\n",
      "['mobilenetv2_1.00_32-imagenet224-32-12.tensorboard',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.001_0.2502_2.1470.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.002_0.2674_2.1322.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.003_0.2708_2.0992.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.005_0.2736_2.1101.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.006_0.2745_2.0891.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.007_0.2768_2.0711.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.010_0.2827_2.0833.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.013_0.2860_2.0625.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.020_0.2872_2.0713.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.026_0.2847_2.0599.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.031_0.2879_2.0564.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.047_0.2966_2.0507.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-32-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_32-imagenet224-32-12.csv',\n",
      " 'model.mobilenetv2_1.00_32-imagenet224-32-12.h5',\n",
      " 'weights.mobilenetv2_1.00_32-imagenet224-32-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_32-imagenet224-32-12\n",
    "model32imagenet2243212 = consecutiveModelTraining(\n",
    "    input_size=32,\n",
    "    batch_size=32,\n",
    "    weights='imagenet',\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "304e10df-8993-4f09-aa1b-eadd111ac299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T17:25:04.794794Z",
     "iopub.status.busy": "2021-06-09T17:25:04.793791Z",
     "iopub.status.idle": "2021-06-09T17:25:04.870798Z",
     "shell.execute_reply": "2021-06-09T17:25:04.870798Z",
     "shell.execute_reply.started": "2021-06-09T17:25:04.793791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.995568</td>\n",
       "      <td>0.312719</td>\n",
       "      <td>0.548695</td>\n",
       "      <td>0.767203</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.145973</td>\n",
       "      <td>1319.600000</td>\n",
       "      <td>98959.400000</td>\n",
       "      <td>480.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277808</td>\n",
       "      <td>0.490040</td>\n",
       "      <td>0.724957</td>\n",
       "      <td>0.316195</td>\n",
       "      <td>0.841115</td>\n",
       "      <td>0.113598</td>\n",
       "      <td>687.040000</td>\n",
       "      <td>66397.740000</td>\n",
       "      <td>130.260000</td>\n",
       "      <td>5360.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027282</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>132.958947</td>\n",
       "      <td>66.806452</td>\n",
       "      <td>66.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>49.722889</td>\n",
       "      <td>17.139059</td>\n",
       "      <td>17.139059</td>\n",
       "      <td>49.722889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.967080</td>\n",
       "      <td>0.265819</td>\n",
       "      <td>0.496239</td>\n",
       "      <td>0.720744</td>\n",
       "      <td>0.279530</td>\n",
       "      <td>0.709899</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>98888.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250165</td>\n",
       "      <td>0.472884</td>\n",
       "      <td>0.710097</td>\n",
       "      <td>0.288584</td>\n",
       "      <td>0.816934</td>\n",
       "      <td>0.080192</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>66368.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>5297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.983956</td>\n",
       "      <td>0.311062</td>\n",
       "      <td>0.544939</td>\n",
       "      <td>0.765510</td>\n",
       "      <td>0.346147</td>\n",
       "      <td>0.724686</td>\n",
       "      <td>0.144275</td>\n",
       "      <td>1304.250000</td>\n",
       "      <td>98929.500000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274595</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.722878</td>\n",
       "      <td>0.312607</td>\n",
       "      <td>0.831584</td>\n",
       "      <td>0.112310</td>\n",
       "      <td>679.250000</td>\n",
       "      <td>66386.750000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>5330.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.991128</td>\n",
       "      <td>0.314878</td>\n",
       "      <td>0.550608</td>\n",
       "      <td>0.768618</td>\n",
       "      <td>0.351374</td>\n",
       "      <td>0.734396</td>\n",
       "      <td>0.149336</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>98946.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278356</td>\n",
       "      <td>0.491485</td>\n",
       "      <td>0.725888</td>\n",
       "      <td>0.317326</td>\n",
       "      <td>0.839162</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>693.000000</td>\n",
       "      <td>66394.500000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>5355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000022</td>\n",
       "      <td>0.316344</td>\n",
       "      <td>0.554923</td>\n",
       "      <td>0.770877</td>\n",
       "      <td>0.355241</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>1381.750000</td>\n",
       "      <td>98969.000000</td>\n",
       "      <td>510.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282325</td>\n",
       "      <td>0.495040</td>\n",
       "      <td>0.727998</td>\n",
       "      <td>0.322270</td>\n",
       "      <td>0.848285</td>\n",
       "      <td>0.118634</td>\n",
       "      <td>717.500000</td>\n",
       "      <td>66403.000000</td>\n",
       "      <td>141.250000</td>\n",
       "      <td>5368.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.157672</td>\n",
       "      <td>0.324226</td>\n",
       "      <td>0.559292</td>\n",
       "      <td>0.775261</td>\n",
       "      <td>0.362253</td>\n",
       "      <td>0.828530</td>\n",
       "      <td>0.157743</td>\n",
       "      <td>1426.000000</td>\n",
       "      <td>99321.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296627</td>\n",
       "      <td>0.512401</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.332623</td>\n",
       "      <td>0.871585</td>\n",
       "      <td>0.124173</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>66455.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5563.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    1.995568              0.312719   0.548695   0.767203   0.349184   \n",
       "std     0.027282              0.009248   0.009670   0.007806   0.012426   \n",
       "min     1.967080              0.265819   0.496239   0.720744   0.279530   \n",
       "25%     1.983956              0.311062   0.544939   0.765510   0.346147   \n",
       "50%     1.991128              0.314878   0.550608   0.768618   0.351374   \n",
       "75%     2.000022              0.316344   0.554923   0.770877   0.355241   \n",
       "max     2.157672              0.324226   0.559292   0.775261   0.362253   \n",
       "\n",
       "       precision     recall           TP            TN          FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000   50.000000  ...   \n",
       "mean    0.734523   0.145973  1319.600000  98959.400000  480.600000  ...   \n",
       "std     0.017186   0.014708   132.958947     66.806452   66.806452  ...   \n",
       "min     0.709899   0.063606   575.000000  98888.000000  119.000000  ...   \n",
       "25%     0.724686   0.144275  1304.250000  98929.500000  471.000000  ...   \n",
       "50%     0.734396   0.149336  1350.000000  98946.000000  494.000000  ...   \n",
       "75%     0.739891   0.152848  1381.750000  98969.000000  510.500000  ...   \n",
       "max     0.828530   0.157743  1426.000000  99321.000000  552.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.277808   0.490040     0.724957    0.316195   \n",
       "std                    0.007638   0.007400     0.005081    0.008356   \n",
       "min                    0.250165   0.472884     0.710097    0.288584   \n",
       "25%                    0.274595   0.486111     0.722878    0.312607   \n",
       "50%                    0.278356   0.491485     0.725888    0.317326   \n",
       "75%                    0.282325   0.495040     0.727998    0.322270   \n",
       "max                    0.296627   0.512401     0.733933    0.332623   \n",
       "\n",
       "       val_precision  val_recall      val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000   50.000000     50.000000   50.000000   \n",
       "mean        0.841115    0.113598  687.040000  66397.740000  130.260000   \n",
       "std         0.013265    0.008221   49.722889     17.139059   17.139059   \n",
       "min         0.816934    0.080192  485.000000  66368.000000   73.000000   \n",
       "25%         0.831584    0.112310  679.250000  66386.750000  125.000000   \n",
       "50%         0.839162    0.114583  693.000000  66394.500000  133.500000   \n",
       "75%         0.848285    0.118634  717.500000  66403.000000  141.250000   \n",
       "max         0.871585    0.124173  751.000000  66455.000000  160.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean   5360.960000  \n",
       "std      49.722889  \n",
       "min    5297.000000  \n",
       "25%    5330.500000  \n",
       "50%    5355.000000  \n",
       "75%    5368.750000  \n",
       "max    5563.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model32imagenet2243212['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9a9d7-0679-41e4-ad42-4e2750b887c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fab6e3a-c6c3-48f7-b510-7989153c266e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T17:25:04.872794Z",
     "iopub.status.busy": "2021-06-09T17:25:04.872794Z",
     "iopub.status.idle": "2021-06-09T19:07:11.429904Z",
     "shell.execute_reply": "2021-06-09T19:07:11.429904Z",
     "shell.execute_reply.started": "2021-06-09T17:25:04.872794Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "mobilenetv2_1.00_32-imagenet224-64-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_32-imagenet224-64-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 1, 1, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 15,372\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 141,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 94}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_32-imagenet224-64-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_32-imagenet224-64-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_32-imagenet224-64-12\n",
      "Epoch 1/50\n",
      "  2/141 [..............................] - ETA: 11:04 - loss: 2.4864 - categorical_accuracy: 0.0938 - top-3: 0.3594 - ROC-AUC: 0.4858 - PR-AUC: 0.0976 - precision: 0.0000e+00 - recall: 0.0000e+00 - TP: 0.0000e+00 - TN: 1408.0000 - FP: 0.0000e+00 - FN: 128.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5010s vs `on_train_batch_end` time: 9.0612s). Check your callbacks.\n",
      "141/141 [==============================] - 134s 947ms/step - loss: 2.1989 - categorical_accuracy: 0.2539 - top-3: 0.4802 - ROC-AUC: 0.7092 - PR-AUC: 0.2660 - precision: 0.8452 - recall: 0.0461 - TP: 415.0000 - TN: 99012.0000 - FP: 76.0000 - FN: 8593.0000 - val_loss: 2.1762 - val_categorical_accuracy: 0.2502 - val_top-3: 0.4684 - val_ROC-AUC: 0.7006 - val_PR-AUC: 0.2821 - val_precision: 0.9123 - val_recall: 0.0691 - val_TP: 416.0000 - val_TN: 66136.0000 - val_FP: 40.0000 - val_FN: 5600.0000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 119s 848ms/step - loss: 2.0629 - categorical_accuracy: 0.2890 - top-3: 0.5313 - ROC-AUC: 0.7526 - PR-AUC: 0.3202 - precision: 0.7956 - recall: 0.0959 - TP: 864.0000 - TN: 98866.0000 - FP: 222.0000 - FN: 8144.0000 - val_loss: 2.1361 - val_categorical_accuracy: 0.2548 - val_top-3: 0.4832 - val_ROC-AUC: 0.7121 - val_PR-AUC: 0.2926 - val_precision: 0.8522 - val_recall: 0.0901 - val_TP: 542.0000 - val_TN: 66082.0000 - val_FP: 94.0000 - val_FN: 5474.0000\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 119s 847ms/step - loss: 2.0065 - categorical_accuracy: 0.3086 - top-3: 0.5541 - ROC-AUC: 0.7678 - PR-AUC: 0.3435 - precision: 0.7654 - recall: 0.1210 - TP: 1090.0000 - TN: 98754.0000 - FP: 334.0000 - FN: 7918.0000 - val_loss: 2.1357 - val_categorical_accuracy: 0.2571 - val_top-3: 0.4719 - val_ROC-AUC: 0.7079 - val_PR-AUC: 0.2919 - val_precision: 0.8839 - val_recall: 0.0823 - val_TP: 495.0000 - val_TN: 66111.0000 - val_FP: 65.0000 - val_FN: 5521.0000\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 121s 858ms/step - loss: 2.0092 - categorical_accuracy: 0.3067 - top-3: 0.5490 - ROC-AUC: 0.7637 - PR-AUC: 0.3428 - precision: 0.7789 - recall: 0.1240 - TP: 1117.0000 - TN: 98771.0000 - FP: 317.0000 - FN: 7891.0000 - val_loss: 2.1119 - val_categorical_accuracy: 0.2726 - val_top-3: 0.4882 - val_ROC-AUC: 0.7181 - val_PR-AUC: 0.3041 - val_precision: 0.8774 - val_recall: 0.0916 - val_TP: 551.0000 - val_TN: 66099.0000 - val_FP: 77.0000 - val_FN: 5465.0000\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 121s 859ms/step - loss: 2.0084 - categorical_accuracy: 0.3052 - top-3: 0.5371 - ROC-AUC: 0.7634 - PR-AUC: 0.3420 - precision: 0.7716 - recall: 0.1271 - TP: 1145.0000 - TN: 98749.0000 - FP: 339.0000 - FN: 7863.0000 - val_loss: 2.0979 - val_categorical_accuracy: 0.2776 - val_top-3: 0.4769 - val_ROC-AUC: 0.7209 - val_PR-AUC: 0.3122 - val_precision: 0.8544 - val_recall: 0.1044 - val_TP: 628.0000 - val_TN: 66069.0000 - val_FP: 107.0000 - val_FN: 5388.0000\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 122s 868ms/step - loss: 1.9991 - categorical_accuracy: 0.3137 - top-3: 0.5502 - ROC-AUC: 0.7644 - PR-AUC: 0.3493 - precision: 0.7757 - recall: 0.1348 - TP: 1214.0000 - TN: 98737.0000 - FP: 351.0000 - FN: 7794.0000 - val_loss: 2.0816 - val_categorical_accuracy: 0.2739 - val_top-3: 0.4977 - val_ROC-AUC: 0.7275 - val_PR-AUC: 0.3192 - val_precision: 0.8520 - val_recall: 0.1110 - val_TP: 668.0000 - val_TN: 66060.0000 - val_FP: 116.0000 - val_FN: 5348.0000\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 121s 855ms/step - loss: 1.9868 - categorical_accuracy: 0.3145 - top-3: 0.5548 - ROC-AUC: 0.7695 - PR-AUC: 0.3504 - precision: 0.7392 - recall: 0.1381 - TP: 1244.0000 - TN: 98649.0000 - FP: 439.0000 - FN: 7764.0000 - val_loss: 2.1006 - val_categorical_accuracy: 0.2714 - val_top-3: 0.4880 - val_ROC-AUC: 0.7196 - val_PR-AUC: 0.3080 - val_precision: 0.8522 - val_recall: 0.1016 - val_TP: 611.0000 - val_TN: 66070.0000 - val_FP: 106.0000 - val_FN: 5405.0000\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 120s 852ms/step - loss: 1.9906 - categorical_accuracy: 0.3159 - top-3: 0.5520 - ROC-AUC: 0.7694 - PR-AUC: 0.3521 - precision: 0.7667 - recall: 0.1390 - TP: 1252.0000 - TN: 98707.0000 - FP: 381.0000 - FN: 7756.0000 - val_loss: 2.0809 - val_categorical_accuracy: 0.2822 - val_top-3: 0.5043 - val_ROC-AUC: 0.7283 - val_PR-AUC: 0.3178 - val_precision: 0.8529 - val_recall: 0.1041 - val_TP: 626.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 5390.0000\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 119s 846ms/step - loss: 1.9971 - categorical_accuracy: 0.3139 - top-3: 0.5501 - ROC-AUC: 0.7682 - PR-AUC: 0.3479 - precision: 0.7517 - recall: 0.1368 - TP: 1232.0000 - TN: 98681.0000 - FP: 407.0000 - FN: 7776.0000 - val_loss: 2.0979 - val_categorical_accuracy: 0.2754 - val_top-3: 0.4922 - val_ROC-AUC: 0.7211 - val_PR-AUC: 0.3114 - val_precision: 0.8522 - val_recall: 0.1016 - val_TP: 611.0000 - val_TN: 66070.0000 - val_FP: 106.0000 - val_FN: 5405.0000\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 119s 846ms/step - loss: 1.9912 - categorical_accuracy: 0.3159 - top-3: 0.5578 - ROC-AUC: 0.7691 - PR-AUC: 0.3535 - precision: 0.7454 - recall: 0.1430 - TP: 1288.0000 - TN: 98648.0000 - FP: 440.0000 - FN: 7720.0000 - val_loss: 2.0910 - val_categorical_accuracy: 0.2685 - val_top-3: 0.4897 - val_ROC-AUC: 0.7219 - val_PR-AUC: 0.3135 - val_precision: 0.8837 - val_recall: 0.1036 - val_TP: 623.0000 - val_TN: 66094.0000 - val_FP: 82.0000 - val_FN: 5393.0000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 121s 860ms/step - loss: 1.9788 - categorical_accuracy: 0.3142 - top-3: 0.5553 - ROC-AUC: 0.7708 - PR-AUC: 0.3550 - precision: 0.7556 - recall: 0.1418 - TP: 1277.0000 - TN: 98675.0000 - FP: 413.0000 - FN: 7731.0000 - val_loss: 2.0631 - val_categorical_accuracy: 0.2842 - val_top-3: 0.4967 - val_ROC-AUC: 0.7297 - val_PR-AUC: 0.3279 - val_precision: 0.8737 - val_recall: 0.1139 - val_TP: 685.0000 - val_TN: 66077.0000 - val_FP: 99.0000 - val_FN: 5331.0000\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 121s 857ms/step - loss: 1.9788 - categorical_accuracy: 0.3206 - top-3: 0.5582 - ROC-AUC: 0.7702 - PR-AUC: 0.3542 - precision: 0.7575 - recall: 0.1463 - TP: 1318.0000 - TN: 98666.0000 - FP: 422.0000 - FN: 7690.0000 - val_loss: 2.0957 - val_categorical_accuracy: 0.2746 - val_top-3: 0.4963 - val_ROC-AUC: 0.7211 - val_PR-AUC: 0.3139 - val_precision: 0.8663 - val_recall: 0.1056 - val_TP: 635.0000 - val_TN: 66078.0000 - val_FP: 98.0000 - val_FN: 5381.0000\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 120s 848ms/step - loss: 1.9836 - categorical_accuracy: 0.3148 - top-3: 0.5592 - ROC-AUC: 0.7704 - PR-AUC: 0.3550 - precision: 0.7443 - recall: 0.1412 - TP: 1272.0000 - TN: 98651.0000 - FP: 437.0000 - FN: 7736.0000 - val_loss: 2.0801 - val_categorical_accuracy: 0.2824 - val_top-3: 0.4902 - val_ROC-AUC: 0.7249 - val_PR-AUC: 0.3170 - val_precision: 0.8571 - val_recall: 0.1077 - val_TP: 648.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 5368.0000\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 120s 850ms/step - loss: 1.9862 - categorical_accuracy: 0.3177 - top-3: 0.5522 - ROC-AUC: 0.7693 - PR-AUC: 0.3524 - precision: 0.7424 - recall: 0.1440 - TP: 1297.0000 - TN: 98638.0000 - FP: 450.0000 - FN: 7711.0000 - val_loss: 2.0782 - val_categorical_accuracy: 0.2781 - val_top-3: 0.4910 - val_ROC-AUC: 0.7258 - val_PR-AUC: 0.3177 - val_precision: 0.8549 - val_recall: 0.1107 - val_TP: 666.0000 - val_TN: 66063.0000 - val_FP: 113.0000 - val_FN: 5350.0000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 122s 866ms/step - loss: 1.9912 - categorical_accuracy: 0.3133 - top-3: 0.5530 - ROC-AUC: 0.7695 - PR-AUC: 0.3507 - precision: 0.7354 - recall: 0.1417 - TP: 1276.0000 - TN: 98629.0000 - FP: 459.0000 - FN: 7732.0000 - val_loss: 2.0743 - val_categorical_accuracy: 0.2759 - val_top-3: 0.4958 - val_ROC-AUC: 0.7278 - val_PR-AUC: 0.3167 - val_precision: 0.8553 - val_recall: 0.1080 - val_TP: 650.0000 - val_TN: 66066.0000 - val_FP: 110.0000 - val_FN: 5366.0000\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 125s 885ms/step - loss: 1.9771 - categorical_accuracy: 0.3213 - top-3: 0.5546 - ROC-AUC: 0.7724 - PR-AUC: 0.3583 - precision: 0.7549 - recall: 0.1488 - TP: 1340.0000 - TN: 98653.0000 - FP: 435.0000 - FN: 7668.0000 - val_loss: 2.0706 - val_categorical_accuracy: 0.2861 - val_top-3: 0.5020 - val_ROC-AUC: 0.7292 - val_PR-AUC: 0.3232 - val_precision: 0.8720 - val_recall: 0.1144 - val_TP: 688.0000 - val_TN: 66075.0000 - val_FP: 101.0000 - val_FN: 5328.0000\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 121s 861ms/step - loss: 1.9959 - categorical_accuracy: 0.3124 - top-3: 0.5515 - ROC-AUC: 0.7677 - PR-AUC: 0.3503 - precision: 0.7304 - recall: 0.1441 - TP: 1298.0000 - TN: 98609.0000 - FP: 479.0000 - FN: 7710.0000 - val_loss: 2.0641 - val_categorical_accuracy: 0.2849 - val_top-3: 0.5005 - val_ROC-AUC: 0.7311 - val_PR-AUC: 0.3257 - val_precision: 0.8668 - val_recall: 0.1125 - val_TP: 677.0000 - val_TN: 66072.0000 - val_FP: 104.0000 - val_FN: 5339.0000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 122s 866ms/step - loss: 1.9839 - categorical_accuracy: 0.3135 - top-3: 0.5551 - ROC-AUC: 0.7704 - PR-AUC: 0.3490 - precision: 0.7245 - recall: 0.1378 - TP: 1241.0000 - TN: 98616.0000 - FP: 472.0000 - FN: 7767.0000 - val_loss: 2.0875 - val_categorical_accuracy: 0.2708 - val_top-3: 0.4882 - val_ROC-AUC: 0.7214 - val_PR-AUC: 0.3117 - val_precision: 0.8752 - val_recall: 0.1084 - val_TP: 652.0000 - val_TN: 66083.0000 - val_FP: 93.0000 - val_FN: 5364.0000\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 121s 860ms/step - loss: 1.9899 - categorical_accuracy: 0.3147 - top-3: 0.5487 - ROC-AUC: 0.7686 - PR-AUC: 0.3500 - precision: 0.7366 - recall: 0.1419 - TP: 1278.0000 - TN: 98631.0000 - FP: 457.0000 - FN: 7730.0000 - val_loss: 2.0758 - val_categorical_accuracy: 0.2689 - val_top-3: 0.4850 - val_ROC-AUC: 0.7254 - val_PR-AUC: 0.3172 - val_precision: 0.8450 - val_recall: 0.1160 - val_TP: 698.0000 - val_TN: 66048.0000 - val_FP: 128.0000 - val_FN: 5318.0000\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 120s 853ms/step - loss: 1.9695 - categorical_accuracy: 0.3169 - top-3: 0.5581 - ROC-AUC: 0.7731 - PR-AUC: 0.3587 - precision: 0.7628 - recall: 0.1474 - TP: 1328.0000 - TN: 98675.0000 - FP: 413.0000 - FN: 7680.0000 - val_loss: 2.0759 - val_categorical_accuracy: 0.2778 - val_top-3: 0.4834 - val_ROC-AUC: 0.7253 - val_PR-AUC: 0.3186 - val_precision: 0.8628 - val_recall: 0.1192 - val_TP: 717.0000 - val_TN: 66062.0000 - val_FP: 114.0000 - val_FN: 5299.0000\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 122s 864ms/step - loss: 1.9800 - categorical_accuracy: 0.3155 - top-3: 0.5543 - ROC-AUC: 0.7698 - PR-AUC: 0.3531 - precision: 0.7416 - recall: 0.1453 - TP: 1309.0000 - TN: 98632.0000 - FP: 456.0000 - FN: 7699.0000 - val_loss: 2.0763 - val_categorical_accuracy: 0.2801 - val_top-3: 0.4982 - val_ROC-AUC: 0.7271 - val_PR-AUC: 0.3190 - val_precision: 0.8545 - val_recall: 0.1152 - val_TP: 693.0000 - val_TN: 66058.0000 - val_FP: 118.0000 - val_FN: 5323.0000\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 120s 851ms/step - loss: 1.9795 - categorical_accuracy: 0.3162 - top-3: 0.5525 - ROC-AUC: 0.7728 - PR-AUC: 0.3536 - precision: 0.7386 - recall: 0.1443 - TP: 1300.0000 - TN: 98628.0000 - FP: 460.0000 - FN: 7708.0000 - val_loss: 2.0617 - val_categorical_accuracy: 0.2861 - val_top-3: 0.5017 - val_ROC-AUC: 0.7327 - val_PR-AUC: 0.3256 - val_precision: 0.8395 - val_recall: 0.1165 - val_TP: 701.0000 - val_TN: 66042.0000 - val_FP: 134.0000 - val_FN: 5315.0000\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 122s 864ms/step - loss: 1.9761 - categorical_accuracy: 0.3184 - top-3: 0.5576 - ROC-AUC: 0.7727 - PR-AUC: 0.3545 - precision: 0.7361 - recall: 0.1455 - TP: 1311.0000 - TN: 98618.0000 - FP: 470.0000 - FN: 7697.0000 - val_loss: 2.0780 - val_categorical_accuracy: 0.2809 - val_top-3: 0.4965 - val_ROC-AUC: 0.7259 - val_PR-AUC: 0.3171 - val_precision: 0.8456 - val_recall: 0.1147 - val_TP: 690.0000 - val_TN: 66050.0000 - val_FP: 126.0000 - val_FN: 5326.0000\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 122s 867ms/step - loss: 1.9805 - categorical_accuracy: 0.3216 - top-3: 0.5544 - ROC-AUC: 0.7703 - PR-AUC: 0.3554 - precision: 0.7474 - recall: 0.1459 - TP: 1314.0000 - TN: 98644.0000 - FP: 444.0000 - FN: 7694.0000 - val_loss: 2.0810 - val_categorical_accuracy: 0.2798 - val_top-3: 0.4914 - val_ROC-AUC: 0.7248 - val_PR-AUC: 0.3153 - val_precision: 0.8360 - val_recall: 0.1110 - val_TP: 668.0000 - val_TN: 66045.0000 - val_FP: 131.0000 - val_FN: 5348.0000\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 123s 869ms/step - loss: 1.9930 - categorical_accuracy: 0.3117 - top-3: 0.5510 - ROC-AUC: 0.7687 - PR-AUC: 0.3506 - precision: 0.7458 - recall: 0.1440 - TP: 1297.0000 - TN: 98646.0000 - FP: 442.0000 - FN: 7711.0000 - val_loss: 2.0738 - val_categorical_accuracy: 0.2812 - val_top-3: 0.4839 - val_ROC-AUC: 0.7258 - val_PR-AUC: 0.3161 - val_precision: 0.8482 - val_recall: 0.1152 - val_TP: 693.0000 - val_TN: 66052.0000 - val_FP: 124.0000 - val_FN: 5323.0000\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 122s 865ms/step - loss: 1.9764 - categorical_accuracy: 0.3195 - top-3: 0.5566 - ROC-AUC: 0.7709 - PR-AUC: 0.3550 - precision: 0.7451 - recall: 0.1441 - TP: 1298.0000 - TN: 98644.0000 - FP: 444.0000 - FN: 7710.0000 - val_loss: 2.0751 - val_categorical_accuracy: 0.2899 - val_top-3: 0.4980 - val_ROC-AUC: 0.7277 - val_PR-AUC: 0.3224 - val_precision: 0.8372 - val_recall: 0.1145 - val_TP: 689.0000 - val_TN: 66042.0000 - val_FP: 134.0000 - val_FN: 5327.0000\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 121s 860ms/step - loss: 1.9882 - categorical_accuracy: 0.3097 - top-3: 0.5480 - ROC-AUC: 0.7681 - PR-AUC: 0.3513 - precision: 0.7403 - recall: 0.1462 - TP: 1317.0000 - TN: 98626.0000 - FP: 462.0000 - FN: 7691.0000 - val_loss: 2.0616 - val_categorical_accuracy: 0.2842 - val_top-3: 0.4950 - val_ROC-AUC: 0.7295 - val_PR-AUC: 0.3263 - val_precision: 0.8410 - val_recall: 0.1213 - val_TP: 730.0000 - val_TN: 66038.0000 - val_FP: 138.0000 - val_FN: 5286.0000\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 122s 864ms/step - loss: 1.9821 - categorical_accuracy: 0.3169 - top-3: 0.5492 - ROC-AUC: 0.7714 - PR-AUC: 0.3573 - precision: 0.7384 - recall: 0.1501 - TP: 1352.0000 - TN: 98609.0000 - FP: 479.0000 - FN: 7656.0000 - val_loss: 2.0648 - val_categorical_accuracy: 0.2804 - val_top-3: 0.4932 - val_ROC-AUC: 0.7307 - val_PR-AUC: 0.3245 - val_precision: 0.8788 - val_recall: 0.1157 - val_TP: 696.0000 - val_TN: 66080.0000 - val_FP: 96.0000 - val_FN: 5320.0000\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 123s 873ms/step - loss: 1.9736 - categorical_accuracy: 0.3197 - top-3: 0.5588 - ROC-AUC: 0.7743 - PR-AUC: 0.3590 - precision: 0.7372 - recall: 0.1485 - TP: 1338.0000 - TN: 98611.0000 - FP: 477.0000 - FN: 7670.0000 - val_loss: 2.0632 - val_categorical_accuracy: 0.2904 - val_top-3: 0.4938 - val_ROC-AUC: 0.7291 - val_PR-AUC: 0.3272 - val_precision: 0.8780 - val_recall: 0.1160 - val_TP: 698.0000 - val_TN: 66079.0000 - val_FP: 97.0000 - val_FN: 5318.0000\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 122s 863ms/step - loss: 1.9722 - categorical_accuracy: 0.3208 - top-3: 0.5592 - ROC-AUC: 0.7742 - PR-AUC: 0.3596 - precision: 0.7479 - recall: 0.1475 - TP: 1329.0000 - TN: 98640.0000 - FP: 448.0000 - FN: 7679.0000 - val_loss: 2.0857 - val_categorical_accuracy: 0.2774 - val_top-3: 0.4895 - val_ROC-AUC: 0.7243 - val_PR-AUC: 0.3134 - val_precision: 0.8220 - val_recall: 0.1144 - val_TP: 688.0000 - val_TN: 66027.0000 - val_FP: 149.0000 - val_FN: 5328.0000\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 127s 902ms/step - loss: 1.9735 - categorical_accuracy: 0.3228 - top-3: 0.5566 - ROC-AUC: 0.7721 - PR-AUC: 0.3582 - precision: 0.7514 - recall: 0.1523 - TP: 1372.0000 - TN: 98634.0000 - FP: 454.0000 - FN: 7636.0000 - val_loss: 2.0544 - val_categorical_accuracy: 0.2817 - val_top-3: 0.4993 - val_ROC-AUC: 0.7310 - val_PR-AUC: 0.3279 - val_precision: 0.8710 - val_recall: 0.1212 - val_TP: 729.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 5287.0000\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 126s 890ms/step - loss: 1.9717 - categorical_accuracy: 0.3234 - top-3: 0.5607 - ROC-AUC: 0.7745 - PR-AUC: 0.3601 - precision: 0.7397 - recall: 0.1518 - TP: 1367.0000 - TN: 98607.0000 - FP: 481.0000 - FN: 7641.0000 - val_loss: 2.0671 - val_categorical_accuracy: 0.2832 - val_top-3: 0.4987 - val_ROC-AUC: 0.7268 - val_PR-AUC: 0.3227 - val_precision: 0.8598 - val_recall: 0.1162 - val_TP: 699.0000 - val_TN: 66062.0000 - val_FP: 114.0000 - val_FN: 5317.0000\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 125s 885ms/step - loss: 1.9864 - categorical_accuracy: 0.3092 - top-3: 0.5510 - ROC-AUC: 0.7702 - PR-AUC: 0.3530 - precision: 0.7313 - recall: 0.1495 - TP: 1347.0000 - TN: 98593.0000 - FP: 495.0000 - FN: 7661.0000 - val_loss: 2.0734 - val_categorical_accuracy: 0.2758 - val_top-3: 0.5028 - val_ROC-AUC: 0.7309 - val_PR-AUC: 0.3179 - val_precision: 0.8358 - val_recall: 0.1109 - val_TP: 667.0000 - val_TN: 66045.0000 - val_FP: 131.0000 - val_FN: 5349.0000\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 123s 869ms/step - loss: 1.9660 - categorical_accuracy: 0.3229 - top-3: 0.5605 - ROC-AUC: 0.7737 - PR-AUC: 0.3606 - precision: 0.7497 - recall: 0.1506 - TP: 1357.0000 - TN: 98635.0000 - FP: 453.0000 - FN: 7651.0000 - val_loss: 2.0668 - val_categorical_accuracy: 0.2849 - val_top-3: 0.4882 - val_ROC-AUC: 0.7321 - val_PR-AUC: 0.3237 - val_precision: 0.8290 - val_recall: 0.1160 - val_TP: 698.0000 - val_TN: 66032.0000 - val_FP: 144.0000 - val_FN: 5318.0000\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 125s 887ms/step - loss: 1.9823 - categorical_accuracy: 0.3192 - top-3: 0.5534 - ROC-AUC: 0.7707 - PR-AUC: 0.3565 - precision: 0.7296 - recall: 0.1501 - TP: 1352.0000 - TN: 98587.0000 - FP: 501.0000 - FN: 7656.0000 - val_loss: 2.0679 - val_categorical_accuracy: 0.2872 - val_top-3: 0.5028 - val_ROC-AUC: 0.7304 - val_PR-AUC: 0.3235 - val_precision: 0.8631 - val_recall: 0.1132 - val_TP: 681.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 5335.0000\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 125s 887ms/step - loss: 1.9906 - categorical_accuracy: 0.3176 - top-3: 0.5543 - ROC-AUC: 0.7714 - PR-AUC: 0.3505 - precision: 0.7189 - recall: 0.1468 - TP: 1322.0000 - TN: 98571.0000 - FP: 517.0000 - FN: 7686.0000 - val_loss: 2.0735 - val_categorical_accuracy: 0.2851 - val_top-3: 0.4952 - val_ROC-AUC: 0.7267 - val_PR-AUC: 0.3191 - val_precision: 0.8394 - val_recall: 0.1104 - val_TP: 664.0000 - val_TN: 66049.0000 - val_FP: 127.0000 - val_FN: 5352.0000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 119s 844ms/step - loss: 1.9710 - categorical_accuracy: 0.3146 - top-3: 0.5532 - ROC-AUC: 0.7740 - PR-AUC: 0.3582 - precision: 0.7451 - recall: 0.1505 - TP: 1356.0000 - TN: 98624.0000 - FP: 464.0000 - FN: 7652.0000 - val_loss: 2.0917 - val_categorical_accuracy: 0.2685 - val_top-3: 0.4850 - val_ROC-AUC: 0.7211 - val_PR-AUC: 0.3105 - val_precision: 0.8555 - val_recall: 0.1132 - val_TP: 681.0000 - val_TN: 66061.0000 - val_FP: 115.0000 - val_FN: 5335.0000\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 122s 868ms/step - loss: 1.9795 - categorical_accuracy: 0.3151 - top-3: 0.5564 - ROC-AUC: 0.7724 - PR-AUC: 0.3548 - precision: 0.7468 - recall: 0.1470 - TP: 1324.0000 - TN: 98639.0000 - FP: 449.0000 - FN: 7684.0000 - val_loss: 2.0749 - val_categorical_accuracy: 0.2778 - val_top-3: 0.4945 - val_ROC-AUC: 0.7261 - val_PR-AUC: 0.3179 - val_precision: 0.8537 - val_recall: 0.1105 - val_TP: 665.0000 - val_TN: 66062.0000 - val_FP: 114.0000 - val_FN: 5351.0000\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 120s 853ms/step - loss: 1.9850 - categorical_accuracy: 0.3172 - top-3: 0.5554 - ROC-AUC: 0.7724 - PR-AUC: 0.3550 - precision: 0.7421 - recall: 0.1489 - TP: 1341.0000 - TN: 98622.0000 - FP: 466.0000 - FN: 7667.0000 - val_loss: 2.0678 - val_categorical_accuracy: 0.2841 - val_top-3: 0.4874 - val_ROC-AUC: 0.7268 - val_PR-AUC: 0.3238 - val_precision: 0.8577 - val_recall: 0.1192 - val_TP: 717.0000 - val_TN: 66057.0000 - val_FP: 119.0000 - val_FN: 5299.0000\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 123s 875ms/step - loss: 1.9777 - categorical_accuracy: 0.3182 - top-3: 0.5515 - ROC-AUC: 0.7705 - PR-AUC: 0.3567 - precision: 0.7528 - recall: 0.1508 - TP: 1358.0000 - TN: 98642.0000 - FP: 446.0000 - FN: 7650.0000 - val_loss: 2.0718 - val_categorical_accuracy: 0.2788 - val_top-3: 0.4942 - val_ROC-AUC: 0.7261 - val_PR-AUC: 0.3171 - val_precision: 0.8294 - val_recall: 0.1164 - val_TP: 700.0000 - val_TN: 66032.0000 - val_FP: 144.0000 - val_FN: 5316.0000\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 125s 887ms/step - loss: 1.9812 - categorical_accuracy: 0.3151 - top-3: 0.5571 - ROC-AUC: 0.7723 - PR-AUC: 0.3534 - precision: 0.7200 - recall: 0.1473 - TP: 1327.0000 - TN: 98572.0000 - FP: 516.0000 - FN: 7681.0000 - val_loss: 2.0811 - val_categorical_accuracy: 0.2739 - val_top-3: 0.4912 - val_ROC-AUC: 0.7235 - val_PR-AUC: 0.3162 - val_precision: 0.8723 - val_recall: 0.1090 - val_TP: 656.0000 - val_TN: 66080.0000 - val_FP: 96.0000 - val_FN: 5360.0000\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 123s 872ms/step - loss: 1.9742 - categorical_accuracy: 0.3202 - top-3: 0.5538 - ROC-AUC: 0.7725 - PR-AUC: 0.3587 - precision: 0.7375 - recall: 0.1538 - TP: 1385.0000 - TN: 98595.0000 - FP: 493.0000 - FN: 7623.0000 - val_loss: 2.0682 - val_categorical_accuracy: 0.2864 - val_top-3: 0.4943 - val_ROC-AUC: 0.7291 - val_PR-AUC: 0.3232 - val_precision: 0.8584 - val_recall: 0.1169 - val_TP: 703.0000 - val_TN: 66060.0000 - val_FP: 116.0000 - val_FN: 5313.0000\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 120s 853ms/step - loss: 1.9784 - categorical_accuracy: 0.3214 - top-3: 0.5578 - ROC-AUC: 0.7724 - PR-AUC: 0.3580 - precision: 0.7451 - recall: 0.1519 - TP: 1368.0000 - TN: 98620.0000 - FP: 468.0000 - FN: 7640.0000 - val_loss: 2.0736 - val_categorical_accuracy: 0.2756 - val_top-3: 0.4967 - val_ROC-AUC: 0.7273 - val_PR-AUC: 0.3183 - val_precision: 0.8271 - val_recall: 0.1177 - val_TP: 708.0000 - val_TN: 66028.0000 - val_FP: 148.0000 - val_FN: 5308.0000\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 118s 839ms/step - loss: 1.9652 - categorical_accuracy: 0.3206 - top-3: 0.5619 - ROC-AUC: 0.7763 - PR-AUC: 0.3609 - precision: 0.7433 - recall: 0.1536 - TP: 1384.0000 - TN: 98610.0000 - FP: 478.0000 - FN: 7624.0000 - val_loss: 2.0627 - val_categorical_accuracy: 0.2831 - val_top-3: 0.4945 - val_ROC-AUC: 0.7321 - val_PR-AUC: 0.3231 - val_precision: 0.8265 - val_recall: 0.1140 - val_TP: 686.0000 - val_TN: 66032.0000 - val_FP: 144.0000 - val_FN: 5330.0000\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 121s 855ms/step - loss: 1.9718 - categorical_accuracy: 0.3190 - top-3: 0.5542 - ROC-AUC: 0.7731 - PR-AUC: 0.3593 - precision: 0.7267 - recall: 0.1496 - TP: 1348.0000 - TN: 98581.0000 - FP: 507.0000 - FN: 7660.0000 - val_loss: 2.0585 - val_categorical_accuracy: 0.2841 - val_top-3: 0.5078 - val_ROC-AUC: 0.7348 - val_PR-AUC: 0.3275 - val_precision: 0.8499 - val_recall: 0.1195 - val_TP: 719.0000 - val_TN: 66049.0000 - val_FP: 127.0000 - val_FN: 5297.0000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 119s 842ms/step - loss: 1.9768 - categorical_accuracy: 0.3212 - top-3: 0.5623 - ROC-AUC: 0.7730 - PR-AUC: 0.3578 - precision: 0.7376 - recall: 0.1489 - TP: 1341.0000 - TN: 98611.0000 - FP: 477.0000 - FN: 7667.0000 - val_loss: 2.0711 - val_categorical_accuracy: 0.2799 - val_top-3: 0.4880 - val_ROC-AUC: 0.7283 - val_PR-AUC: 0.3203 - val_precision: 0.8648 - val_recall: 0.1149 - val_TP: 691.0000 - val_TN: 66068.0000 - val_FP: 108.0000 - val_FN: 5325.0000\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 118s 836ms/step - loss: 1.9814 - categorical_accuracy: 0.3210 - top-3: 0.5595 - ROC-AUC: 0.7707 - PR-AUC: 0.3548 - precision: 0.7490 - recall: 0.1508 - TP: 1358.0000 - TN: 98633.0000 - FP: 455.0000 - FN: 7650.0000 - val_loss: 2.0808 - val_categorical_accuracy: 0.2791 - val_top-3: 0.4894 - val_ROC-AUC: 0.7253 - val_PR-AUC: 0.3166 - val_precision: 0.8500 - val_recall: 0.1130 - val_TP: 680.0000 - val_TN: 66056.0000 - val_FP: 120.0000 - val_FN: 5336.0000\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 118s 839ms/step - loss: 1.9641 - categorical_accuracy: 0.3175 - top-3: 0.5535 - ROC-AUC: 0.7731 - PR-AUC: 0.3607 - precision: 0.7599 - recall: 0.1518 - TP: 1367.0000 - TN: 98656.0000 - FP: 432.0000 - FN: 7641.0000 - val_loss: 2.0574 - val_categorical_accuracy: 0.2839 - val_top-3: 0.4950 - val_ROC-AUC: 0.7318 - val_PR-AUC: 0.3243 - val_precision: 0.8375 - val_recall: 0.1182 - val_TP: 711.0000 - val_TN: 66038.0000 - val_FP: 138.0000 - val_FN: 5305.0000\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 118s 840ms/step - loss: 1.9588 - categorical_accuracy: 0.3242 - top-3: 0.5654 - ROC-AUC: 0.7747 - PR-AUC: 0.3640 - precision: 0.7469 - recall: 0.1556 - TP: 1402.0000 - TN: 98613.0000 - FP: 475.0000 - FN: 7606.0000 - val_loss: 2.0868 - val_categorical_accuracy: 0.2768 - val_top-3: 0.4884 - val_ROC-AUC: 0.7225 - val_PR-AUC: 0.3150 - val_precision: 0.8457 - val_recall: 0.1139 - val_TP: 685.0000 - val_TN: 66051.0000 - val_FP: 125.0000 - val_FN: 5331.0000\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 120s 850ms/step - loss: 1.9619 - categorical_accuracy: 0.3233 - top-3: 0.5616 - ROC-AUC: 0.7761 - PR-AUC: 0.3626 - precision: 0.7352 - recall: 0.1525 - TP: 1374.0000 - TN: 98593.0000 - FP: 495.0000 - FN: 7634.0000 - val_loss: 2.0645 - val_categorical_accuracy: 0.2834 - val_top-3: 0.4962 - val_ROC-AUC: 0.7297 - val_PR-AUC: 0.3217 - val_precision: 0.8538 - val_recall: 0.1165 - val_TP: 701.0000 - val_TN: 66056.0000 - val_FP: 120.0000 - val_FN: 5315.0000\n",
      "-----\n",
      "(6122788.83 ms) == (102m:2s)\n",
      "-----\n",
      "\n",
      "\n",
      "25\n",
      "['mobilenetv2_1.00_32-imagenet224-64-12.tensorboard',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.001_0.2502_2.1762.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.002_0.2548_2.1361.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.003_0.2571_2.1357.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.004_0.2726_2.1119.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.005_0.2776_2.0979.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.006_0.2739_2.0816.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.008_0.2822_2.0809.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.011_0.2842_2.0631.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.016_0.2861_2.0706.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.022_0.2861_2.0617.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.026_0.2899_2.0751.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.027_0.2842_2.0616.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.029_0.2904_2.0632.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.031_0.2817_2.0544.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_32-imagenet224-64-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_32-imagenet224-64-12.csv',\n",
      " 'model.mobilenetv2_1.00_32-imagenet224-64-12.h5',\n",
      " 'weights.mobilenetv2_1.00_32-imagenet224-64-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_32-imagenet224-64-12\n",
    "model32imagenet2246412 = consecutiveModelTraining(\n",
    "    input_size=32,\n",
    "    batch_size=64,\n",
    "    weights='imagenet',\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0ba704-c3e8-4ce9-be59-c0e3da6b591c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T19:07:11.432912Z",
     "iopub.status.busy": "2021-06-09T19:07:11.431906Z",
     "iopub.status.idle": "2021-06-09T19:07:11.510912Z",
     "shell.execute_reply": "2021-06-09T19:07:11.509909Z",
     "shell.execute_reply.started": "2021-06-09T19:07:11.432912Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.987698</td>\n",
       "      <td>0.315007</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.769386</td>\n",
       "      <td>0.352096</td>\n",
       "      <td>0.748137</td>\n",
       "      <td>0.142320</td>\n",
       "      <td>1282.020000</td>\n",
       "      <td>98651.060000</td>\n",
       "      <td>436.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278225</td>\n",
       "      <td>0.492410</td>\n",
       "      <td>0.725594</td>\n",
       "      <td>0.317195</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.110618</td>\n",
       "      <td>665.480000</td>\n",
       "      <td>66062.360000</td>\n",
       "      <td>113.640000</td>\n",
       "      <td>5350.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.011944</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>154.197526</td>\n",
       "      <td>75.057912</td>\n",
       "      <td>75.057912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>58.739911</td>\n",
       "      <td>21.091405</td>\n",
       "      <td>21.091405</td>\n",
       "      <td>58.739911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.958833</td>\n",
       "      <td>0.253885</td>\n",
       "      <td>0.480240</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>0.266001</td>\n",
       "      <td>0.718869</td>\n",
       "      <td>0.046070</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>98571.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250166</td>\n",
       "      <td>0.468418</td>\n",
       "      <td>0.700570</td>\n",
       "      <td>0.282074</td>\n",
       "      <td>0.821983</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>66027.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.974665</td>\n",
       "      <td>0.313999</td>\n",
       "      <td>0.551621</td>\n",
       "      <td>0.769347</td>\n",
       "      <td>0.350603</td>\n",
       "      <td>0.737521</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>1277.250000</td>\n",
       "      <td>98611.500000</td>\n",
       "      <td>435.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275474</td>\n",
       "      <td>0.488198</td>\n",
       "      <td>0.723724</td>\n",
       "      <td>0.315070</td>\n",
       "      <td>0.845174</td>\n",
       "      <td>0.108544</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>66049.000000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>5318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.980890</td>\n",
       "      <td>0.316940</td>\n",
       "      <td>0.554341</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.354837</td>\n",
       "      <td>0.745077</td>\n",
       "      <td>0.146536</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>98633.500000</td>\n",
       "      <td>454.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279837</td>\n",
       "      <td>0.494016</td>\n",
       "      <td>0.726763</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.854129</td>\n",
       "      <td>0.113863</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>66062.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>5331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.990420</td>\n",
       "      <td>0.320493</td>\n",
       "      <td>0.557837</td>\n",
       "      <td>0.772796</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.752498</td>\n",
       "      <td>0.150089</td>\n",
       "      <td>1352.000000</td>\n",
       "      <td>98652.500000</td>\n",
       "      <td>476.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284034</td>\n",
       "      <td>0.496676</td>\n",
       "      <td>0.729411</td>\n",
       "      <td>0.323205</td>\n",
       "      <td>0.865935</td>\n",
       "      <td>0.116024</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>66071.500000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>5363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.198852</td>\n",
       "      <td>0.324156</td>\n",
       "      <td>0.565386</td>\n",
       "      <td>0.776340</td>\n",
       "      <td>0.363975</td>\n",
       "      <td>0.845214</td>\n",
       "      <td>0.155639</td>\n",
       "      <td>1402.000000</td>\n",
       "      <td>99012.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290392</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.734753</td>\n",
       "      <td>0.327935</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.121343</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>66136.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>5600.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    1.987698              0.315007   0.552877   0.769386   0.352096   \n",
       "std     0.034435              0.010603   0.011944   0.009475   0.014181   \n",
       "min     1.958833              0.253885   0.480240   0.709217   0.266001   \n",
       "25%     1.974665              0.313999   0.551621   0.769347   0.350603   \n",
       "50%     1.980890              0.316940   0.554341   0.770769   0.354837   \n",
       "75%     1.990420              0.320493   0.557837   0.772796   0.358222   \n",
       "max     2.198852              0.324156   0.565386   0.776340   0.363975   \n",
       "\n",
       "       precision     recall           TP            TN          FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000   50.000000  ...   \n",
       "mean    0.748137   0.142320  1282.020000  98651.060000  436.940000  ...   \n",
       "std     0.020363   0.017118   154.197526     75.057912   75.057912  ...   \n",
       "min     0.718869   0.046070   415.000000  98571.000000   76.000000  ...   \n",
       "25%     0.737521   0.141791  1277.250000  98611.500000  435.500000  ...   \n",
       "50%     0.745077   0.146536  1320.000000  98633.500000  454.500000  ...   \n",
       "75%     0.752498   0.150089  1352.000000  98652.500000  476.500000  ...   \n",
       "max     0.845214   0.155639  1402.000000  99012.000000  517.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.278225   0.492410     0.725594    0.317195   \n",
       "std                    0.008190   0.007699     0.006168    0.009055   \n",
       "min                    0.250166   0.468418     0.700570    0.282074   \n",
       "25%                    0.275474   0.488198     0.723724    0.315070   \n",
       "50%                    0.279837   0.494016     0.726763    0.317919   \n",
       "75%                    0.284034   0.496676     0.729411    0.323205   \n",
       "max                    0.290392   0.507812     0.734753    0.327935   \n",
       "\n",
       "       val_precision  val_recall      val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000   50.000000     50.000000   50.000000   \n",
       "mean        0.855271    0.110618  665.480000  66062.360000  113.640000   \n",
       "std         0.017571    0.009764   58.739911     21.091405   21.091405   \n",
       "min         0.821983    0.069149  416.000000  66027.000000   40.000000   \n",
       "25%         0.845174    0.108544  653.000000  66049.000000  104.500000   \n",
       "50%         0.854129    0.113863  685.000000  66062.000000  114.000000   \n",
       "75%         0.865935    0.116024  698.000000  66071.500000  127.000000   \n",
       "max         0.912281    0.121343  730.000000  66136.000000  149.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean   5350.520000  \n",
       "std      58.739911  \n",
       "min    5286.000000  \n",
       "25%    5318.000000  \n",
       "50%    5331.000000  \n",
       "75%    5363.000000  \n",
       "max    5600.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model32imagenet2246412['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20c3a4-95f8-4b1d-82b0-4637593aadea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d87c9f84-3813-4699-951c-c2bcf7a15d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T19:07:12.120954Z",
     "iopub.status.busy": "2021-06-09T19:07:12.120954Z",
     "iopub.status.idle": "2021-06-09T21:19:31.035161Z",
     "shell.execute_reply": "2021-06-09T21:19:31.035161Z",
     "shell.execute_reply.started": "2021-06-09T19:07:12.120954Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_96-imagenet96-64-fc12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_96-imagenet96-64-fc12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,686,156\n",
      "Trainable params: 428,172\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 64,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 141,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 94}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_96-imagenet96-64-fc12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_96-imagenet96-64-fc12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_96-imagenet96-64-fc12\n",
      "Epoch 1/50\n",
      "  2/141 [..............................] - ETA: 10:21 - loss: 5.8479 - categorical_accuracy: 0.0859 - top-3: 0.2031 - ROC-AUC: 0.4946 - PR-AUC: 0.0850 - precision: 0.1452 - recall: 0.0703 - TP: 9.0000 - TN: 1355.0000 - FP: 53.0000 - FN: 119.0000          WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7001s vs `on_train_batch_end` time: 8.2436s). Check your callbacks.\n",
      "141/141 [==============================] - 171s 1s/step - loss: 0.8152 - categorical_accuracy: 0.7518 - top-3: 0.8908 - ROC-AUC: 0.9665 - PR-AUC: 0.8525 - precision: 0.8879 - recall: 0.6825 - TP: 6148.0000 - TN: 98312.0000 - FP: 776.0000 - FN: 2860.0000 - val_loss: 0.1498 - val_categorical_accuracy: 0.9511 - val_top-3: 0.9960 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9881 - val_precision: 0.9597 - val_recall: 0.9423 - val_TP: 5669.0000 - val_TN: 65938.0000 - val_FP: 238.0000 - val_FN: 347.0000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.3035 - categorical_accuracy: 0.9112 - top-3: 0.9827 - ROC-AUC: 0.9925 - PR-AUC: 0.9645 - precision: 0.9342 - recall: 0.8904 - TP: 8021.0000 - TN: 98523.0000 - FP: 565.0000 - FN: 987.0000 - val_loss: 0.0802 - val_categorical_accuracy: 0.9779 - val_top-3: 0.9942 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9963 - val_precision: 0.9847 - val_recall: 0.9726 - val_TP: 5851.0000 - val_TN: 66085.0000 - val_FP: 91.0000 - val_FN: 165.0000\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.2200 - categorical_accuracy: 0.9368 - top-3: 0.9892 - ROC-AUC: 0.9947 - PR-AUC: 0.9769 - precision: 0.9541 - recall: 0.9221 - TP: 8306.0000 - TN: 98688.0000 - FP: 400.0000 - FN: 702.0000 - val_loss: 0.1024 - val_categorical_accuracy: 0.9717 - val_top-3: 0.9960 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9945 - val_precision: 0.9814 - val_recall: 0.9581 - val_TP: 5764.0000 - val_TN: 66067.0000 - val_FP: 109.0000 - val_FN: 252.0000\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 160s 1s/step - loss: 0.1775 - categorical_accuracy: 0.9516 - top-3: 0.9905 - ROC-AUC: 0.9960 - PR-AUC: 0.9833 - precision: 0.9638 - recall: 0.9389 - TP: 8458.0000 - TN: 98770.0000 - FP: 318.0000 - FN: 550.0000 - val_loss: 0.0276 - val_categorical_accuracy: 0.9934 - val_top-3: 0.9980 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9983 - val_precision: 0.9952 - val_recall: 0.9922 - val_TP: 5969.0000 - val_TN: 66147.0000 - val_FP: 29.0000 - val_FN: 47.0000\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1847 - categorical_accuracy: 0.9500 - top-3: 0.9908 - ROC-AUC: 0.9956 - PR-AUC: 0.9827 - precision: 0.9631 - recall: 0.9389 - TP: 8458.0000 - TN: 98764.0000 - FP: 324.0000 - FN: 550.0000 - val_loss: 0.1016 - val_categorical_accuracy: 0.9706 - val_top-3: 0.9952 - val_ROC-AUC: 0.9980 - val_PR-AUC: 0.9930 - val_precision: 0.9787 - val_recall: 0.9628 - val_TP: 5792.0000 - val_TN: 66050.0000 - val_FP: 126.0000 - val_FN: 224.0000\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.3043 - categorical_accuracy: 0.9351 - top-3: 0.9826 - ROC-AUC: 0.9918 - PR-AUC: 0.9694 - precision: 0.9510 - recall: 0.9202 - TP: 8289.0000 - TN: 98661.0000 - FP: 427.0000 - FN: 719.0000 - val_loss: 0.0537 - val_categorical_accuracy: 0.9862 - val_top-3: 0.9977 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9979 - val_precision: 0.9917 - val_recall: 0.9786 - val_TP: 5887.0000 - val_TN: 66127.0000 - val_FP: 49.0000 - val_FN: 129.0000\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1689 - categorical_accuracy: 0.9584 - top-3: 0.9906 - ROC-AUC: 0.9963 - PR-AUC: 0.9856 - precision: 0.9706 - recall: 0.9485 - TP: 8544.0000 - TN: 98829.0000 - FP: 259.0000 - FN: 464.0000 - val_loss: 0.0443 - val_categorical_accuracy: 0.9892 - val_top-3: 0.9987 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9975 - val_precision: 0.9921 - val_recall: 0.9859 - val_TP: 5931.0000 - val_TN: 66129.0000 - val_FP: 47.0000 - val_FN: 85.0000\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1781 - categorical_accuracy: 0.9571 - top-3: 0.9897 - ROC-AUC: 0.9959 - PR-AUC: 0.9847 - precision: 0.9707 - recall: 0.9442 - TP: 8505.0000 - TN: 98831.0000 - FP: 257.0000 - FN: 503.0000 - val_loss: 0.0562 - val_categorical_accuracy: 0.9869 - val_top-3: 0.9980 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9952 - val_precision: 0.9890 - val_recall: 0.9855 - val_TP: 5929.0000 - val_TN: 66110.0000 - val_FP: 66.0000 - val_FN: 87.0000\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1829 - categorical_accuracy: 0.9569 - top-3: 0.9898 - ROC-AUC: 0.9953 - PR-AUC: 0.9827 - precision: 0.9674 - recall: 0.9448 - TP: 8511.0000 - TN: 98801.0000 - FP: 287.0000 - FN: 497.0000 - val_loss: 0.0439 - val_categorical_accuracy: 0.9904 - val_top-3: 0.9983 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9987 - val_precision: 0.9940 - val_recall: 0.9844 - val_TP: 5922.0000 - val_TN: 66140.0000 - val_FP: 36.0000 - val_FN: 94.0000\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 160s 1s/step - loss: 0.1405 - categorical_accuracy: 0.9617 - top-3: 0.9915 - ROC-AUC: 0.9971 - PR-AUC: 0.9891 - precision: 0.9741 - recall: 0.9520 - TP: 8576.0000 - TN: 98860.0000 - FP: 228.0000 - FN: 432.0000 - val_loss: 0.0203 - val_categorical_accuracy: 0.9940 - val_top-3: 0.9995 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9992 - val_precision: 0.9953 - val_recall: 0.9924 - val_TP: 5970.0000 - val_TN: 66148.0000 - val_FP: 28.0000 - val_FN: 46.0000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 160s 1s/step - loss: 0.1309 - categorical_accuracy: 0.9688 - top-3: 0.9932 - ROC-AUC: 0.9968 - PR-AUC: 0.9885 - precision: 0.9773 - recall: 0.9604 - TP: 8651.0000 - TN: 98887.0000 - FP: 201.0000 - FN: 357.0000 - val_loss: 0.0609 - val_categorical_accuracy: 0.9820 - val_top-3: 0.9950 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9977 - val_precision: 0.9892 - val_recall: 0.9779 - val_TP: 5883.0000 - val_TN: 66112.0000 - val_FP: 64.0000 - val_FN: 133.0000\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1085 - categorical_accuracy: 0.9707 - top-3: 0.9939 - ROC-AUC: 0.9982 - PR-AUC: 0.9926 - precision: 0.9788 - recall: 0.9633 - TP: 8677.0000 - TN: 98900.0000 - FP: 188.0000 - FN: 331.0000 - val_loss: 0.0312 - val_categorical_accuracy: 0.9934 - val_top-3: 0.9988 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9975 - val_precision: 0.9942 - val_recall: 0.9917 - val_TP: 5966.0000 - val_TN: 66141.0000 - val_FP: 35.0000 - val_FN: 50.0000\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1633 - categorical_accuracy: 0.9604 - top-3: 0.9900 - ROC-AUC: 0.9958 - PR-AUC: 0.9852 - precision: 0.9745 - recall: 0.9493 - TP: 8551.0000 - TN: 98864.0000 - FP: 224.0000 - FN: 457.0000 - val_loss: 0.0320 - val_categorical_accuracy: 0.9932 - val_top-3: 0.9990 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9981 - val_precision: 0.9948 - val_recall: 0.9894 - val_TP: 5952.0000 - val_TN: 66145.0000 - val_FP: 31.0000 - val_FN: 64.0000\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1579 - categorical_accuracy: 0.9614 - top-3: 0.9908 - ROC-AUC: 0.9964 - PR-AUC: 0.9869 - precision: 0.9739 - recall: 0.9512 - TP: 8568.0000 - TN: 98858.0000 - FP: 230.0000 - FN: 440.0000 - val_loss: 0.0502 - val_categorical_accuracy: 0.9910 - val_top-3: 0.9988 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9956 - val_precision: 0.9933 - val_recall: 0.9890 - val_TP: 5950.0000 - val_TN: 66136.0000 - val_FP: 40.0000 - val_FN: 66.0000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1237 - categorical_accuracy: 0.9685 - top-3: 0.9947 - ROC-AUC: 0.9973 - PR-AUC: 0.9905 - precision: 0.9754 - recall: 0.9586 - TP: 8635.0000 - TN: 98870.0000 - FP: 218.0000 - FN: 373.0000 - val_loss: 0.0243 - val_categorical_accuracy: 0.9934 - val_top-3: 0.9992 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9994 - val_precision: 0.9958 - val_recall: 0.9907 - val_TP: 5960.0000 - val_TN: 66151.0000 - val_FP: 25.0000 - val_FN: 56.0000\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1516 - categorical_accuracy: 0.9613 - top-3: 0.9916 - ROC-AUC: 0.9966 - PR-AUC: 0.9871 - precision: 0.9703 - recall: 0.9517 - TP: 8573.0000 - TN: 98826.0000 - FP: 262.0000 - FN: 435.0000 - val_loss: 0.0353 - val_categorical_accuracy: 0.9912 - val_top-3: 0.9995 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9987 - val_precision: 0.9931 - val_recall: 0.9862 - val_TP: 5933.0000 - val_TN: 66135.0000 - val_FP: 41.0000 - val_FN: 83.0000\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1499 - categorical_accuracy: 0.9623 - top-3: 0.9907 - ROC-AUC: 0.9964 - PR-AUC: 0.9880 - precision: 0.9753 - recall: 0.9529 - TP: 8584.0000 - TN: 98871.0000 - FP: 217.0000 - FN: 424.0000 - val_loss: 0.0482 - val_categorical_accuracy: 0.9895 - val_top-3: 0.9980 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9973 - val_precision: 0.9935 - val_recall: 0.9864 - val_TP: 5934.0000 - val_TN: 66137.0000 - val_FP: 39.0000 - val_FN: 82.0000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1388 - categorical_accuracy: 0.9676 - top-3: 0.9931 - ROC-AUC: 0.9968 - PR-AUC: 0.9892 - precision: 0.9766 - recall: 0.9596 - TP: 8644.0000 - TN: 98881.0000 - FP: 207.0000 - FN: 364.0000 - val_loss: 0.0271 - val_categorical_accuracy: 0.9932 - val_top-3: 0.9988 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9980 - val_precision: 0.9950 - val_recall: 0.9914 - val_TP: 5964.0000 - val_TN: 66146.0000 - val_FP: 30.0000 - val_FN: 52.0000\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1320 - categorical_accuracy: 0.9702 - top-3: 0.9915 - ROC-AUC: 0.9965 - PR-AUC: 0.9892 - precision: 0.9791 - recall: 0.9628 - TP: 8673.0000 - TN: 98903.0000 - FP: 185.0000 - FN: 335.0000 - val_loss: 0.0348 - val_categorical_accuracy: 0.9904 - val_top-3: 0.9978 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9988 - val_precision: 0.9945 - val_recall: 0.9862 - val_TP: 5933.0000 - val_TN: 66143.0000 - val_FP: 33.0000 - val_FN: 83.0000\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 161s 1s/step - loss: 0.1387 - categorical_accuracy: 0.9645 - top-3: 0.9919 - ROC-AUC: 0.9968 - PR-AUC: 0.9889 - precision: 0.9768 - recall: 0.9555 - TP: 8607.0000 - TN: 98884.0000 - FP: 204.0000 - FN: 401.0000 - val_loss: 0.0249 - val_categorical_accuracy: 0.9937 - val_top-3: 0.9982 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9983 - val_precision: 0.9958 - val_recall: 0.9927 - val_TP: 5972.0000 - val_TN: 66151.0000 - val_FP: 25.0000 - val_FN: 44.0000\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1268 - categorical_accuracy: 0.9695 - top-3: 0.9929 - ROC-AUC: 0.9971 - PR-AUC: 0.9903 - precision: 0.9787 - recall: 0.9610 - TP: 8657.0000 - TN: 98900.0000 - FP: 188.0000 - FN: 351.0000 - val_loss: 0.0315 - val_categorical_accuracy: 0.9910 - val_top-3: 0.9983 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9987 - val_precision: 0.9930 - val_recall: 0.9897 - val_TP: 5954.0000 - val_TN: 66134.0000 - val_FP: 42.0000 - val_FN: 62.0000\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1292 - categorical_accuracy: 0.9697 - top-3: 0.9910 - ROC-AUC: 0.9974 - PR-AUC: 0.9914 - precision: 0.9794 - recall: 0.9629 - TP: 8674.0000 - TN: 98906.0000 - FP: 182.0000 - FN: 334.0000 - val_loss: 0.0366 - val_categorical_accuracy: 0.9902 - val_top-3: 0.9982 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9980 - val_precision: 0.9931 - val_recall: 0.9877 - val_TP: 5942.0000 - val_TN: 66135.0000 - val_FP: 41.0000 - val_FN: 74.0000\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1727 - categorical_accuracy: 0.9617 - top-3: 0.9896 - ROC-AUC: 0.9953 - PR-AUC: 0.9850 - precision: 0.9725 - recall: 0.9507 - TP: 8564.0000 - TN: 98846.0000 - FP: 242.0000 - FN: 444.0000 - val_loss: 0.0408 - val_categorical_accuracy: 0.9875 - val_top-3: 0.9988 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9971 - val_precision: 0.9901 - val_recall: 0.9855 - val_TP: 5929.0000 - val_TN: 66117.0000 - val_FP: 59.0000 - val_FN: 87.0000\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 155s 1s/step - loss: 0.1577 - categorical_accuracy: 0.9639 - top-3: 0.9892 - ROC-AUC: 0.9959 - PR-AUC: 0.9869 - precision: 0.9763 - recall: 0.9562 - TP: 8613.0000 - TN: 98879.0000 - FP: 209.0000 - FN: 395.0000 - val_loss: 0.0257 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9988 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9985 - val_precision: 0.9952 - val_recall: 0.9907 - val_TP: 5960.0000 - val_TN: 66147.0000 - val_FP: 29.0000 - val_FN: 56.0000\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1229 - categorical_accuracy: 0.9697 - top-3: 0.9918 - ROC-AUC: 0.9974 - PR-AUC: 0.9916 - precision: 0.9807 - recall: 0.9625 - TP: 8670.0000 - TN: 98917.0000 - FP: 171.0000 - FN: 338.0000 - val_loss: 0.0211 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9992 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9984 - val_precision: 0.9953 - val_recall: 0.9937 - val_TP: 5978.0000 - val_TN: 66148.0000 - val_FP: 28.0000 - val_FN: 38.0000\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1815 - categorical_accuracy: 0.9645 - top-3: 0.9879 - ROC-AUC: 0.9957 - PR-AUC: 0.9858 - precision: 0.9784 - recall: 0.9534 - TP: 8588.0000 - TN: 98898.0000 - FP: 190.0000 - FN: 420.0000 - val_loss: 0.0257 - val_categorical_accuracy: 0.9938 - val_top-3: 0.9993 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9987 - val_precision: 0.9958 - val_recall: 0.9919 - val_TP: 5967.0000 - val_TN: 66151.0000 - val_FP: 25.0000 - val_FN: 49.0000\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.2355 - categorical_accuracy: 0.9550 - top-3: 0.9855 - ROC-AUC: 0.9944 - PR-AUC: 0.9823 - precision: 0.9708 - recall: 0.9411 - TP: 8477.0000 - TN: 98833.0000 - FP: 255.0000 - FN: 531.0000 - val_loss: 0.0403 - val_categorical_accuracy: 0.9887 - val_top-3: 0.9975 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9991 - val_precision: 0.9953 - val_recall: 0.9797 - val_TP: 5894.0000 - val_TN: 66148.0000 - val_FP: 28.0000 - val_FN: 122.0000\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.2586 - categorical_accuracy: 0.9383 - top-3: 0.9795 - ROC-AUC: 0.9933 - PR-AUC: 0.9758 - precision: 0.9613 - recall: 0.9206 - TP: 8293.0000 - TN: 98754.0000 - FP: 334.0000 - FN: 715.0000 - val_loss: 0.0547 - val_categorical_accuracy: 0.9882 - val_top-3: 0.9985 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9946 - val_precision: 0.9903 - val_recall: 0.9849 - val_TP: 5925.0000 - val_TN: 66118.0000 - val_FP: 58.0000 - val_FN: 91.0000\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1243 - categorical_accuracy: 0.9668 - top-3: 0.9901 - ROC-AUC: 0.9975 - PR-AUC: 0.9909 - precision: 0.9794 - recall: 0.9573 - TP: 8623.0000 - TN: 98907.0000 - FP: 181.0000 - FN: 385.0000 - val_loss: 0.0576 - val_categorical_accuracy: 0.9855 - val_top-3: 0.9980 - val_ROC-AUC: 0.9983 - val_PR-AUC: 0.9947 - val_precision: 0.9881 - val_recall: 0.9824 - val_TP: 5910.0000 - val_TN: 66105.0000 - val_FP: 71.0000 - val_FN: 106.0000\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 160s 1s/step - loss: 0.1481 - categorical_accuracy: 0.9666 - top-3: 0.9902 - ROC-AUC: 0.9967 - PR-AUC: 0.9891 - precision: 0.9779 - recall: 0.9593 - TP: 8641.0000 - TN: 98893.0000 - FP: 195.0000 - FN: 367.0000 - val_loss: 0.0241 - val_categorical_accuracy: 0.9960 - val_top-3: 0.9985 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9984 - val_precision: 0.9973 - val_recall: 0.9930 - val_TP: 5974.0000 - val_TN: 66160.0000 - val_FP: 16.0000 - val_FN: 42.0000\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1283 - categorical_accuracy: 0.9695 - top-3: 0.9917 - ROC-AUC: 0.9972 - PR-AUC: 0.9908 - precision: 0.9811 - recall: 0.9616 - TP: 8662.0000 - TN: 98921.0000 - FP: 167.0000 - FN: 346.0000 - val_loss: 0.0224 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9983 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9965 - val_recall: 0.9927 - val_TP: 5972.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 44.0000\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1705 - categorical_accuracy: 0.9628 - top-3: 0.9893 - ROC-AUC: 0.9958 - PR-AUC: 0.9855 - precision: 0.9772 - recall: 0.9513 - TP: 8569.0000 - TN: 98888.0000 - FP: 200.0000 - FN: 439.0000 - val_loss: 0.0306 - val_categorical_accuracy: 0.9919 - val_top-3: 0.9990 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9994 - val_precision: 0.9946 - val_recall: 0.9875 - val_TP: 5941.0000 - val_TN: 66144.0000 - val_FP: 32.0000 - val_FN: 75.0000\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 155s 1s/step - loss: 0.1268 - categorical_accuracy: 0.9686 - top-3: 0.9926 - ROC-AUC: 0.9974 - PR-AUC: 0.9908 - precision: 0.9807 - recall: 0.9589 - TP: 8638.0000 - TN: 98918.0000 - FP: 170.0000 - FN: 370.0000 - val_loss: 0.0323 - val_categorical_accuracy: 0.9919 - val_top-3: 0.9980 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9988 - val_precision: 0.9961 - val_recall: 0.9884 - val_TP: 5946.0000 - val_TN: 66153.0000 - val_FP: 23.0000 - val_FN: 70.0000\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1190 - categorical_accuracy: 0.9734 - top-3: 0.9938 - ROC-AUC: 0.9971 - PR-AUC: 0.9906 - precision: 0.9820 - recall: 0.9623 - TP: 8668.0000 - TN: 98929.0000 - FP: 159.0000 - FN: 340.0000 - val_loss: 0.0200 - val_categorical_accuracy: 0.9932 - val_top-3: 0.9992 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9970 - val_recall: 0.9914 - val_TP: 5964.0000 - val_TN: 66158.0000 - val_FP: 18.0000 - val_FN: 52.0000\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1175 - categorical_accuracy: 0.9701 - top-3: 0.9909 - ROC-AUC: 0.9974 - PR-AUC: 0.9913 - precision: 0.9823 - recall: 0.9628 - TP: 8673.0000 - TN: 98932.0000 - FP: 156.0000 - FN: 335.0000 - val_loss: 0.0128 - val_categorical_accuracy: 0.9963 - val_top-3: 0.9995 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9996 - val_precision: 0.9977 - val_recall: 0.9948 - val_TP: 5985.0000 - val_TN: 66162.0000 - val_FP: 14.0000 - val_FN: 31.0000\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1077 - categorical_accuracy: 0.9728 - top-3: 0.9921 - ROC-AUC: 0.9982 - PR-AUC: 0.9931 - precision: 0.9855 - recall: 0.9655 - TP: 8697.0000 - TN: 98960.0000 - FP: 128.0000 - FN: 311.0000 - val_loss: 0.0159 - val_categorical_accuracy: 0.9963 - val_top-3: 0.9997 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9989 - val_precision: 0.9975 - val_recall: 0.9952 - val_TP: 5987.0000 - val_TN: 66161.0000 - val_FP: 15.0000 - val_FN: 29.0000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.0988 - categorical_accuracy: 0.9745 - top-3: 0.9938 - ROC-AUC: 0.9980 - PR-AUC: 0.9933 - precision: 0.9830 - recall: 0.9680 - TP: 8720.0000 - TN: 98937.0000 - FP: 151.0000 - FN: 288.0000 - val_loss: 0.0228 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9990 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9987 - val_precision: 0.9960 - val_recall: 0.9922 - val_TP: 5969.0000 - val_TN: 66152.0000 - val_FP: 24.0000 - val_FN: 47.0000\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 156s 1s/step - loss: 0.1155 - categorical_accuracy: 0.9747 - top-3: 0.9932 - ROC-AUC: 0.9975 - PR-AUC: 0.9920 - precision: 0.9841 - recall: 0.9674 - TP: 8714.0000 - TN: 98947.0000 - FP: 141.0000 - FN: 294.0000 - val_loss: 0.0296 - val_categorical_accuracy: 0.9950 - val_top-3: 0.9987 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9992 - val_precision: 0.9978 - val_recall: 0.9919 - val_TP: 5967.0000 - val_TN: 66163.0000 - val_FP: 13.0000 - val_FN: 49.0000\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 158s 1s/step - loss: 0.1255 - categorical_accuracy: 0.9689 - top-3: 0.9908 - ROC-AUC: 0.9972 - PR-AUC: 0.9909 - precision: 0.9813 - recall: 0.9624 - TP: 8669.0000 - TN: 98923.0000 - FP: 165.0000 - FN: 339.0000 - val_loss: 0.0279 - val_categorical_accuracy: 0.9942 - val_top-3: 0.9980 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9986 - val_precision: 0.9968 - val_recall: 0.9914 - val_TP: 5964.0000 - val_TN: 66157.0000 - val_FP: 19.0000 - val_FN: 52.0000\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1348 - categorical_accuracy: 0.9710 - top-3: 0.9911 - ROC-AUC: 0.9967 - PR-AUC: 0.9893 - precision: 0.9822 - recall: 0.9635 - TP: 8679.0000 - TN: 98931.0000 - FP: 157.0000 - FN: 329.0000 - val_loss: 0.0250 - val_categorical_accuracy: 0.9929 - val_top-3: 0.9978 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9992 - val_precision: 0.9965 - val_recall: 0.9907 - val_TP: 5960.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 56.0000\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1198 - categorical_accuracy: 0.9715 - top-3: 0.9917 - ROC-AUC: 0.9971 - PR-AUC: 0.9906 - precision: 0.9808 - recall: 0.9620 - TP: 8666.0000 - TN: 98918.0000 - FP: 170.0000 - FN: 342.0000 - val_loss: 0.0411 - val_categorical_accuracy: 0.9952 - val_top-3: 0.9987 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9982 - val_precision: 0.9968 - val_recall: 0.9925 - val_TP: 5971.0000 - val_TN: 66157.0000 - val_FP: 19.0000 - val_FN: 45.0000\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1970 - categorical_accuracy: 0.9600 - top-3: 0.9889 - ROC-AUC: 0.9962 - PR-AUC: 0.9853 - precision: 0.9751 - recall: 0.9477 - TP: 8537.0000 - TN: 98870.0000 - FP: 218.0000 - FN: 471.0000 - val_loss: 0.0204 - val_categorical_accuracy: 0.9955 - val_top-3: 0.9997 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9984 - val_precision: 0.9972 - val_recall: 0.9942 - val_TP: 5981.0000 - val_TN: 66159.0000 - val_FP: 17.0000 - val_FN: 35.0000\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1386 - categorical_accuracy: 0.9661 - top-3: 0.9890 - ROC-AUC: 0.9967 - PR-AUC: 0.9892 - precision: 0.9807 - recall: 0.9567 - TP: 8618.0000 - TN: 98918.0000 - FP: 170.0000 - FN: 390.0000 - val_loss: 0.0386 - val_categorical_accuracy: 0.9895 - val_top-3: 0.9978 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9979 - val_precision: 0.9931 - val_recall: 0.9869 - val_TP: 5937.0000 - val_TN: 66135.0000 - val_FP: 41.0000 - val_FN: 79.0000\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1457 - categorical_accuracy: 0.9637 - top-3: 0.9899 - ROC-AUC: 0.9973 - PR-AUC: 0.9897 - precision: 0.9789 - recall: 0.9546 - TP: 8599.0000 - TN: 98903.0000 - FP: 185.0000 - FN: 409.0000 - val_loss: 0.0516 - val_categorical_accuracy: 0.9892 - val_top-3: 0.9978 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9951 - val_precision: 0.9923 - val_recall: 0.9850 - val_TP: 5926.0000 - val_TN: 66130.0000 - val_FP: 46.0000 - val_FN: 90.0000\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1193 - categorical_accuracy: 0.9701 - top-3: 0.9923 - ROC-AUC: 0.9972 - PR-AUC: 0.9903 - precision: 0.9819 - recall: 0.9616 - TP: 8662.0000 - TN: 98928.0000 - FP: 160.0000 - FN: 346.0000 - val_loss: 0.0211 - val_categorical_accuracy: 0.9937 - val_top-3: 0.9992 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9992 - val_precision: 0.9960 - val_recall: 0.9920 - val_TP: 5968.0000 - val_TN: 66152.0000 - val_FP: 24.0000 - val_FN: 48.0000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 157s 1s/step - loss: 0.1414 - categorical_accuracy: 0.9689 - top-3: 0.9913 - ROC-AUC: 0.9968 - PR-AUC: 0.9900 - precision: 0.9803 - recall: 0.9589 - TP: 8638.0000 - TN: 98914.0000 - FP: 174.0000 - FN: 370.0000 - val_loss: 0.0170 - val_categorical_accuracy: 0.9947 - val_top-3: 0.9988 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9995 - val_precision: 0.9975 - val_recall: 0.9932 - val_TP: 5975.0000 - val_TN: 66161.0000 - val_FP: 15.0000 - val_FN: 41.0000\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1033 - categorical_accuracy: 0.9775 - top-3: 0.9941 - ROC-AUC: 0.9979 - PR-AUC: 0.9930 - precision: 0.9862 - recall: 0.9706 - TP: 8743.0000 - TN: 98966.0000 - FP: 122.0000 - FN: 265.0000 - val_loss: 0.0216 - val_categorical_accuracy: 0.9942 - val_top-3: 0.9995 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9992 - val_precision: 0.9965 - val_recall: 0.9929 - val_TP: 5973.0000 - val_TN: 66155.0000 - val_FP: 21.0000 - val_FN: 43.0000\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 155s 1s/step - loss: 0.1472 - categorical_accuracy: 0.9641 - top-3: 0.9883 - ROC-AUC: 0.9970 - PR-AUC: 0.9896 - precision: 0.9794 - recall: 0.9573 - TP: 8623.0000 - TN: 98907.0000 - FP: 181.0000 - FN: 385.0000 - val_loss: 0.0333 - val_categorical_accuracy: 0.9924 - val_top-3: 0.9983 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9987 - val_precision: 0.9955 - val_recall: 0.9917 - val_TP: 5966.0000 - val_TN: 66149.0000 - val_FP: 27.0000 - val_FN: 50.0000\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 155s 1s/step - loss: 0.1873 - categorical_accuracy: 0.9640 - top-3: 0.9888 - ROC-AUC: 0.9964 - PR-AUC: 0.9882 - precision: 0.9780 - recall: 0.9557 - TP: 8609.0000 - TN: 98894.0000 - FP: 194.0000 - FN: 399.0000 - val_loss: 0.0352 - val_categorical_accuracy: 0.9934 - val_top-3: 0.9985 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9982 - val_precision: 0.9973 - val_recall: 0.9907 - val_TP: 5960.0000 - val_TN: 66160.0000 - val_FP: 16.0000 - val_FN: 56.0000\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 159s 1s/step - loss: 0.1817 - categorical_accuracy: 0.9576 - top-3: 0.9877 - ROC-AUC: 0.9957 - PR-AUC: 0.9853 - precision: 0.9722 - recall: 0.9459 - TP: 8521.0000 - TN: 98844.0000 - FP: 244.0000 - FN: 487.0000 - val_loss: 0.0170 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9992 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9991 - val_precision: 0.9968 - val_recall: 0.9932 - val_TP: 5975.0000 - val_TN: 66157.0000 - val_FP: 19.0000 - val_FN: 41.0000\n",
      "-----\n",
      "(7935035.91 ms) == (132m:15s)\n",
      "-----\n",
      "\n",
      "\n",
      "19\n",
      "['mobilenetv2_1.00_96-imagenet96-64-fc12.tensorboard',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.001_0.9511_0.1498.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.002_0.9779_0.0802.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.004_0.9934_0.0276.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.010_0.9940_0.0203.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.025_0.9945_0.0211.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.030_0.9960_0.0241.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.034_0.9932_0.0200.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.035_0.9963_0.0128.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-64-fc12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_96-imagenet96-64-fc12.csv',\n",
      " 'model.mobilenetv2_1.00_96-imagenet96-64-fc12.h5',\n",
      " 'weights.mobilenetv2_1.00_96-imagenet96-64-fc12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_96-imagenet96-64-fc12\n",
    "model96imagenet64_64fc12 = consecutiveModelTraining(\n",
    "    input_size=96,\n",
    "    batch_size=64,\n",
    "    weights='imagenet',\n",
    "    dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba90bc6-45aa-464a-a646-7b7320f76667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T21:19:31.037164Z",
     "iopub.status.busy": "2021-06-09T21:19:31.037164Z",
     "iopub.status.idle": "2021-06-09T21:19:31.100163Z",
     "shell.execute_reply": "2021-06-09T21:19:31.099161Z",
     "shell.execute_reply.started": "2021-06-09T21:19:31.037164Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.169084</td>\n",
       "      <td>0.958435</td>\n",
       "      <td>0.988366</td>\n",
       "      <td>0.995815</td>\n",
       "      <td>0.984503</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.947345</td>\n",
       "      <td>8533.680000</td>\n",
       "      <td>98857.280000</td>\n",
       "      <td>230.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.997777</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.986872</td>\n",
       "      <td>5937.020000</td>\n",
       "      <td>66135.520000</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>78.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.103625</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>0.014384</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.019862</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.040820</td>\n",
       "      <td>367.709926</td>\n",
       "      <td>112.259183</td>\n",
       "      <td>112.259183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>58.750767</td>\n",
       "      <td>36.950734</td>\n",
       "      <td>36.950734</td>\n",
       "      <td>58.750767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.098848</td>\n",
       "      <td>0.751776</td>\n",
       "      <td>0.890764</td>\n",
       "      <td>0.966454</td>\n",
       "      <td>0.852486</td>\n",
       "      <td>0.887926</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>98312.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951130</td>\n",
       "      <td>0.994182</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>0.988098</td>\n",
       "      <td>0.959709</td>\n",
       "      <td>0.942320</td>\n",
       "      <td>5669.000000</td>\n",
       "      <td>65938.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.125838</td>\n",
       "      <td>0.960119</td>\n",
       "      <td>0.989260</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>0.972251</td>\n",
       "      <td>0.948684</td>\n",
       "      <td>8545.750000</td>\n",
       "      <td>98844.500000</td>\n",
       "      <td>170.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989279</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>0.997568</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>0.985622</td>\n",
       "      <td>5929.500000</td>\n",
       "      <td>66134.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.143546</td>\n",
       "      <td>0.964476</td>\n",
       "      <td>0.990786</td>\n",
       "      <td>0.996743</td>\n",
       "      <td>0.989111</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.956428</td>\n",
       "      <td>8615.500000</td>\n",
       "      <td>98890.500000</td>\n",
       "      <td>197.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992769</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.990691</td>\n",
       "      <td>5960.000000</td>\n",
       "      <td>66147.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.177937</td>\n",
       "      <td>0.969638</td>\n",
       "      <td>0.991868</td>\n",
       "      <td>0.997225</td>\n",
       "      <td>0.990604</td>\n",
       "      <td>0.980658</td>\n",
       "      <td>0.961923</td>\n",
       "      <td>8665.000000</td>\n",
       "      <td>98917.750000</td>\n",
       "      <td>243.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>0.999003</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>5969.000000</td>\n",
       "      <td>66155.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>86.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815178</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.993317</td>\n",
       "      <td>0.986238</td>\n",
       "      <td>0.970582</td>\n",
       "      <td>8743.000000</td>\n",
       "      <td>98966.000000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>5987.000000</td>\n",
       "      <td>66163.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>347.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.169084              0.958435   0.988366   0.995815   0.984503   \n",
       "std     0.103625              0.032032   0.014384   0.004433   0.019862   \n",
       "min     0.098848              0.751776   0.890764   0.966454   0.852486   \n",
       "25%     0.125838              0.960119   0.989260   0.995843   0.985297   \n",
       "50%     0.143546              0.964476   0.990786   0.996743   0.989111   \n",
       "75%     0.177937              0.969638   0.991868   0.997225   0.990604   \n",
       "max     0.815178              0.977464   0.994671   0.998237   0.993317   \n",
       "\n",
       "       precision     recall           TP            TN          FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000   50.000000  ...   \n",
       "mean    0.973262   0.947345  8533.680000  98857.280000  230.720000  ...   \n",
       "std     0.015455   0.040820   367.709926    112.259183  112.259183  ...   \n",
       "min     0.887926   0.682504  6148.000000  98312.000000  122.000000  ...   \n",
       "25%     0.972251   0.948684  8545.750000  98844.500000  170.250000  ...   \n",
       "50%     0.977612   0.956428  8615.500000  98890.500000  197.500000  ...   \n",
       "75%     0.980658   0.961923  8665.000000  98917.750000  243.500000  ...   \n",
       "max     0.986238   0.970582  8743.000000  98966.000000  776.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.990066   0.998295     0.999350    0.997777   \n",
       "std                    0.007812   0.001182     0.000483    0.002073   \n",
       "min                    0.951130   0.994182     0.998017    0.988098   \n",
       "25%                    0.989279   0.998005     0.999238    0.997568   \n",
       "50%                    0.992769   0.998504     0.999457    0.998422   \n",
       "75%                    0.994141   0.999003     0.999671    0.999034   \n",
       "max                    0.996343   0.999668     0.999902    0.999695   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.993209    0.986872  5937.020000  66135.520000   40.480000   \n",
       "std         0.006260    0.009766    58.750767     36.950734   36.950734   \n",
       "min         0.959709    0.942320  5669.000000  65938.000000   13.000000   \n",
       "25%         0.993031    0.985622  5929.500000  66134.250000   21.000000   \n",
       "50%         0.995161    0.990691  5960.000000  66147.000000   29.000000   \n",
       "75%         0.996494    0.992188  5969.000000  66155.000000   41.750000   \n",
       "max         0.997826    0.995180  5987.000000  66163.000000  238.000000   \n",
       "\n",
       "           val_FN  \n",
       "count   50.000000  \n",
       "mean    78.980000  \n",
       "std     58.750767  \n",
       "min     29.000000  \n",
       "25%     47.000000  \n",
       "50%     56.000000  \n",
       "75%     86.500000  \n",
       "max    347.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model96imagenet64_64fc12['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b4d0d-52f0-456f-ab7e-108efeb7871f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7a73873-210f-4251-91a2-07a291f98325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T21:19:31.102163Z",
     "iopub.status.busy": "2021-06-09T21:19:31.102163Z",
     "iopub.status.idle": "2021-06-10T00:27:21.687057Z",
     "shell.execute_reply": "2021-06-10T00:27:21.686055Z",
     "shell.execute_reply.started": "2021-06-09T21:19:31.102163Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_128-16-fc12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_128-16-fc12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_128 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,686,156\n",
      "Trainable params: 2,652,044\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_128-16-fc12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_128-16-fc12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_128-16-fc12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 54:53 - loss: 6.2365 - categorical_accuracy: 0.0625 - top-3: 0.2812 - ROC-AUC: 0.4524 - PR-AUC: 0.0826 - precision: 0.0667 - recall: 0.0312 - TP: 1.0000 - TN: 338.0000 - FP: 14.0000 - FN: 31.0000            WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2310s vs `on_train_batch_end` time: 11.4249s). Check your callbacks.\n",
      "567/567 [==============================] - 239s 422ms/step - loss: 2.0630 - categorical_accuracy: 0.2522 - top-3: 0.5421 - ROC-AUC: 0.7706 - PR-AUC: 0.2724 - precision: 0.6274 - recall: 0.0793 - TP: 719.0000 - TN: 99365.0000 - FP: 427.0000 - FN: 8353.0000 - val_loss: 1.6383 - val_categorical_accuracy: 0.3562 - val_top-3: 0.7326 - val_ROC-AUC: 0.8758 - val_PR-AUC: 0.4077 - val_precision: 0.6535 - val_recall: 0.1172 - val_TP: 709.0000 - val_TN: 66152.0000 - val_FP: 376.0000 - val_FN: 5339.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 225s 396ms/step - loss: 1.7016 - categorical_accuracy: 0.3558 - top-3: 0.6820 - ROC-AUC: 0.8540 - PR-AUC: 0.4044 - precision: 0.6738 - recall: 0.1662 - TP: 1508.0000 - TN: 99062.0000 - FP: 730.0000 - FN: 7564.0000 - val_loss: 1.9030 - val_categorical_accuracy: 0.2814 - val_top-3: 0.6019 - val_ROC-AUC: 0.8121 - val_PR-AUC: 0.3147 - val_precision: 0.5356 - val_recall: 0.0957 - val_TP: 579.0000 - val_TN: 66026.0000 - val_FP: 502.0000 - val_FN: 5469.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 253s 446ms/step - loss: 1.5358 - categorical_accuracy: 0.4205 - top-3: 0.7291 - ROC-AUC: 0.8840 - PR-AUC: 0.4953 - precision: 0.7602 - recall: 0.2397 - TP: 2175.0000 - TN: 99106.0000 - FP: 686.0000 - FN: 6897.0000 - val_loss: 1.3126 - val_categorical_accuracy: 0.5134 - val_top-3: 0.7654 - val_ROC-AUC: 0.9137 - val_PR-AUC: 0.6116 - val_precision: 0.8862 - val_recall: 0.3310 - val_TP: 2002.0000 - val_TN: 66271.0000 - val_FP: 257.0000 - val_FN: 4046.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 237s 418ms/step - loss: 1.4054 - categorical_accuracy: 0.4809 - top-3: 0.7740 - ROC-AUC: 0.9054 - PR-AUC: 0.5741 - precision: 0.8434 - recall: 0.2957 - TP: 2683.0000 - TN: 99294.0000 - FP: 498.0000 - FN: 6389.0000 - val_loss: 1.1846 - val_categorical_accuracy: 0.5050 - val_top-3: 0.8477 - val_ROC-AUC: 0.9322 - val_PR-AUC: 0.6381 - val_precision: 0.9530 - val_recall: 0.3153 - val_TP: 1907.0000 - val_TN: 66434.0000 - val_FP: 94.0000 - val_FN: 4141.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 1.2367 - categorical_accuracy: 0.5215 - top-3: 0.8456 - ROC-AUC: 0.9274 - PR-AUC: 0.6339 - precision: 0.8730 - recall: 0.3252 - TP: 2950.0000 - TN: 99363.0000 - FP: 429.0000 - FN: 6122.0000 - val_loss: 1.0996 - val_categorical_accuracy: 0.5724 - val_top-3: 0.8776 - val_ROC-AUC: 0.9405 - val_PR-AUC: 0.6906 - val_precision: 0.9385 - val_recall: 0.3429 - val_TP: 2074.0000 - val_TN: 66392.0000 - val_FP: 136.0000 - val_FN: 3974.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 1.1441 - categorical_accuracy: 0.5694 - top-3: 0.8803 - ROC-AUC: 0.9384 - PR-AUC: 0.6704 - precision: 0.8225 - recall: 0.3555 - TP: 3225.0000 - TN: 99096.0000 - FP: 696.0000 - FN: 5847.0000 - val_loss: 0.8734 - val_categorical_accuracy: 0.6430 - val_top-3: 0.9311 - val_ROC-AUC: 0.9651 - val_PR-AUC: 0.7630 - val_precision: 0.8622 - val_recall: 0.4170 - val_TP: 2522.0000 - val_TN: 66125.0000 - val_FP: 403.0000 - val_FN: 3526.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 1.0217 - categorical_accuracy: 0.6110 - top-3: 0.9146 - ROC-AUC: 0.9505 - PR-AUC: 0.7181 - precision: 0.7968 - recall: 0.4306 - TP: 3906.0000 - TN: 98796.0000 - FP: 996.0000 - FN: 5166.0000 - val_loss: 0.7509 - val_categorical_accuracy: 0.7313 - val_top-3: 0.9588 - val_ROC-AUC: 0.9746 - val_PR-AUC: 0.8290 - val_precision: 0.8765 - val_recall: 0.5516 - val_TP: 3336.0000 - val_TN: 66058.0000 - val_FP: 470.0000 - val_FN: 2712.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.9250 - categorical_accuracy: 0.6616 - top-3: 0.9275 - ROC-AUC: 0.9586 - PR-AUC: 0.7623 - precision: 0.7928 - recall: 0.5248 - TP: 4761.0000 - TN: 98548.0000 - FP: 1244.0000 - FN: 4311.0000 - val_loss: 0.8061 - val_categorical_accuracy: 0.7103 - val_top-3: 0.9387 - val_ROC-AUC: 0.9681 - val_PR-AUC: 0.8111 - val_precision: 0.8524 - val_recall: 0.6014 - val_TP: 3637.0000 - val_TN: 65898.0000 - val_FP: 630.0000 - val_FN: 2411.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.8665 - categorical_accuracy: 0.6986 - top-3: 0.9321 - ROC-AUC: 0.9637 - PR-AUC: 0.7895 - precision: 0.8017 - recall: 0.5794 - TP: 5256.0000 - TN: 98492.0000 - FP: 1300.0000 - FN: 3816.0000 - val_loss: 0.7021 - val_categorical_accuracy: 0.7510 - val_top-3: 0.9592 - val_ROC-AUC: 0.9781 - val_PR-AUC: 0.8494 - val_precision: 0.8279 - val_recall: 0.6809 - val_TP: 4118.0000 - val_TN: 65672.0000 - val_FP: 856.0000 - val_FN: 1930.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 225s 398ms/step - loss: 0.8554 - categorical_accuracy: 0.7054 - top-3: 0.9336 - ROC-AUC: 0.9644 - PR-AUC: 0.7978 - precision: 0.8045 - recall: 0.6048 - TP: 5487.0000 - TN: 98459.0000 - FP: 1333.0000 - FN: 3585.0000 - val_loss: 0.5835 - val_categorical_accuracy: 0.8219 - val_top-3: 0.9610 - val_ROC-AUC: 0.9838 - val_PR-AUC: 0.9002 - val_precision: 0.8950 - val_recall: 0.7371 - val_TP: 4458.0000 - val_TN: 66005.0000 - val_FP: 523.0000 - val_FN: 1590.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 223s 392ms/step - loss: 0.7826 - categorical_accuracy: 0.7405 - top-3: 0.9426 - ROC-AUC: 0.9690 - PR-AUC: 0.8260 - precision: 0.8149 - recall: 0.6632 - TP: 6017.0000 - TN: 98425.0000 - FP: 1367.0000 - FN: 3055.0000 - val_loss: 0.5902 - val_categorical_accuracy: 0.7979 - val_top-3: 0.9611 - val_ROC-AUC: 0.9834 - val_PR-AUC: 0.8902 - val_precision: 0.8747 - val_recall: 0.7214 - val_TP: 4363.0000 - val_TN: 65903.0000 - val_FP: 625.0000 - val_FN: 1685.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 221s 390ms/step - loss: 0.7034 - categorical_accuracy: 0.7690 - top-3: 0.9508 - ROC-AUC: 0.9741 - PR-AUC: 0.8533 - precision: 0.8309 - recall: 0.6986 - TP: 6338.0000 - TN: 98502.0000 - FP: 1290.0000 - FN: 2734.0000 - val_loss: 0.4665 - val_categorical_accuracy: 0.8337 - val_top-3: 0.9790 - val_ROC-AUC: 0.9890 - val_PR-AUC: 0.9237 - val_precision: 0.9052 - val_recall: 0.7470 - val_TP: 4518.0000 - val_TN: 66055.0000 - val_FP: 473.0000 - val_FN: 1530.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.6280 - categorical_accuracy: 0.7942 - top-3: 0.9608 - ROC-AUC: 0.9785 - PR-AUC: 0.8767 - precision: 0.8505 - recall: 0.7339 - TP: 6658.0000 - TN: 98622.0000 - FP: 1170.0000 - FN: 2414.0000 - val_loss: 0.4302 - val_categorical_accuracy: 0.8729 - val_top-3: 0.9775 - val_ROC-AUC: 0.9893 - val_PR-AUC: 0.9330 - val_precision: 0.9016 - val_recall: 0.8409 - val_TP: 5086.0000 - val_TN: 65973.0000 - val_FP: 555.0000 - val_FN: 962.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 224s 395ms/step - loss: 0.6272 - categorical_accuracy: 0.8015 - top-3: 0.9579 - ROC-AUC: 0.9785 - PR-AUC: 0.8783 - precision: 0.8496 - recall: 0.7464 - TP: 6771.0000 - TN: 98593.0000 - FP: 1199.0000 - FN: 2301.0000 - val_loss: 0.4747 - val_categorical_accuracy: 0.8408 - val_top-3: 0.9759 - val_ROC-AUC: 0.9862 - val_PR-AUC: 0.9187 - val_precision: 0.8602 - val_recall: 0.8198 - val_TP: 4958.0000 - val_TN: 65722.0000 - val_FP: 806.0000 - val_FN: 1090.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 226s 398ms/step - loss: 0.5751 - categorical_accuracy: 0.8235 - top-3: 0.9626 - ROC-AUC: 0.9815 - PR-AUC: 0.8965 - precision: 0.8633 - recall: 0.7792 - TP: 7069.0000 - TN: 98673.0000 - FP: 1119.0000 - FN: 2003.0000 - val_loss: 0.3996 - val_categorical_accuracy: 0.8862 - val_top-3: 0.9777 - val_ROC-AUC: 0.9905 - val_PR-AUC: 0.9460 - val_precision: 0.9144 - val_recall: 0.8552 - val_TP: 5172.0000 - val_TN: 66044.0000 - val_FP: 484.0000 - val_FN: 876.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 224s 396ms/step - loss: 0.5434 - categorical_accuracy: 0.8344 - top-3: 0.9679 - ROC-AUC: 0.9832 - PR-AUC: 0.9038 - precision: 0.8685 - recall: 0.7963 - TP: 7224.0000 - TN: 98698.0000 - FP: 1094.0000 - FN: 1848.0000 - val_loss: 0.3591 - val_categorical_accuracy: 0.9005 - val_top-3: 0.9836 - val_ROC-AUC: 0.9914 - val_PR-AUC: 0.9532 - val_precision: 0.9230 - val_recall: 0.8861 - val_TP: 5359.0000 - val_TN: 66081.0000 - val_FP: 447.0000 - val_FN: 689.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 222s 391ms/step - loss: 0.5263 - categorical_accuracy: 0.8485 - top-3: 0.9653 - ROC-AUC: 0.9840 - PR-AUC: 0.9106 - precision: 0.8745 - recall: 0.8112 - TP: 7359.0000 - TN: 98736.0000 - FP: 1056.0000 - FN: 1713.0000 - val_loss: 0.3507 - val_categorical_accuracy: 0.8978 - val_top-3: 0.9838 - val_ROC-AUC: 0.9921 - val_PR-AUC: 0.9538 - val_precision: 0.9241 - val_recall: 0.8763 - val_TP: 5300.0000 - val_TN: 66093.0000 - val_FP: 435.0000 - val_FN: 748.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 221s 390ms/step - loss: 0.4367 - categorical_accuracy: 0.8713 - top-3: 0.9785 - ROC-AUC: 0.9878 - PR-AUC: 0.9312 - precision: 0.8952 - recall: 0.8463 - TP: 7678.0000 - TN: 98893.0000 - FP: 899.0000 - FN: 1394.0000 - val_loss: 0.2553 - val_categorical_accuracy: 0.9254 - val_top-3: 0.9906 - val_ROC-AUC: 0.9943 - val_PR-AUC: 0.9707 - val_precision: 0.9351 - val_recall: 0.9150 - val_TP: 5534.0000 - val_TN: 66144.0000 - val_FP: 384.0000 - val_FN: 514.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.4410 - categorical_accuracy: 0.8770 - top-3: 0.9772 - ROC-AUC: 0.9867 - PR-AUC: 0.9301 - precision: 0.8960 - recall: 0.8545 - TP: 7752.0000 - TN: 98892.0000 - FP: 900.0000 - FN: 1320.0000 - val_loss: 0.3493 - val_categorical_accuracy: 0.9077 - val_top-3: 0.9762 - val_ROC-AUC: 0.9902 - val_PR-AUC: 0.9544 - val_precision: 0.9166 - val_recall: 0.9018 - val_TP: 5454.0000 - val_TN: 66032.0000 - val_FP: 496.0000 - val_FN: 594.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 223s 392ms/step - loss: 0.5154 - categorical_accuracy: 0.8511 - top-3: 0.9683 - ROC-AUC: 0.9839 - PR-AUC: 0.9169 - precision: 0.8798 - recall: 0.8149 - TP: 7393.0000 - TN: 98782.0000 - FP: 1010.0000 - FN: 1679.0000 - val_loss: 0.2589 - val_categorical_accuracy: 0.9302 - val_top-3: 0.9889 - val_ROC-AUC: 0.9938 - val_PR-AUC: 0.9694 - val_precision: 0.9402 - val_recall: 0.9226 - val_TP: 5580.0000 - val_TN: 66173.0000 - val_FP: 355.0000 - val_FN: 468.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 227s 400ms/step - loss: 0.3974 - categorical_accuracy: 0.8936 - top-3: 0.9782 - ROC-AUC: 0.9885 - PR-AUC: 0.9426 - precision: 0.9092 - recall: 0.8803 - TP: 7986.0000 - TN: 98994.0000 - FP: 798.0000 - FN: 1086.0000 - val_loss: 0.4334 - val_categorical_accuracy: 0.8618 - val_top-3: 0.9785 - val_ROC-AUC: 0.9886 - val_PR-AUC: 0.9378 - val_precision: 0.8776 - val_recall: 0.8510 - val_TP: 5147.0000 - val_TN: 65810.0000 - val_FP: 718.0000 - val_FN: 901.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.4416 - categorical_accuracy: 0.8801 - top-3: 0.9746 - ROC-AUC: 0.9865 - PR-AUC: 0.9319 - precision: 0.8979 - recall: 0.8599 - TP: 7801.0000 - TN: 98905.0000 - FP: 887.0000 - FN: 1271.0000 - val_loss: 0.3238 - val_categorical_accuracy: 0.9152 - val_top-3: 0.9851 - val_ROC-AUC: 0.9907 - val_PR-AUC: 0.9553 - val_precision: 0.9242 - val_recall: 0.9066 - val_TP: 5483.0000 - val_TN: 66078.0000 - val_FP: 450.0000 - val_FN: 565.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 224s 395ms/step - loss: 0.4071 - categorical_accuracy: 0.8890 - top-3: 0.9787 - ROC-AUC: 0.9879 - PR-AUC: 0.9385 - precision: 0.9038 - recall: 0.8731 - TP: 7921.0000 - TN: 98949.0000 - FP: 843.0000 - FN: 1151.0000 - val_loss: 0.2731 - val_categorical_accuracy: 0.9286 - val_top-3: 0.9866 - val_ROC-AUC: 0.9937 - val_PR-AUC: 0.9697 - val_precision: 0.9399 - val_recall: 0.9177 - val_TP: 5550.0000 - val_TN: 66173.0000 - val_FP: 355.0000 - val_FN: 498.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 225s 397ms/step - loss: 0.4074 - categorical_accuracy: 0.8871 - top-3: 0.9786 - ROC-AUC: 0.9884 - PR-AUC: 0.9386 - precision: 0.9055 - recall: 0.8711 - TP: 7903.0000 - TN: 98967.0000 - FP: 825.0000 - FN: 1169.0000 - val_loss: 0.3200 - val_categorical_accuracy: 0.9152 - val_top-3: 0.9853 - val_ROC-AUC: 0.9928 - val_PR-AUC: 0.9593 - val_precision: 0.9321 - val_recall: 0.9011 - val_TP: 5450.0000 - val_TN: 66131.0000 - val_FP: 397.0000 - val_FN: 598.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 224s 395ms/step - loss: 0.3905 - categorical_accuracy: 0.8922 - top-3: 0.9785 - ROC-AUC: 0.9886 - PR-AUC: 0.9429 - precision: 0.9127 - recall: 0.8752 - TP: 7940.0000 - TN: 99033.0000 - FP: 759.0000 - FN: 1132.0000 - val_loss: 0.1580 - val_categorical_accuracy: 0.9616 - val_top-3: 0.9944 - val_ROC-AUC: 0.9973 - val_PR-AUC: 0.9876 - val_precision: 0.9665 - val_recall: 0.9585 - val_TP: 5797.0000 - val_TN: 66327.0000 - val_FP: 201.0000 - val_FN: 251.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.3601 - categorical_accuracy: 0.9075 - top-3: 0.9803 - ROC-AUC: 0.9889 - PR-AUC: 0.9499 - precision: 0.9202 - recall: 0.8947 - TP: 8117.0000 - TN: 99088.0000 - FP: 704.0000 - FN: 955.0000 - val_loss: 0.2320 - val_categorical_accuracy: 0.9392 - val_top-3: 0.9916 - val_ROC-AUC: 0.9953 - val_PR-AUC: 0.9772 - val_precision: 0.9483 - val_recall: 0.9334 - val_TP: 5645.0000 - val_TN: 66220.0000 - val_FP: 308.0000 - val_FN: 403.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 225s 396ms/step - loss: 0.3548 - categorical_accuracy: 0.9045 - top-3: 0.9832 - ROC-AUC: 0.9897 - PR-AUC: 0.9503 - precision: 0.9192 - recall: 0.8890 - TP: 8065.0000 - TN: 99083.0000 - FP: 709.0000 - FN: 1007.0000 - val_loss: 0.2751 - val_categorical_accuracy: 0.9243 - val_top-3: 0.9922 - val_ROC-AUC: 0.9932 - val_PR-AUC: 0.9649 - val_precision: 0.9283 - val_recall: 0.9168 - val_TP: 5545.0000 - val_TN: 66100.0000 - val_FP: 428.0000 - val_FN: 503.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 225s 396ms/step - loss: 0.2949 - categorical_accuracy: 0.9226 - top-3: 0.9864 - ROC-AUC: 0.9919 - PR-AUC: 0.9627 - precision: 0.9337 - recall: 0.9113 - TP: 8267.0000 - TN: 99205.0000 - FP: 587.0000 - FN: 805.0000 - val_loss: 0.2821 - val_categorical_accuracy: 0.9340 - val_top-3: 0.9853 - val_ROC-AUC: 0.9920 - val_PR-AUC: 0.9645 - val_precision: 0.9400 - val_recall: 0.9301 - val_TP: 5625.0000 - val_TN: 66169.0000 - val_FP: 359.0000 - val_FN: 423.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.3656 - categorical_accuracy: 0.9009 - top-3: 0.9812 - ROC-AUC: 0.9896 - PR-AUC: 0.9494 - precision: 0.9145 - recall: 0.8854 - TP: 8032.0000 - TN: 99041.0000 - FP: 751.0000 - FN: 1040.0000 - val_loss: 0.1646 - val_categorical_accuracy: 0.9583 - val_top-3: 0.9957 - val_ROC-AUC: 0.9973 - val_PR-AUC: 0.9858 - val_precision: 0.9644 - val_recall: 0.9539 - val_TP: 5769.0000 - val_TN: 66315.0000 - val_FP: 213.0000 - val_FN: 279.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 227s 401ms/step - loss: 0.3313 - categorical_accuracy: 0.9104 - top-3: 0.9824 - ROC-AUC: 0.9910 - PR-AUC: 0.9567 - precision: 0.9225 - recall: 0.8985 - TP: 8151.0000 - TN: 99107.0000 - FP: 685.0000 - FN: 921.0000 - val_loss: 0.1659 - val_categorical_accuracy: 0.9631 - val_top-3: 0.9950 - val_ROC-AUC: 0.9963 - val_PR-AUC: 0.9833 - val_precision: 0.9667 - val_recall: 0.9606 - val_TP: 5810.0000 - val_TN: 66328.0000 - val_FP: 200.0000 - val_FN: 238.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 0.4318 - categorical_accuracy: 0.8864 - top-3: 0.9741 - ROC-AUC: 0.9866 - PR-AUC: 0.9369 - precision: 0.9071 - recall: 0.8655 - TP: 7852.0000 - TN: 98988.0000 - FP: 804.0000 - FN: 1220.0000 - val_loss: 0.2416 - val_categorical_accuracy: 0.9421 - val_top-3: 0.9881 - val_ROC-AUC: 0.9937 - val_PR-AUC: 0.9705 - val_precision: 0.9520 - val_recall: 0.9354 - val_TP: 5657.0000 - val_TN: 66243.0000 - val_FP: 285.0000 - val_FN: 391.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 221s 391ms/step - loss: 0.3100 - categorical_accuracy: 0.9242 - top-3: 0.9856 - ROC-AUC: 0.9917 - PR-AUC: 0.9595 - precision: 0.9329 - recall: 0.9127 - TP: 8280.0000 - TN: 99196.0000 - FP: 596.0000 - FN: 792.0000 - val_loss: 0.1682 - val_categorical_accuracy: 0.9600 - val_top-3: 0.9964 - val_ROC-AUC: 0.9973 - val_PR-AUC: 0.9848 - val_precision: 0.9644 - val_recall: 0.9527 - val_TP: 5762.0000 - val_TN: 66315.0000 - val_FP: 213.0000 - val_FN: 286.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 224s 394ms/step - loss: 0.2875 - categorical_accuracy: 0.9256 - top-3: 0.9868 - ROC-AUC: 0.9919 - PR-AUC: 0.9651 - precision: 0.9376 - recall: 0.9150 - TP: 8301.0000 - TN: 99240.0000 - FP: 552.0000 - FN: 771.0000 - val_loss: 0.2834 - val_categorical_accuracy: 0.9228 - val_top-3: 0.9802 - val_ROC-AUC: 0.9929 - val_PR-AUC: 0.9661 - val_precision: 0.9374 - val_recall: 0.9144 - val_TP: 5530.0000 - val_TN: 66159.0000 - val_FP: 369.0000 - val_FN: 518.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 225s 397ms/step - loss: 0.2642 - categorical_accuracy: 0.9322 - top-3: 0.9885 - ROC-AUC: 0.9931 - PR-AUC: 0.9685 - precision: 0.9407 - recall: 0.9217 - TP: 8362.0000 - TN: 99265.0000 - FP: 527.0000 - FN: 710.0000 - val_loss: 0.1316 - val_categorical_accuracy: 0.9692 - val_top-3: 0.9962 - val_ROC-AUC: 0.9975 - val_PR-AUC: 0.9872 - val_precision: 0.9724 - val_recall: 0.9678 - val_TP: 5853.0000 - val_TN: 66362.0000 - val_FP: 166.0000 - val_FN: 195.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 226s 398ms/step - loss: 0.2669 - categorical_accuracy: 0.9320 - top-3: 0.9885 - ROC-AUC: 0.9927 - PR-AUC: 0.9677 - precision: 0.9389 - recall: 0.9239 - TP: 8382.0000 - TN: 99247.0000 - FP: 545.0000 - FN: 690.0000 - val_loss: 0.1123 - val_categorical_accuracy: 0.9696 - val_top-3: 0.9960 - val_ROC-AUC: 0.9977 - val_PR-AUC: 0.9912 - val_precision: 0.9726 - val_recall: 0.9674 - val_TP: 5851.0000 - val_TN: 66363.0000 - val_FP: 165.0000 - val_FN: 197.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 0.2734 - categorical_accuracy: 0.9247 - top-3: 0.9884 - ROC-AUC: 0.9926 - PR-AUC: 0.9672 - precision: 0.9340 - recall: 0.9129 - TP: 8282.0000 - TN: 99207.0000 - FP: 585.0000 - FN: 790.0000 - val_loss: 0.1659 - val_categorical_accuracy: 0.9666 - val_top-3: 0.9919 - val_ROC-AUC: 0.9957 - val_PR-AUC: 0.9868 - val_precision: 0.9707 - val_recall: 0.9643 - val_TP: 5832.0000 - val_TN: 66352.0000 - val_FP: 176.0000 - val_FN: 216.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 0.2477 - categorical_accuracy: 0.9357 - top-3: 0.9859 - ROC-AUC: 0.9941 - PR-AUC: 0.9740 - precision: 0.9480 - recall: 0.9259 - TP: 8400.0000 - TN: 99331.0000 - FP: 461.0000 - FN: 672.0000 - val_loss: 0.1896 - val_categorical_accuracy: 0.9549 - val_top-3: 0.9945 - val_ROC-AUC: 0.9967 - val_PR-AUC: 0.9821 - val_precision: 0.9575 - val_recall: 0.9535 - val_TP: 5767.0000 - val_TN: 66272.0000 - val_FP: 256.0000 - val_FN: 281.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.4918 - categorical_accuracy: 0.8505 - top-3: 0.9623 - ROC-AUC: 0.9856 - PR-AUC: 0.9264 - precision: 0.9041 - recall: 0.8131 - TP: 7376.0000 - TN: 99010.0000 - FP: 782.0000 - FN: 1696.0000 - val_loss: 0.1638 - val_categorical_accuracy: 0.9621 - val_top-3: 0.9949 - val_ROC-AUC: 0.9960 - val_PR-AUC: 0.9851 - val_precision: 0.9687 - val_recall: 0.9570 - val_TP: 5788.0000 - val_TN: 66341.0000 - val_FP: 187.0000 - val_FN: 260.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.2216 - categorical_accuracy: 0.9355 - top-3: 0.9888 - ROC-AUC: 0.9949 - PR-AUC: 0.9770 - precision: 0.9588 - recall: 0.9193 - TP: 8340.0000 - TN: 99434.0000 - FP: 358.0000 - FN: 732.0000 - val_loss: 0.1263 - val_categorical_accuracy: 0.9689 - val_top-3: 0.9974 - val_ROC-AUC: 0.9970 - val_PR-AUC: 0.9874 - val_precision: 0.9732 - val_recall: 0.9661 - val_TP: 5843.0000 - val_TN: 66367.0000 - val_FP: 161.0000 - val_FN: 205.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.2149 - categorical_accuracy: 0.9425 - top-3: 0.9885 - ROC-AUC: 0.9951 - PR-AUC: 0.9788 - precision: 0.9630 - recall: 0.9301 - TP: 8438.0000 - TN: 99468.0000 - FP: 324.0000 - FN: 634.0000 - val_loss: 0.0921 - val_categorical_accuracy: 0.9772 - val_top-3: 0.9954 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9942 - val_precision: 0.9799 - val_recall: 0.9744 - val_TP: 5893.0000 - val_TN: 66407.0000 - val_FP: 121.0000 - val_FN: 155.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 222s 392ms/step - loss: 0.2456 - categorical_accuracy: 0.9336 - top-3: 0.9839 - ROC-AUC: 0.9937 - PR-AUC: 0.9748 - precision: 0.9560 - recall: 0.9181 - TP: 8329.0000 - TN: 99409.0000 - FP: 383.0000 - FN: 743.0000 - val_loss: 0.1356 - val_categorical_accuracy: 0.9664 - val_top-3: 0.9962 - val_ROC-AUC: 0.9974 - val_PR-AUC: 0.9878 - val_precision: 0.9707 - val_recall: 0.9626 - val_TP: 5822.0000 - val_TN: 66352.0000 - val_FP: 176.0000 - val_FN: 226.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 221s 390ms/step - loss: 0.3133 - categorical_accuracy: 0.9136 - top-3: 0.9805 - ROC-AUC: 0.9920 - PR-AUC: 0.9631 - precision: 0.9395 - recall: 0.8963 - TP: 8131.0000 - TN: 99268.0000 - FP: 524.0000 - FN: 941.0000 - val_loss: 0.1526 - val_categorical_accuracy: 0.9585 - val_top-3: 0.9964 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9881 - val_precision: 0.9642 - val_recall: 0.9522 - val_TP: 5759.0000 - val_TN: 66314.0000 - val_FP: 214.0000 - val_FN: 289.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.2075 - categorical_accuracy: 0.9431 - top-3: 0.9895 - ROC-AUC: 0.9949 - PR-AUC: 0.9786 - precision: 0.9582 - recall: 0.9296 - TP: 8433.0000 - TN: 99424.0000 - FP: 368.0000 - FN: 639.0000 - val_loss: 0.1117 - val_categorical_accuracy: 0.9732 - val_top-3: 0.9965 - val_ROC-AUC: 0.9981 - val_PR-AUC: 0.9914 - val_precision: 0.9756 - val_recall: 0.9704 - val_TP: 5869.0000 - val_TN: 66381.0000 - val_FP: 147.0000 - val_FN: 179.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 0.2287 - categorical_accuracy: 0.9377 - top-3: 0.9882 - ROC-AUC: 0.9944 - PR-AUC: 0.9765 - precision: 0.9567 - recall: 0.9216 - TP: 8361.0000 - TN: 99414.0000 - FP: 378.0000 - FN: 711.0000 - val_loss: 0.1198 - val_categorical_accuracy: 0.9704 - val_top-3: 0.9967 - val_ROC-AUC: 0.9971 - val_PR-AUC: 0.9914 - val_precision: 0.9726 - val_recall: 0.9684 - val_TP: 5857.0000 - val_TN: 66363.0000 - val_FP: 165.0000 - val_FN: 191.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 225s 397ms/step - loss: 0.2474 - categorical_accuracy: 0.9388 - top-3: 0.9879 - ROC-AUC: 0.9939 - PR-AUC: 0.9748 - precision: 0.9576 - recall: 0.9246 - TP: 8388.0000 - TN: 99421.0000 - FP: 371.0000 - FN: 684.0000 - val_loss: 0.0969 - val_categorical_accuracy: 0.9769 - val_top-3: 0.9965 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9925 - val_precision: 0.9794 - val_recall: 0.9755 - val_TP: 5900.0000 - val_TN: 66404.0000 - val_FP: 124.0000 - val_FN: 148.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 224s 394ms/step - loss: 0.2946 - categorical_accuracy: 0.9258 - top-3: 0.9826 - ROC-AUC: 0.9922 - PR-AUC: 0.9681 - precision: 0.9481 - recall: 0.9094 - TP: 8250.0000 - TN: 99340.0000 - FP: 452.0000 - FN: 822.0000 - val_loss: 0.1967 - val_categorical_accuracy: 0.9595 - val_top-3: 0.9921 - val_ROC-AUC: 0.9957 - val_PR-AUC: 0.9801 - val_precision: 0.9647 - val_recall: 0.9534 - val_TP: 5766.0000 - val_TN: 66317.0000 - val_FP: 211.0000 - val_FN: 282.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 226s 398ms/step - loss: 0.3130 - categorical_accuracy: 0.9076 - top-3: 0.9836 - ROC-AUC: 0.9917 - PR-AUC: 0.9610 - precision: 0.9341 - recall: 0.8890 - TP: 8065.0000 - TN: 99223.0000 - FP: 569.0000 - FN: 1007.0000 - val_loss: 0.1156 - val_categorical_accuracy: 0.9724 - val_top-3: 0.9959 - val_ROC-AUC: 0.9978 - val_PR-AUC: 0.9913 - val_precision: 0.9747 - val_recall: 0.9696 - val_TP: 5864.0000 - val_TN: 66376.0000 - val_FP: 152.0000 - val_FN: 184.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 223s 394ms/step - loss: 0.2305 - categorical_accuracy: 0.9352 - top-3: 0.9864 - ROC-AUC: 0.9946 - PR-AUC: 0.9767 - precision: 0.9606 - recall: 0.9194 - TP: 8341.0000 - TN: 99450.0000 - FP: 342.0000 - FN: 731.0000 - val_loss: 0.1702 - val_categorical_accuracy: 0.9492 - val_top-3: 0.9967 - val_ROC-AUC: 0.9966 - val_PR-AUC: 0.9857 - val_precision: 0.9582 - val_recall: 0.9468 - val_TP: 5726.0000 - val_TN: 66278.0000 - val_FP: 250.0000 - val_FN: 322.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 226s 398ms/step - loss: 0.3208 - categorical_accuracy: 0.9112 - top-3: 0.9813 - ROC-AUC: 0.9917 - PR-AUC: 0.9619 - precision: 0.9387 - recall: 0.8873 - TP: 8050.0000 - TN: 99266.0000 - FP: 526.0000 - FN: 1022.0000 - val_loss: 0.0826 - val_categorical_accuracy: 0.9808 - val_top-3: 0.9970 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9950 - val_precision: 0.9835 - val_recall: 0.9773 - val_TP: 5911.0000 - val_TN: 66429.0000 - val_FP: 99.0000 - val_FN: 137.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 223s 393ms/step - loss: 0.1921 - categorical_accuracy: 0.9468 - top-3: 0.9907 - ROC-AUC: 0.9953 - PR-AUC: 0.9804 - precision: 0.9696 - recall: 0.9340 - TP: 8473.0000 - TN: 99526.0000 - FP: 266.0000 - FN: 599.0000 - val_loss: 0.1335 - val_categorical_accuracy: 0.9673 - val_top-3: 0.9916 - val_ROC-AUC: 0.9967 - val_PR-AUC: 0.9886 - val_precision: 0.9721 - val_recall: 0.9661 - val_TP: 5843.0000 - val_TN: 66360.0000 - val_FP: 168.0000 - val_FN: 205.0000\n",
      "-----\n",
      "(11265653.52 ms) == (187m:45s)\n",
      "-----\n",
      "\n",
      "\n",
      "32\n",
      "['mobilenetv2_1.00_128-16-fc12.tensorboard',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.001_0.3562_1.6383.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.003_0.5134_1.3126.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.004_0.5050_1.1846.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.005_0.5724_1.0996.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.006_0.6430_0.8734.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.007_0.7313_0.7509.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.009_0.7510_0.7021.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.010_0.8219_0.5835.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.012_0.8337_0.4665.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.013_0.8729_0.4302.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.015_0.8862_0.3996.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.016_0.9005_0.3591.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.017_0.8978_0.3507.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.018_0.9254_0.2553.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.020_0.9302_0.2589.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.025_0.9616_0.1580.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.030_0.9631_0.1659.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.034_0.9692_0.1316.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.035_0.9696_0.1123.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.040_0.9772_0.0921.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.049_0.9808_0.0826.hdf5',\n",
      " 'mobilenetv2_1.00_128-16-fc12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_128-16-fc12.csv',\n",
      " 'model.mobilenetv2_1.00_128-16-fc12.h5',\n",
      " 'weights.mobilenetv2_1.00_128-16-fc12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_128-16-fc12\n",
    "model_8 = consecutiveModelTraining(\n",
    "    input_size=128,\n",
    "    batch_size=16,\n",
    "    weights=None,\n",
    "    dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b74a7d72-84b7-44d8-b905-5103b4fa753f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T00:27:21.688055Z",
     "iopub.status.busy": "2021-06-10T00:27:21.688055Z",
     "iopub.status.idle": "2021-06-10T00:27:21.766060Z",
     "shell.execute_reply": "2021-06-10T00:27:21.765061Z",
     "shell.execute_reply.started": "2021-06-10T00:27:21.688055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.557772</td>\n",
       "      <td>0.819173</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.973354</td>\n",
       "      <td>0.876842</td>\n",
       "      <td>0.888860</td>\n",
       "      <td>0.767077</td>\n",
       "      <td>6958.920000</td>\n",
       "      <td>99057.920000</td>\n",
       "      <td>734.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864967</td>\n",
       "      <td>0.962887</td>\n",
       "      <td>0.982361</td>\n",
       "      <td>0.912823</td>\n",
       "      <td>0.922567</td>\n",
       "      <td>0.822024</td>\n",
       "      <td>4971.600000</td>\n",
       "      <td>66193.180000</td>\n",
       "      <td>334.820000</td>\n",
       "      <td>1076.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.421236</td>\n",
       "      <td>0.167134</td>\n",
       "      <td>0.087133</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.156959</td>\n",
       "      <td>0.072527</td>\n",
       "      <td>0.226870</td>\n",
       "      <td>2058.165538</td>\n",
       "      <td>305.860235</td>\n",
       "      <td>305.860235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163544</td>\n",
       "      <td>0.074923</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.144888</td>\n",
       "      <td>0.078954</td>\n",
       "      <td>0.230768</td>\n",
       "      <td>1395.685948</td>\n",
       "      <td>187.131045</td>\n",
       "      <td>187.131045</td>\n",
       "      <td>1395.685948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.192106</td>\n",
       "      <td>0.252205</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>0.770561</td>\n",
       "      <td>0.272393</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>0.079255</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>98425.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281415</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.812064</td>\n",
       "      <td>0.314717</td>\n",
       "      <td>0.535615</td>\n",
       "      <td>0.095734</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>65672.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.289302</td>\n",
       "      <td>0.796021</td>\n",
       "      <td>0.958609</td>\n",
       "      <td>0.978488</td>\n",
       "      <td>0.877081</td>\n",
       "      <td>0.853737</td>\n",
       "      <td>0.737020</td>\n",
       "      <td>6686.250000</td>\n",
       "      <td>98892.250000</td>\n",
       "      <td>504.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846023</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>0.988695</td>\n",
       "      <td>0.926056</td>\n",
       "      <td>0.907529</td>\n",
       "      <td>0.825066</td>\n",
       "      <td>4990.000000</td>\n",
       "      <td>66078.750000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>241.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.402250</td>\n",
       "      <td>0.890597</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.988437</td>\n",
       "      <td>0.940599</td>\n",
       "      <td>0.908135</td>\n",
       "      <td>0.874173</td>\n",
       "      <td>7930.500000</td>\n",
       "      <td>99092.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929398</td>\n",
       "      <td>0.988509</td>\n",
       "      <td>0.993720</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>0.940096</td>\n",
       "      <td>0.920139</td>\n",
       "      <td>5565.000000</td>\n",
       "      <td>66231.500000</td>\n",
       "      <td>296.500000</td>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.627780</td>\n",
       "      <td>0.925375</td>\n",
       "      <td>0.985808</td>\n",
       "      <td>0.992153</td>\n",
       "      <td>0.966691</td>\n",
       "      <td>0.938878</td>\n",
       "      <td>0.912864</td>\n",
       "      <td>8281.500000</td>\n",
       "      <td>99287.500000</td>\n",
       "      <td>899.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962880</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.987122</td>\n",
       "      <td>0.968208</td>\n",
       "      <td>0.960111</td>\n",
       "      <td>5806.750000</td>\n",
       "      <td>66352.000000</td>\n",
       "      <td>449.250000</td>\n",
       "      <td>1058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.063020</td>\n",
       "      <td>0.946759</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.980379</td>\n",
       "      <td>0.969562</td>\n",
       "      <td>0.933973</td>\n",
       "      <td>8473.000000</td>\n",
       "      <td>99526.000000</td>\n",
       "      <td>1367.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980820</td>\n",
       "      <td>0.997355</td>\n",
       "      <td>0.998499</td>\n",
       "      <td>0.994991</td>\n",
       "      <td>0.983527</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>5911.000000</td>\n",
       "      <td>66434.000000</td>\n",
       "      <td>856.000000</td>\n",
       "      <td>5469.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.557772              0.819173   0.945736   0.973354   0.876842   \n",
       "std     0.421236              0.167134   0.087133   0.041186   0.156959   \n",
       "min     0.192106              0.252205   0.542108   0.770561   0.272393   \n",
       "25%     0.289302              0.796021   0.958609   0.978488   0.877081   \n",
       "50%     0.402250              0.890597   0.978560   0.988437   0.940599   \n",
       "75%     0.627780              0.925375   0.985808   0.992153   0.966691   \n",
       "max     2.063020              0.946759   0.990741   0.995255   0.980379   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.888860   0.767077  6958.920000  99057.920000   734.080000  ...   \n",
       "std     0.072527   0.226870  2058.165538    305.860235   305.860235  ...   \n",
       "min     0.627400   0.079255   719.000000  98425.000000   266.000000  ...   \n",
       "25%     0.853737   0.737020  6686.250000  98892.250000   504.500000  ...   \n",
       "50%     0.908135   0.874173  7930.500000  99092.000000   700.000000  ...   \n",
       "75%     0.938878   0.912864  8281.500000  99287.500000   899.750000  ...   \n",
       "max     0.969562   0.933973  8473.000000  99526.000000  1367.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.864967   0.962887     0.982361    0.912823   \n",
       "std                    0.163544   0.074923     0.033868    0.144888   \n",
       "min                    0.281415   0.601852     0.812064    0.314717   \n",
       "25%                    0.846023   0.976521     0.988695    0.926056   \n",
       "50%                    0.929398   0.988509     0.993720    0.969584   \n",
       "75%                    0.962880   0.995618     0.997065    0.987122   \n",
       "max                    0.980820   0.997355     0.998499    0.994991   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.922567    0.822024  4971.600000  66193.180000  334.820000   \n",
       "std         0.078954    0.230768  1395.685948    187.131045  187.131045   \n",
       "min         0.535615    0.095734   579.000000  65672.000000   94.000000   \n",
       "25%         0.907529    0.825066  4990.000000  66078.750000  176.000000   \n",
       "50%         0.940096    0.920139  5565.000000  66231.500000  296.500000   \n",
       "75%         0.968208    0.960111  5806.750000  66352.000000  449.250000   \n",
       "max         0.983527    0.977348  5911.000000  66434.000000  856.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean   1076.400000  \n",
       "std    1395.685948  \n",
       "min     137.000000  \n",
       "25%     241.250000  \n",
       "50%     483.000000  \n",
       "75%    1058.000000  \n",
       "max    5469.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1d237-4374-48ca-89a1-a0a960795169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b408db9-474e-4128-aadd-440360e1f9e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T00:27:21.998083Z",
     "iopub.status.busy": "2021-06-10T00:27:21.997077Z",
     "iopub.status.idle": "2021-06-10T02:48:08.200265Z",
     "shell.execute_reply": "2021-06-10T02:48:08.199265Z",
     "shell.execute_reply.started": "2021-06-10T00:27:21.998083Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_64-16-12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_64-16-12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_64 (Functio (None, 2, 2, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 2,239,244\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_64-16-12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_64-16-12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_64-16-12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 57:43 - loss: 3.5130 - categorical_accuracy: 0.0312 - top-3: 0.1875 - ROC-AUC: 0.5140 - PR-AUC: 0.0865 - precision: 0.1111 - recall: 0.0312 - TP: 1.0000 - TN: 344.0000 - FP: 8.0000 - FN: 31.0000                 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2090s vs `on_train_batch_end` time: 12.0509s). Check your callbacks.\n",
      "567/567 [==============================] - 178s 314ms/step - loss: 2.2618 - categorical_accuracy: 0.2524 - top-3: 0.5433 - ROC-AUC: 0.7580 - PR-AUC: 0.2714 - precision: 0.5505 - recall: 0.0956 - TP: 867.0000 - TN: 99084.0000 - FP: 708.0000 - FN: 8205.0000 - val_loss: 1.3268 - val_categorical_accuracy: 0.4818 - val_top-3: 0.8366 - val_ROC-AUC: 0.9185 - val_PR-AUC: 0.5451 - val_precision: 0.6791 - val_recall: 0.2596 - val_TP: 1570.0000 - val_TN: 65786.0000 - val_FP: 742.0000 - val_FN: 4478.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.8957 - categorical_accuracy: 0.6900 - top-3: 0.9204 - ROC-AUC: 0.9612 - PR-AUC: 0.7779 - precision: 0.7890 - recall: 0.5972 - TP: 5418.0000 - TN: 98343.0000 - FP: 1449.0000 - FN: 3654.0000 - val_loss: 0.4030 - val_categorical_accuracy: 0.8661 - val_top-3: 0.9785 - val_ROC-AUC: 0.9914 - val_PR-AUC: 0.9411 - val_precision: 0.8980 - val_recall: 0.8340 - val_TP: 5044.0000 - val_TN: 65955.0000 - val_FP: 573.0000 - val_FN: 1004.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 165s 292ms/step - loss: 0.3139 - categorical_accuracy: 0.9005 - top-3: 0.9875 - ROC-AUC: 0.9926 - PR-AUC: 0.9587 - precision: 0.9175 - recall: 0.8860 - TP: 8038.0000 - TN: 99069.0000 - FP: 723.0000 - FN: 1034.0000 - val_loss: 0.2750 - val_categorical_accuracy: 0.9147 - val_top-3: 0.9897 - val_ROC-AUC: 0.9934 - val_PR-AUC: 0.9645 - val_precision: 0.9267 - val_recall: 0.9072 - val_TP: 5487.0000 - val_TN: 66094.0000 - val_FP: 434.0000 - val_FN: 561.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.2433 - categorical_accuracy: 0.9237 - top-3: 0.9937 - ROC-AUC: 0.9948 - PR-AUC: 0.9721 - precision: 0.9349 - recall: 0.9138 - TP: 8290.0000 - TN: 99215.0000 - FP: 577.0000 - FN: 782.0000 - val_loss: 0.1992 - val_categorical_accuracy: 0.9395 - val_top-3: 0.9939 - val_ROC-AUC: 0.9958 - val_PR-AUC: 0.9802 - val_precision: 0.9474 - val_recall: 0.9327 - val_TP: 5641.0000 - val_TN: 66215.0000 - val_FP: 313.0000 - val_FN: 407.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 165s 291ms/step - loss: 0.1947 - categorical_accuracy: 0.9419 - top-3: 0.9935 - ROC-AUC: 0.9951 - PR-AUC: 0.9792 - precision: 0.9518 - recall: 0.9344 - TP: 8477.0000 - TN: 99363.0000 - FP: 429.0000 - FN: 595.0000 - val_loss: 0.1338 - val_categorical_accuracy: 0.9559 - val_top-3: 0.9950 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9909 - val_precision: 0.9643 - val_recall: 0.9519 - val_TP: 5757.0000 - val_TN: 66315.0000 - val_FP: 213.0000 - val_FN: 291.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.1602 - categorical_accuracy: 0.9528 - top-3: 0.9948 - ROC-AUC: 0.9965 - PR-AUC: 0.9851 - precision: 0.9590 - recall: 0.9462 - TP: 8584.0000 - TN: 99425.0000 - FP: 367.0000 - FN: 488.0000 - val_loss: 0.1949 - val_categorical_accuracy: 0.9423 - val_top-3: 0.9909 - val_ROC-AUC: 0.9959 - val_PR-AUC: 0.9805 - val_precision: 0.9498 - val_recall: 0.9352 - val_TP: 5656.0000 - val_TN: 66229.0000 - val_FP: 299.0000 - val_FN: 392.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.1549 - categorical_accuracy: 0.9561 - top-3: 0.9950 - ROC-AUC: 0.9965 - PR-AUC: 0.9857 - precision: 0.9632 - recall: 0.9497 - TP: 8616.0000 - TN: 99463.0000 - FP: 329.0000 - FN: 456.0000 - val_loss: 0.1159 - val_categorical_accuracy: 0.9663 - val_top-3: 0.9972 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9904 - val_precision: 0.9698 - val_recall: 0.9626 - val_TP: 5822.0000 - val_TN: 66347.0000 - val_FP: 181.0000 - val_FN: 226.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 161s 285ms/step - loss: 0.1355 - categorical_accuracy: 0.9604 - top-3: 0.9964 - ROC-AUC: 0.9972 - PR-AUC: 0.9882 - precision: 0.9666 - recall: 0.9561 - TP: 8674.0000 - TN: 99492.0000 - FP: 300.0000 - FN: 398.0000 - val_loss: 0.2180 - val_categorical_accuracy: 0.9410 - val_top-3: 0.9914 - val_ROC-AUC: 0.9940 - val_PR-AUC: 0.9769 - val_precision: 0.9510 - val_recall: 0.9340 - val_TP: 5649.0000 - val_TN: 66237.0000 - val_FP: 291.0000 - val_FN: 399.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 189s 333ms/step - loss: 0.0904 - categorical_accuracy: 0.9732 - top-3: 0.9979 - ROC-AUC: 0.9984 - PR-AUC: 0.9941 - precision: 0.9771 - recall: 0.9699 - TP: 8799.0000 - TN: 99586.0000 - FP: 206.0000 - FN: 273.0000 - val_loss: 0.0742 - val_categorical_accuracy: 0.9793 - val_top-3: 0.9980 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9947 - val_precision: 0.9821 - val_recall: 0.9773 - val_TP: 5911.0000 - val_TN: 66420.0000 - val_FP: 108.0000 - val_FN: 137.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 200s 353ms/step - loss: 0.1106 - categorical_accuracy: 0.9684 - top-3: 0.9970 - ROC-AUC: 0.9976 - PR-AUC: 0.9913 - precision: 0.9724 - recall: 0.9647 - TP: 8752.0000 - TN: 99544.0000 - FP: 248.0000 - FN: 320.0000 - val_loss: 0.1168 - val_categorical_accuracy: 0.9673 - val_top-3: 0.9931 - val_ROC-AUC: 0.9976 - val_PR-AUC: 0.9910 - val_precision: 0.9730 - val_recall: 0.9643 - val_TP: 5832.0000 - val_TN: 66366.0000 - val_FP: 162.0000 - val_FN: 216.0000\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 183s 322ms/step - loss: 0.0952 - categorical_accuracy: 0.9737 - top-3: 0.9978 - ROC-AUC: 0.9979 - PR-AUC: 0.9921 - precision: 0.9767 - recall: 0.9699 - TP: 8799.0000 - TN: 99582.0000 - FP: 210.0000 - FN: 273.0000 - val_loss: 0.0707 - val_categorical_accuracy: 0.9792 - val_top-3: 0.9988 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9957 - val_precision: 0.9814 - val_recall: 0.9759 - val_TP: 5902.0000 - val_TN: 66416.0000 - val_FP: 112.0000 - val_FN: 146.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0677 - categorical_accuracy: 0.9820 - top-3: 0.9991 - ROC-AUC: 0.9984 - PR-AUC: 0.9943 - precision: 0.9837 - recall: 0.9809 - TP: 8899.0000 - TN: 99645.0000 - FP: 147.0000 - FN: 173.0000 - val_loss: 0.0296 - val_categorical_accuracy: 0.9927 - val_top-3: 0.9995 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9981 - val_precision: 0.9935 - val_recall: 0.9919 - val_TP: 5999.0000 - val_TN: 66489.0000 - val_FP: 39.0000 - val_FN: 49.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 172s 304ms/step - loss: 0.1021 - categorical_accuracy: 0.9717 - top-3: 0.9974 - ROC-AUC: 0.9976 - PR-AUC: 0.9919 - precision: 0.9758 - recall: 0.9685 - TP: 8786.0000 - TN: 99574.0000 - FP: 218.0000 - FN: 286.0000 - val_loss: 0.0493 - val_categorical_accuracy: 0.9858 - val_top-3: 0.9982 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9974 - val_precision: 0.9879 - val_recall: 0.9841 - val_TP: 5952.0000 - val_TN: 66455.0000 - val_FP: 73.0000 - val_FN: 96.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 187s 329ms/step - loss: 0.0814 - categorical_accuracy: 0.9773 - top-3: 0.9983 - ROC-AUC: 0.9983 - PR-AUC: 0.9941 - precision: 0.9798 - recall: 0.9741 - TP: 8837.0000 - TN: 99610.0000 - FP: 182.0000 - FN: 235.0000 - val_loss: 0.0836 - val_categorical_accuracy: 0.9752 - val_top-3: 0.9970 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9951 - val_precision: 0.9798 - val_recall: 0.9696 - val_TP: 5864.0000 - val_TN: 66407.0000 - val_FP: 121.0000 - val_FN: 184.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 190s 336ms/step - loss: 0.0698 - categorical_accuracy: 0.9797 - top-3: 0.9980 - ROC-AUC: 0.9988 - PR-AUC: 0.9958 - precision: 0.9831 - recall: 0.9775 - TP: 8868.0000 - TN: 99640.0000 - FP: 152.0000 - FN: 204.0000 - val_loss: 0.0331 - val_categorical_accuracy: 0.9896 - val_top-3: 0.9998 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9994 - val_precision: 0.9914 - val_recall: 0.9869 - val_TP: 5969.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 79.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 184s 325ms/step - loss: 0.0679 - categorical_accuracy: 0.9786 - top-3: 0.9981 - ROC-AUC: 0.9991 - PR-AUC: 0.9961 - precision: 0.9817 - recall: 0.9764 - TP: 8858.0000 - TN: 99627.0000 - FP: 165.0000 - FN: 214.0000 - val_loss: 0.0999 - val_categorical_accuracy: 0.9729 - val_top-3: 0.9964 - val_ROC-AUC: 0.9973 - val_PR-AUC: 0.9896 - val_precision: 0.9759 - val_recall: 0.9702 - val_TP: 5868.0000 - val_TN: 66383.0000 - val_FP: 145.0000 - val_FN: 180.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 181s 318ms/step - loss: 0.0803 - categorical_accuracy: 0.9770 - top-3: 0.9977 - ROC-AUC: 0.9982 - PR-AUC: 0.9939 - precision: 0.9789 - recall: 0.9746 - TP: 8842.0000 - TN: 99601.0000 - FP: 191.0000 - FN: 230.0000 - val_loss: 0.0550 - val_categorical_accuracy: 0.9836 - val_top-3: 0.9988 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9960 - val_precision: 0.9859 - val_recall: 0.9828 - val_TP: 5944.0000 - val_TN: 66443.0000 - val_FP: 85.0000 - val_FN: 104.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 184s 325ms/step - loss: 0.0416 - categorical_accuracy: 0.9886 - top-3: 0.9989 - ROC-AUC: 0.9991 - PR-AUC: 0.9969 - precision: 0.9905 - recall: 0.9878 - TP: 8961.0000 - TN: 99706.0000 - FP: 86.0000 - FN: 111.0000 - val_loss: 0.0634 - val_categorical_accuracy: 0.9798 - val_top-3: 0.9982 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9962 - val_precision: 0.9825 - val_recall: 0.9762 - val_TP: 5904.0000 - val_TN: 66423.0000 - val_FP: 105.0000 - val_FN: 144.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 181s 320ms/step - loss: 0.0615 - categorical_accuracy: 0.9820 - top-3: 0.9980 - ROC-AUC: 0.9989 - PR-AUC: 0.9959 - precision: 0.9848 - recall: 0.9807 - TP: 8897.0000 - TN: 99655.0000 - FP: 137.0000 - FN: 175.0000 - val_loss: 0.0343 - val_categorical_accuracy: 0.9901 - val_top-3: 0.9992 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9983 - val_precision: 0.9919 - val_recall: 0.9889 - val_TP: 5981.0000 - val_TN: 66479.0000 - val_FP: 49.0000 - val_FN: 67.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 178s 313ms/step - loss: 0.0482 - categorical_accuracy: 0.9857 - top-3: 0.9986 - ROC-AUC: 0.9989 - PR-AUC: 0.9966 - precision: 0.9877 - recall: 0.9838 - TP: 8925.0000 - TN: 99681.0000 - FP: 111.0000 - FN: 147.0000 - val_loss: 0.0449 - val_categorical_accuracy: 0.9874 - val_top-3: 0.9980 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9977 - val_precision: 0.9892 - val_recall: 0.9851 - val_TP: 5958.0000 - val_TN: 66463.0000 - val_FP: 65.0000 - val_FN: 90.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0478 - categorical_accuracy: 0.9854 - top-3: 0.9985 - ROC-AUC: 0.9990 - PR-AUC: 0.9968 - precision: 0.9874 - recall: 0.9841 - TP: 8928.0000 - TN: 99678.0000 - FP: 114.0000 - FN: 144.0000 - val_loss: 0.0654 - val_categorical_accuracy: 0.9805 - val_top-3: 0.9983 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9958 - val_precision: 0.9819 - val_recall: 0.9787 - val_TP: 5919.0000 - val_TN: 66419.0000 - val_FP: 109.0000 - val_FN: 129.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0487 - categorical_accuracy: 0.9859 - top-3: 0.9985 - ROC-AUC: 0.9990 - PR-AUC: 0.9970 - precision: 0.9884 - recall: 0.9841 - TP: 8928.0000 - TN: 99687.0000 - FP: 105.0000 - FN: 144.0000 - val_loss: 0.0234 - val_categorical_accuracy: 0.9926 - val_top-3: 0.9998 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9930 - val_recall: 0.9911 - val_TP: 5994.0000 - val_TN: 66486.0000 - val_FP: 42.0000 - val_FN: 54.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0536 - categorical_accuracy: 0.9858 - top-3: 0.9980 - ROC-AUC: 0.9989 - PR-AUC: 0.9969 - precision: 0.9875 - recall: 0.9843 - TP: 8930.0000 - TN: 99679.0000 - FP: 113.0000 - FN: 142.0000 - val_loss: 0.0524 - val_categorical_accuracy: 0.9838 - val_top-3: 0.9995 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9959 - val_precision: 0.9856 - val_recall: 0.9823 - val_TP: 5941.0000 - val_TN: 66441.0000 - val_FP: 87.0000 - val_FN: 107.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 165s 290ms/step - loss: 0.0281 - categorical_accuracy: 0.9923 - top-3: 0.9994 - ROC-AUC: 0.9996 - PR-AUC: 0.9988 - precision: 0.9939 - recall: 0.9906 - TP: 8987.0000 - TN: 99737.0000 - FP: 55.0000 - FN: 85.0000 - val_loss: 0.0119 - val_categorical_accuracy: 0.9962 - val_top-3: 0.9995 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9997 - val_precision: 0.9967 - val_recall: 0.9960 - val_TP: 6024.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 24.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0443 - categorical_accuracy: 0.9889 - top-3: 0.9989 - ROC-AUC: 0.9986 - PR-AUC: 0.9957 - precision: 0.9896 - recall: 0.9877 - TP: 8960.0000 - TN: 99698.0000 - FP: 94.0000 - FN: 112.0000 - val_loss: 0.0317 - val_categorical_accuracy: 0.9901 - val_top-3: 0.9983 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9987 - val_precision: 0.9934 - val_recall: 0.9893 - val_TP: 5983.0000 - val_TN: 66488.0000 - val_FP: 40.0000 - val_FN: 65.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0426 - categorical_accuracy: 0.9870 - top-3: 0.9982 - ROC-AUC: 0.9993 - PR-AUC: 0.9979 - precision: 0.9886 - recall: 0.9864 - TP: 8949.0000 - TN: 99689.0000 - FP: 103.0000 - FN: 123.0000 - val_loss: 0.0385 - val_categorical_accuracy: 0.9879 - val_top-3: 0.9985 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9977 - val_precision: 0.9914 - val_recall: 0.9868 - val_TP: 5968.0000 - val_TN: 66476.0000 - val_FP: 52.0000 - val_FN: 80.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0429 - categorical_accuracy: 0.9878 - top-3: 0.9986 - ROC-AUC: 0.9992 - PR-AUC: 0.9975 - precision: 0.9895 - recall: 0.9868 - TP: 8952.0000 - TN: 99697.0000 - FP: 95.0000 - FN: 120.0000 - val_loss: 0.0284 - val_categorical_accuracy: 0.9924 - val_top-3: 0.9987 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9979 - val_precision: 0.9930 - val_recall: 0.9917 - val_TP: 5998.0000 - val_TN: 66486.0000 - val_FP: 42.0000 - val_FN: 50.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0305 - categorical_accuracy: 0.9911 - top-3: 0.9994 - ROC-AUC: 0.9996 - PR-AUC: 0.9985 - precision: 0.9927 - recall: 0.9897 - TP: 8979.0000 - TN: 99726.0000 - FP: 66.0000 - FN: 93.0000 - val_loss: 0.0198 - val_categorical_accuracy: 0.9954 - val_top-3: 0.9995 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9986 - val_precision: 0.9957 - val_recall: 0.9947 - val_TP: 6016.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 32.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0431 - categorical_accuracy: 0.9870 - top-3: 0.9989 - ROC-AUC: 0.9992 - PR-AUC: 0.9972 - precision: 0.9883 - recall: 0.9866 - TP: 8950.0000 - TN: 99686.0000 - FP: 106.0000 - FN: 122.0000 - val_loss: 0.0121 - val_categorical_accuracy: 0.9967 - val_top-3: 0.9998 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9995 - val_precision: 0.9970 - val_recall: 0.9957 - val_TP: 6022.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 26.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0265 - categorical_accuracy: 0.9935 - top-3: 0.9997 - ROC-AUC: 0.9993 - PR-AUC: 0.9979 - precision: 0.9943 - recall: 0.9933 - TP: 9011.0000 - TN: 99740.0000 - FP: 52.0000 - FN: 61.0000 - val_loss: 0.0413 - val_categorical_accuracy: 0.9894 - val_top-3: 0.9983 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9969 - val_precision: 0.9901 - val_recall: 0.9889 - val_TP: 5981.0000 - val_TN: 66468.0000 - val_FP: 60.0000 - val_FN: 67.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 162s 286ms/step - loss: 0.0414 - categorical_accuracy: 0.9883 - top-3: 0.9993 - ROC-AUC: 0.9994 - PR-AUC: 0.9978 - precision: 0.9893 - recall: 0.9875 - TP: 8959.0000 - TN: 99695.0000 - FP: 97.0000 - FN: 113.0000 - val_loss: 0.0558 - val_categorical_accuracy: 0.9841 - val_top-3: 0.9974 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9972 - val_precision: 0.9859 - val_recall: 0.9820 - val_TP: 5939.0000 - val_TN: 66443.0000 - val_FP: 85.0000 - val_FN: 109.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.0310 - categorical_accuracy: 0.9897 - top-3: 0.9992 - ROC-AUC: 0.9995 - PR-AUC: 0.9983 - precision: 0.9915 - recall: 0.9891 - TP: 8973.0000 - TN: 99715.0000 - FP: 77.0000 - FN: 99.0000 - val_loss: 0.0166 - val_categorical_accuracy: 0.9955 - val_top-3: 0.9997 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9986 - val_precision: 0.9962 - val_recall: 0.9950 - val_TP: 6018.0000 - val_TN: 66505.0000 - val_FP: 23.0000 - val_FN: 30.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0249 - categorical_accuracy: 0.9926 - top-3: 0.9993 - ROC-AUC: 0.9995 - PR-AUC: 0.9987 - precision: 0.9932 - recall: 0.9920 - TP: 8999.0000 - TN: 99730.0000 - FP: 62.0000 - FN: 73.0000 - val_loss: 0.0386 - val_categorical_accuracy: 0.9888 - val_top-3: 0.9988 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9973 - val_precision: 0.9896 - val_recall: 0.9883 - val_TP: 5977.0000 - val_TN: 66465.0000 - val_FP: 63.0000 - val_FN: 71.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 165s 290ms/step - loss: 0.0210 - categorical_accuracy: 0.9938 - top-3: 0.9997 - ROC-AUC: 0.9996 - PR-AUC: 0.9989 - precision: 0.9948 - recall: 0.9932 - TP: 9010.0000 - TN: 99745.0000 - FP: 47.0000 - FN: 62.0000 - val_loss: 0.0228 - val_categorical_accuracy: 0.9944 - val_top-3: 0.9993 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9988 - val_precision: 0.9954 - val_recall: 0.9939 - val_TP: 6011.0000 - val_TN: 66500.0000 - val_FP: 28.0000 - val_FN: 37.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 164s 288ms/step - loss: 0.0302 - categorical_accuracy: 0.9926 - top-3: 0.9996 - ROC-AUC: 0.9994 - PR-AUC: 0.9980 - precision: 0.9933 - recall: 0.9920 - TP: 8999.0000 - TN: 99731.0000 - FP: 61.0000 - FN: 73.0000 - val_loss: 0.0583 - val_categorical_accuracy: 0.9848 - val_top-3: 0.9975 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9947 - val_precision: 0.9872 - val_recall: 0.9838 - val_TP: 5950.0000 - val_TN: 66451.0000 - val_FP: 77.0000 - val_FN: 98.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0178 - categorical_accuracy: 0.9953 - top-3: 0.9994 - ROC-AUC: 0.9997 - PR-AUC: 0.9989 - precision: 0.9964 - recall: 0.9948 - TP: 9025.0000 - TN: 99759.0000 - FP: 33.0000 - FN: 47.0000 - val_loss: 0.0829 - val_categorical_accuracy: 0.9848 - val_top-3: 0.9970 - val_ROC-AUC: 0.9974 - val_PR-AUC: 0.9917 - val_precision: 0.9851 - val_recall: 0.9845 - val_TP: 5954.0000 - val_TN: 66438.0000 - val_FP: 90.0000 - val_FN: 94.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 165s 290ms/step - loss: 0.0403 - categorical_accuracy: 0.9888 - top-3: 0.9991 - ROC-AUC: 0.9990 - PR-AUC: 0.9969 - precision: 0.9903 - recall: 0.9883 - TP: 8966.0000 - TN: 99704.0000 - FP: 88.0000 - FN: 106.0000 - val_loss: 0.0218 - val_categorical_accuracy: 0.9945 - val_top-3: 0.9995 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9985 - val_precision: 0.9949 - val_recall: 0.9934 - val_TP: 6008.0000 - val_TN: 66497.0000 - val_FP: 31.0000 - val_FN: 40.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 165s 291ms/step - loss: 0.0175 - categorical_accuracy: 0.9953 - top-3: 0.9997 - ROC-AUC: 0.9998 - PR-AUC: 0.9993 - precision: 0.9958 - recall: 0.9945 - TP: 9022.0000 - TN: 99754.0000 - FP: 38.0000 - FN: 50.0000 - val_loss: 0.0108 - val_categorical_accuracy: 0.9969 - val_top-3: 0.9993 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9969 - val_recall: 0.9967 - val_TP: 6028.0000 - val_TN: 66509.0000 - val_FP: 19.0000 - val_FN: 20.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0283 - categorical_accuracy: 0.9914 - top-3: 0.9992 - ROC-AUC: 0.9993 - PR-AUC: 0.9981 - precision: 0.9922 - recall: 0.9906 - TP: 8987.0000 - TN: 99721.0000 - FP: 71.0000 - FN: 85.0000 - val_loss: 0.0475 - val_categorical_accuracy: 0.9876 - val_top-3: 0.9993 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9952 - val_precision: 0.9882 - val_recall: 0.9871 - val_TP: 5970.0000 - val_TN: 66457.0000 - val_FP: 71.0000 - val_FN: 78.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0265 - categorical_accuracy: 0.9945 - top-3: 0.9992 - ROC-AUC: 0.9994 - PR-AUC: 0.9982 - precision: 0.9953 - recall: 0.9938 - TP: 9016.0000 - TN: 99749.0000 - FP: 43.0000 - FN: 56.0000 - val_loss: 0.0331 - val_categorical_accuracy: 0.9922 - val_top-3: 0.9992 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9970 - val_precision: 0.9927 - val_recall: 0.9919 - val_TP: 5999.0000 - val_TN: 66484.0000 - val_FP: 44.0000 - val_FN: 49.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 163s 287ms/step - loss: 0.0332 - categorical_accuracy: 0.9911 - top-3: 0.9991 - ROC-AUC: 0.9991 - PR-AUC: 0.9970 - precision: 0.9928 - recall: 0.9906 - TP: 8987.0000 - TN: 99727.0000 - FP: 65.0000 - FN: 85.0000 - val_loss: 0.0160 - val_categorical_accuracy: 0.9954 - val_top-3: 0.9995 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9994 - val_precision: 0.9967 - val_recall: 0.9950 - val_TP: 6018.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 30.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 161s 284ms/step - loss: 0.0256 - categorical_accuracy: 0.9927 - top-3: 0.9994 - ROC-AUC: 0.9995 - PR-AUC: 0.9983 - precision: 0.9933 - recall: 0.9920 - TP: 8999.0000 - TN: 99731.0000 - FP: 61.0000 - FN: 73.0000 - val_loss: 0.0198 - val_categorical_accuracy: 0.9949 - val_top-3: 0.9995 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9991 - val_precision: 0.9954 - val_recall: 0.9934 - val_TP: 6008.0000 - val_TN: 66500.0000 - val_FP: 28.0000 - val_FN: 40.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0259 - categorical_accuracy: 0.9942 - top-3: 0.9991 - ROC-AUC: 0.9996 - PR-AUC: 0.9988 - precision: 0.9949 - recall: 0.9927 - TP: 9006.0000 - TN: 99746.0000 - FP: 46.0000 - FN: 66.0000 - val_loss: 0.0314 - val_categorical_accuracy: 0.9919 - val_top-3: 0.9998 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9970 - val_precision: 0.9924 - val_recall: 0.9909 - val_TP: 5993.0000 - val_TN: 66482.0000 - val_FP: 46.0000 - val_FN: 55.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0216 - categorical_accuracy: 0.9949 - top-3: 0.9997 - ROC-AUC: 0.9994 - PR-AUC: 0.9982 - precision: 0.9954 - recall: 0.9945 - TP: 9022.0000 - TN: 99750.0000 - FP: 42.0000 - FN: 50.0000 - val_loss: 0.0104 - val_categorical_accuracy: 0.9969 - val_top-3: 0.9998 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9970 - val_recall: 0.9960 - val_TP: 6024.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 24.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 164s 289ms/step - loss: 0.0150 - categorical_accuracy: 0.9953 - top-3: 0.9997 - ROC-AUC: 0.9999 - PR-AUC: 0.9996 - precision: 0.9955 - recall: 0.9948 - TP: 9025.0000 - TN: 99751.0000 - FP: 41.0000 - FN: 47.0000 - val_loss: 0.0466 - val_categorical_accuracy: 0.9891 - val_top-3: 0.9995 - val_ROC-AUC: 0.9985 - val_PR-AUC: 0.9955 - val_precision: 0.9899 - val_recall: 0.9886 - val_TP: 5979.0000 - val_TN: 66467.0000 - val_FP: 61.0000 - val_FN: 69.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 163s 288ms/step - loss: 0.0211 - categorical_accuracy: 0.9942 - top-3: 0.9993 - ROC-AUC: 0.9994 - PR-AUC: 0.9983 - precision: 0.9945 - recall: 0.9935 - TP: 9013.0000 - TN: 99742.0000 - FP: 50.0000 - FN: 59.0000 - val_loss: 0.0167 - val_categorical_accuracy: 0.9952 - val_top-3: 0.9997 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9990 - val_precision: 0.9959 - val_recall: 0.9949 - val_TP: 6017.0000 - val_TN: 66503.0000 - val_FP: 25.0000 - val_FN: 31.000035 - TP: 8870.0000 - TN: 98159.0000 - FP: 49.0000 - F\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 162s 286ms/step - loss: 0.0270 - categorical_accuracy: 0.9927 - top-3: 0.9998 - ROC-AUC: 0.9995 - PR-AUC: 0.9984 - precision: 0.9931 - recall: 0.9923 - TP: 9002.0000 - TN: 99729.0000 - FP: 63.0000 - FN: 70.0000 - val_loss: 0.0147 - val_categorical_accuracy: 0.9960 - val_top-3: 0.9998 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9988 - val_precision: 0.9962 - val_recall: 0.9959 - val_TP: 6023.0000 - val_TN: 66505.0000 - val_FP: 23.0000 - val_FN: 25.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 162s 286ms/step - loss: 0.0231 - categorical_accuracy: 0.9934 - top-3: 0.9990 - ROC-AUC: 0.9996 - PR-AUC: 0.9989 - precision: 0.9943 - recall: 0.9926 - TP: 9005.0000 - TN: 99740.0000 - FP: 52.0000 - FN: 67.0000 - val_loss: 0.0103 - val_categorical_accuracy: 0.9962 - val_top-3: 1.0000 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9997 - val_precision: 0.9967 - val_recall: 0.9957 - val_TP: 6022.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 26.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.0109 - categorical_accuracy: 0.9965 - top-3: 0.9997 - ROC-AUC: 0.9999 - PR-AUC: 0.9997 - precision: 0.9967 - recall: 0.9963 - TP: 9038.0000 - TN: 99762.0000 - FP: 30.0000 - FN: 34.0000 - val_loss: 0.0376 - val_categorical_accuracy: 0.9888 - val_top-3: 0.9998 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9976 - val_precision: 0.9896 - val_recall: 0.9879 - val_TP: 5975.0000 - val_TN: 66465.0000 - val_FP: 63.0000 - val_FN: 73.0000\n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 162s 285ms/step - loss: 0.0265 - categorical_accuracy: 0.9932 - top-3: 0.9996 - ROC-AUC: 0.9993 - PR-AUC: 0.9982 - precision: 0.9939 - recall: 0.9927 - TP: 9006.0000 - TN: 99737.0000 - FP: 55.0000 - FN: 66.0000 - val_loss: 0.0402 - val_categorical_accuracy: 0.9906 - val_top-3: 0.9988 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9965 - val_precision: 0.9916 - val_recall: 0.9904 - val_TP: 5990.0000 - val_TN: 66477.0000 - val_FP: 51.0000 - val_FN: 58.0000\n",
      "-----\n",
      "(8441073.32 ms) == (140m:41s)\n",
      "-----\n",
      "\n",
      "\n",
      "26\n",
      "['mobilenetv2_1.00_64-16-12.tensorboard',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.001_0.4818_1.3268.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.002_0.8661_0.4030.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.003_0.9147_0.2750.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.004_0.9395_0.1992.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.005_0.9559_0.1338.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.007_0.9663_0.1159.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.009_0.9793_0.0742.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.011_0.9792_0.0707.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.012_0.9927_0.0296.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.022_0.9926_0.0234.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.024_0.9962_0.0119.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.029_0.9967_0.0121.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.038_0.9969_0.0108.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.044_0.9969_0.0104.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.048_0.9962_0.0103.hdf5',\n",
      " 'mobilenetv2_1.00_64-16-12.weights.050.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_64-16-12.csv',\n",
      " 'model.mobilenetv2_1.00_64-16-12.h5',\n",
      " 'weights.mobilenetv2_1.00_64-16-12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_64-16-12\n",
    "model_9 = consecutiveModelTraining(\n",
    "    input_size=64,\n",
    "    batch_size=16,\n",
    "    weights=None,\n",
    "    dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7956b712-e0ca-42fa-803c-737498452ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T02:48:08.201265Z",
     "iopub.status.busy": "2021-06-10T02:48:08.201265Z",
     "iopub.status.idle": "2021-06-10T02:48:08.280270Z",
     "shell.execute_reply": "2021-06-10T02:48:08.279271Z",
     "shell.execute_reply.started": "2021-06-10T02:48:08.201265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.123873</td>\n",
       "      <td>0.961215</td>\n",
       "      <td>0.987557</td>\n",
       "      <td>0.993094</td>\n",
       "      <td>0.975879</td>\n",
       "      <td>0.971624</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>8656.400000</td>\n",
       "      <td>99612.800000</td>\n",
       "      <td>179.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970675</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>0.984995</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.963819</td>\n",
       "      <td>5829.180000</td>\n",
       "      <td>66417.120000</td>\n",
       "      <td>110.880000</td>\n",
       "      <td>218.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.335667</td>\n",
       "      <td>0.111861</td>\n",
       "      <td>0.065078</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.106444</td>\n",
       "      <td>0.068567</td>\n",
       "      <td>0.136865</td>\n",
       "      <td>1241.638187</td>\n",
       "      <td>243.231644</td>\n",
       "      <td>243.231644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.064273</td>\n",
       "      <td>0.047118</td>\n",
       "      <td>0.105453</td>\n",
       "      <td>637.776869</td>\n",
       "      <td>143.274055</td>\n",
       "      <td>143.274055</td>\n",
       "      <td>637.776869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010871</td>\n",
       "      <td>0.252425</td>\n",
       "      <td>0.543320</td>\n",
       "      <td>0.758012</td>\n",
       "      <td>0.271373</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>867.000000</td>\n",
       "      <td>98343.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481812</td>\n",
       "      <td>0.836640</td>\n",
       "      <td>0.918505</td>\n",
       "      <td>0.545133</td>\n",
       "      <td>0.679066</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>1570.000000</td>\n",
       "      <td>65786.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.977045</td>\n",
       "      <td>0.997933</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>0.994144</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.974234</td>\n",
       "      <td>8838.250000</td>\n",
       "      <td>99603.250000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.994761</td>\n",
       "      <td>0.981953</td>\n",
       "      <td>0.976480</td>\n",
       "      <td>5905.750000</td>\n",
       "      <td>66419.250000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>42.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.988040</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.997027</td>\n",
       "      <td>0.989394</td>\n",
       "      <td>0.987158</td>\n",
       "      <td>8955.500000</td>\n",
       "      <td>99696.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988757</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>0.997127</td>\n",
       "      <td>0.989735</td>\n",
       "      <td>0.987517</td>\n",
       "      <td>5972.500000</td>\n",
       "      <td>66466.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>75.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.081123</td>\n",
       "      <td>0.992725</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.993755</td>\n",
       "      <td>0.992201</td>\n",
       "      <td>9001.250000</td>\n",
       "      <td>99735.500000</td>\n",
       "      <td>188.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993965</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.994535</td>\n",
       "      <td>0.993014</td>\n",
       "      <td>6005.750000</td>\n",
       "      <td>66495.000000</td>\n",
       "      <td>108.750000</td>\n",
       "      <td>142.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.261839</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.996692</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>9038.000000</td>\n",
       "      <td>99762.000000</td>\n",
       "      <td>1449.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.996693</td>\n",
       "      <td>6028.000000</td>\n",
       "      <td>66510.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>4478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.123873              0.961215   0.987557   0.993094   0.975879   \n",
       "std     0.335667              0.111861   0.065078   0.034364   0.106444   \n",
       "min     0.010871              0.252425   0.543320   0.758012   0.271373   \n",
       "25%     0.026504              0.977045   0.997933   0.998358   0.994144   \n",
       "50%     0.042775              0.988040   0.998898   0.999116   0.997027   \n",
       "75%     0.081123              0.992725   0.999421   0.999451   0.998299   \n",
       "max     2.261839              0.996473   0.999780   0.999934   0.999746   \n",
       "\n",
       "       precision     recall           TP            TN           FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.000000    50.000000  ...   \n",
       "mean    0.971624   0.954189  8656.400000  99612.800000   179.200000  ...   \n",
       "std     0.068567   0.136865  1241.638187    243.231644   243.231644  ...   \n",
       "min     0.550476   0.095569   867.000000  98343.000000    30.000000  ...   \n",
       "25%     0.979097   0.974234  8838.250000  99603.250000    56.500000  ...   \n",
       "50%     0.989394   0.987158  8955.500000  99696.000000    96.000000  ...   \n",
       "75%     0.993755   0.992201  9001.250000  99735.500000   188.750000  ...   \n",
       "max     0.996692   0.996252  9038.000000  99762.000000  1449.000000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.970675   0.994444     0.996965    0.984995   \n",
       "std                    0.074463   0.023064     0.011452    0.064273   \n",
       "min                    0.481812   0.836640     0.918505    0.545133   \n",
       "25%                    0.979456   0.997396     0.998470    0.994761   \n",
       "50%                    0.988757   0.998843     0.999005    0.997127   \n",
       "75%                    0.993965   0.999504     0.999551    0.998695   \n",
       "max                    0.996858   1.000000     0.999905    0.999687   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.977431    0.963819  5829.180000  66417.120000  110.880000   \n",
       "std         0.047118    0.105453   637.776869    143.274055  143.274055   \n",
       "min         0.679066    0.259590  1570.000000  65786.000000   18.000000   \n",
       "25%         0.981953    0.976480  5905.750000  66419.250000   33.000000   \n",
       "50%         0.989735    0.987517  5972.500000  66466.000000   62.000000   \n",
       "75%         0.994535    0.993014  6005.750000  66495.000000  108.750000   \n",
       "max         0.997021    0.996693  6028.000000  66510.000000  742.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean    218.820000  \n",
       "std     637.776869  \n",
       "min      20.000000  \n",
       "25%      42.250000  \n",
       "50%      75.500000  \n",
       "75%     142.250000  \n",
       "max    4478.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26807083-09f6-48cb-8e17-04c924e10546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0571e9b9-b324-4785-a0bb-0d35d6fd78b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T02:48:08.467281Z",
     "iopub.status.busy": "2021-06-10T02:48:08.467281Z",
     "iopub.status.idle": "2021-06-10T05:11:31.873080Z",
     "shell.execute_reply": "2021-06-10T05:11:31.872093Z",
     "shell.execute_reply.started": "2021-06-10T02:48:08.467281Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9072 images belonging to 12 classes.\n",
      "Found 6048 images belonging to 12 classes.\n",
      "mobilenetv2_1.00_96-imagenet96-16-fc12\n",
      "\n",
      "\n",
      "Model: \"mobilenetv2_1.00_96-imagenet96-16-fc12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_96 (Functio (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 2,686,156\n",
      "Trainable params: 428,172\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "{'batch_size': 16,\n",
      " 'epochs': 50,\n",
      " 'steps_per_epoch': 567,\n",
      " 'total_train': 9072,\n",
      " 'total_val': 6048,\n",
      " 'validation_steps': 378}\n",
      "\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\checkpoints/mobilenetv2_1.00_96-imagenet96-16-fc12\n",
      "success\n",
      "\n",
      "D:\\MaskTheFace\\datasets\\_temp\\weights and models/mobilenetv2_1.00_96-imagenet96-16-fc12\n",
      "success\n",
      "\n",
      "\n",
      "mobilenetv2_1.00_96-imagenet96-16-fc12\n",
      "Epoch 1/50\n",
      "  2/567 [..............................] - ETA: 50:40 - loss: 6.7731 - categorical_accuracy: 0.1250 - top-3: 0.3125 - ROC-AUC: 0.5556 - PR-AUC: 0.1304 - precision: 0.0714 - recall: 0.0312 - TP: 1.0000 - TN: 339.0000 - FP: 13.0000 - FN: 31.0000            WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1840s vs `on_train_batch_end` time: 10.5752s). Check your callbacks.\n",
      "567/567 [==============================] - 183s 323ms/step - loss: 0.9639 - categorical_accuracy: 0.7070 - top-3: 0.8719 - ROC-AUC: 0.9552 - PR-AUC: 0.8048 - precision: 0.8662 - recall: 0.6228 - TP: 5650.0000 - TN: 98919.0000 - FP: 873.0000 - FN: 3422.0000 - val_loss: 0.1553 - val_categorical_accuracy: 0.9573 - val_top-3: 0.9899 - val_ROC-AUC: 0.9986 - val_PR-AUC: 0.9912 - val_precision: 0.9767 - val_recall: 0.9413 - val_TP: 5693.0000 - val_TN: 66392.0000 - val_FP: 136.0000 - val_FN: 355.0000\n",
      "Epoch 2/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.4260 - categorical_accuracy: 0.8828 - top-3: 0.9612 - ROC-AUC: 0.9871 - PR-AUC: 0.9425 - precision: 0.9324 - recall: 0.8427 - TP: 7645.0000 - TN: 99238.0000 - FP: 554.0000 - FN: 1427.0000 - val_loss: 0.1019 - val_categorical_accuracy: 0.9689 - val_top-3: 0.9919 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9949 - val_precision: 0.9773 - val_recall: 0.9618 - val_TP: 5817.0000 - val_TN: 66393.0000 - val_FP: 135.0000 - val_FN: 231.0000\n",
      "Epoch 3/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.4486 - categorical_accuracy: 0.8849 - top-3: 0.9583 - ROC-AUC: 0.9864 - PR-AUC: 0.9434 - precision: 0.9386 - recall: 0.8471 - TP: 7685.0000 - TN: 99289.0000 - FP: 503.0000 - FN: 1387.0000 - val_loss: 0.1054 - val_categorical_accuracy: 0.9807 - val_top-3: 0.9944 - val_ROC-AUC: 0.9990 - val_PR-AUC: 0.9954 - val_precision: 0.9920 - val_recall: 0.9592 - val_TP: 5801.0000 - val_TN: 66481.0000 - val_FP: 47.0000 - val_FN: 247.0000\n",
      "Epoch 4/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.4646 - categorical_accuracy: 0.8753 - top-3: 0.9566 - ROC-AUC: 0.9870 - PR-AUC: 0.9422 - precision: 0.9332 - recall: 0.8386 - TP: 7608.0000 - TN: 99247.0000 - FP: 545.0000 - FN: 1464.0000 - val_loss: 0.1201 - val_categorical_accuracy: 0.9640 - val_top-3: 0.9927 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9936 - val_precision: 0.9787 - val_recall: 0.9501 - val_TP: 5746.0000 - val_TN: 66403.0000 - val_FP: 125.0000 - val_FN: 302.0000\n",
      "Epoch 5/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.4225 - categorical_accuracy: 0.8839 - top-3: 0.9583 - ROC-AUC: 0.9884 - PR-AUC: 0.9493 - precision: 0.9431 - recall: 0.8500 - TP: 7711.0000 - TN: 99327.0000 - FP: 465.0000 - FN: 1361.0000 - val_loss: 0.1130 - val_categorical_accuracy: 0.9726 - val_top-3: 0.9940 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9937 - val_precision: 0.9868 - val_recall: 0.9507 - val_TP: 5750.0000 - val_TN: 66451.0000 - val_FP: 77.0000 - val_FN: 298.0000\n",
      "Epoch 6/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.5114 - categorical_accuracy: 0.8696 - top-3: 0.9524 - ROC-AUC: 0.9858 - PR-AUC: 0.9389 - precision: 0.9339 - recall: 0.8353 - TP: 7578.0000 - TN: 99256.0000 - FP: 536.0000 - FN: 1494.0000 - val_loss: 0.3982 - val_categorical_accuracy: 0.8780 - val_top-3: 0.9659 - val_ROC-AUC: 0.9928 - val_PR-AUC: 0.9538 - val_precision: 0.9912 - val_recall: 0.8239 - val_TP: 4983.0000 - val_TN: 66484.0000 - val_FP: 44.0000 - val_FN: 1065.0000\n",
      "Epoch 7/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.4068 - categorical_accuracy: 0.8808 - top-3: 0.9588 - ROC-AUC: 0.9894 - PR-AUC: 0.9499 - precision: 0.9432 - recall: 0.8436 - TP: 7653.0000 - TN: 99331.0000 - FP: 461.0000 - FN: 1419.0000 - val_loss: 0.1675 - val_categorical_accuracy: 0.9626 - val_top-3: 0.9856 - val_ROC-AUC: 0.9974 - val_PR-AUC: 0.9877 - val_precision: 0.9885 - val_recall: 0.9243 - val_TP: 5590.0000 - val_TN: 66463.0000 - val_FP: 65.0000 - val_FN: 458.0000\n",
      "Epoch 8/50\n",
      "567/567 [==============================] - 169s 298ms/step - loss: 0.3817 - categorical_accuracy: 0.8899 - top-3: 0.9642 - ROC-AUC: 0.9904 - PR-AUC: 0.9553 - precision: 0.9515 - recall: 0.8564 - TP: 7769.0000 - TN: 99396.0000 - FP: 396.0000 - FN: 1303.0000 - val_loss: 0.1576 - val_categorical_accuracy: 0.9499 - val_top-3: 0.9876 - val_ROC-AUC: 0.9982 - val_PR-AUC: 0.9907 - val_precision: 0.9815 - val_recall: 0.9289 - val_TP: 5618.0000 - val_TN: 66422.0000 - val_FP: 106.0000 - val_FN: 430.0000\n",
      "Epoch 9/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.3685 - categorical_accuracy: 0.8978 - top-3: 0.9654 - ROC-AUC: 0.9908 - PR-AUC: 0.9585 - precision: 0.9531 - recall: 0.8661 - TP: 7857.0000 - TN: 99405.0000 - FP: 387.0000 - FN: 1215.0000 - val_loss: 0.5224 - val_categorical_accuracy: 0.9653 - val_top-3: 0.9874 - val_ROC-AUC: 0.9963 - val_PR-AUC: 0.9857 - val_precision: 0.9844 - val_recall: 0.9418 - val_TP: 5696.0000 - val_TN: 66438.0000 - val_FP: 90.0000 - val_FN: 352.0000\n",
      "Epoch 10/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.4299 - categorical_accuracy: 0.8924 - top-3: 0.9579 - ROC-AUC: 0.9894 - PR-AUC: 0.9529 - precision: 0.9501 - recall: 0.8603 - TP: 7805.0000 - TN: 99382.0000 - FP: 410.0000 - FN: 1267.0000 - val_loss: 0.1241 - val_categorical_accuracy: 0.9732 - val_top-3: 0.9934 - val_ROC-AUC: 0.9977 - val_PR-AUC: 0.9911 - val_precision: 0.9859 - val_recall: 0.9606 - val_TP: 5810.0000 - val_TN: 66445.0000 - val_FP: 83.0000 - val_FN: 238.0000 TP: 7776.0000 - TN: 99033.0000 - FP: 407.0000 - FN: 126\n",
      "Epoch 11/50\n",
      "567/567 [==============================] - 171s 302ms/step - loss: 0.3790 - categorical_accuracy: 0.8891 - top-3: 0.9543 - ROC-AUC: 0.9911 - PR-AUC: 0.9574 - precision: 0.9549 - recall: 0.8550 - TP: 7757.0000 - TN: 99426.0000 - FP: 366.0000 - FN: 1315.0000 - val_loss: 0.1161 - val_categorical_accuracy: 0.9787 - val_top-3: 0.9945 - val_ROC-AUC: 0.9984 - val_PR-AUC: 0.9940 - val_precision: 0.9915 - val_recall: 0.9413 - val_TP: 5693.0000 - val_TN: 66479.0000 - val_FP: 49.0000 - val_FN: 355.0000\n",
      "Epoch 12/50\n",
      "567/567 [==============================] - 169s 298ms/step - loss: 0.3490 - categorical_accuracy: 0.9016 - top-3: 0.9592 - ROC-AUC: 0.9921 - PR-AUC: 0.9621 - precision: 0.9642 - recall: 0.8649 - TP: 7846.0000 - TN: 99501.0000 - FP: 291.0000 - FN: 1226.0000 - val_loss: 0.0391 - val_categorical_accuracy: 0.9909 - val_top-3: 0.9970 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9992 - val_precision: 0.9962 - val_recall: 0.9854 - val_TP: 5960.0000 - val_TN: 66505.0000 - val_FP: 23.0000 - val_FN: 88.0000\n",
      "Epoch 13/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.3149 - categorical_accuracy: 0.9040 - top-3: 0.9604 - ROC-AUC: 0.9929 - PR-AUC: 0.9659 - precision: 0.9657 - recall: 0.8748 - TP: 7936.0000 - TN: 99510.0000 - FP: 282.0000 - FN: 1136.0000 - val_loss: 0.0900 - val_categorical_accuracy: 0.9732 - val_top-3: 0.9922 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9956 - val_precision: 0.9868 - val_recall: 0.9611 - val_TP: 5813.0000 - val_TN: 66450.0000 - val_FP: 78.0000 - val_FN: 235.0000\n",
      "Epoch 14/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3257 - categorical_accuracy: 0.9108 - top-3: 0.9612 - ROC-AUC: 0.9929 - PR-AUC: 0.9667 - precision: 0.9668 - recall: 0.8759 - TP: 7946.0000 - TN: 99519.0000 - FP: 273.0000 - FN: 1126.0000 - val_loss: 0.1376 - val_categorical_accuracy: 0.9615 - val_top-3: 0.9879 - val_ROC-AUC: 0.9970 - val_PR-AUC: 0.9894 - val_precision: 0.9767 - val_recall: 0.9550 - val_TP: 5776.0000 - val_TN: 66390.0000 - val_FP: 138.0000 - val_FN: 272.0000\n",
      "Epoch 15/50\n",
      "567/567 [==============================] - 169s 299ms/step - loss: 0.4199 - categorical_accuracy: 0.8926 - top-3: 0.9555 - ROC-AUC: 0.9904 - PR-AUC: 0.9565 - precision: 0.9579 - recall: 0.8548 - TP: 7755.0000 - TN: 99451.0000 - FP: 341.0000 - FN: 1317.0000 - val_loss: 0.1119 - val_categorical_accuracy: 0.9613 - val_top-3: 0.9932 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9940 - val_precision: 0.9808 - val_recall: 0.9468 - val_TP: 5726.0000 - val_TN: 66416.0000 - val_FP: 112.0000 - val_FN: 322.0000\n",
      "Epoch 16/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.4484 - categorical_accuracy: 0.8929 - top-3: 0.9540 - ROC-AUC: 0.9895 - PR-AUC: 0.9537 - precision: 0.9607 - recall: 0.8568 - TP: 7773.0000 - TN: 99474.0000 - FP: 318.0000 - FN: 1299.0000 - val_loss: 0.1503 - val_categorical_accuracy: 0.9615 - val_top-3: 0.9782 - val_ROC-AUC: 0.9979 - val_PR-AUC: 0.9911 - val_precision: 0.9873 - val_recall: 0.9388 - val_TP: 5678.0000 - val_TN: 66455.0000 - val_FP: 73.0000 - val_FN: 370.0000\n",
      "Epoch 17/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.3608 - categorical_accuracy: 0.9031 - top-3: 0.9575 - ROC-AUC: 0.9915 - PR-AUC: 0.9617 - precision: 0.9619 - recall: 0.8711 - TP: 7903.0000 - TN: 99479.0000 - FP: 313.0000 - FN: 1169.0000 - val_loss: 0.1043 - val_categorical_accuracy: 0.9729 - val_top-3: 0.9929 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9957 - val_precision: 0.9955 - val_recall: 0.9552 - val_TP: 5777.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 271.0000\n",
      "Epoch 18/50\n",
      "567/567 [==============================] - 173s 306ms/step - loss: 0.4509 - categorical_accuracy: 0.8954 - top-3: 0.9519 - ROC-AUC: 0.9913 - PR-AUC: 0.9591 - precision: 0.9627 - recall: 0.8622 - TP: 7822.0000 - TN: 99489.0000 - FP: 303.0000 - FN: 1250.0000 - val_loss: 0.0930 - val_categorical_accuracy: 0.9717 - val_top-3: 0.9932 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9961 - val_precision: 0.9896 - val_recall: 0.9636 - val_TP: 5828.0000 - val_TN: 66467.0000 - val_FP: 61.0000 - val_FN: 220.0000\n",
      "Epoch 19/50\n",
      "567/567 [==============================] - 172s 304ms/step - loss: 0.3391 - categorical_accuracy: 0.9075 - top-3: 0.9599 - ROC-AUC: 0.9924 - PR-AUC: 0.9649 - precision: 0.9639 - recall: 0.8771 - TP: 7957.0000 - TN: 99494.0000 - FP: 298.0000 - FN: 1115.0000 - val_loss: 0.1045 - val_categorical_accuracy: 0.9694 - val_top-3: 0.9909 - val_ROC-AUC: 0.9987 - val_PR-AUC: 0.9946 - val_precision: 0.9896 - val_recall: 0.9557 - val_TP: 5780.0000 - val_TN: 66467.0000 - val_FP: 61.0000 - val_FN: 268.0000\n",
      "Epoch 20/50\n",
      "567/567 [==============================] - 177s 311ms/step - loss: 0.4445 - categorical_accuracy: 0.9041 - top-3: 0.9609 - ROC-AUC: 0.9917 - PR-AUC: 0.9626 - precision: 0.9636 - recall: 0.8735 - TP: 7924.0000 - TN: 99493.0000 - FP: 299.0000 - FN: 1148.0000 - val_loss: 0.0633 - val_categorical_accuracy: 0.9820 - val_top-3: 0.9967 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9973 - val_precision: 0.9863 - val_recall: 0.9762 - val_TP: 5904.0000 - val_TN: 66446.0000 - val_FP: 82.0000 - val_FN: 144.0000\n",
      "Epoch 21/50\n",
      "567/567 [==============================] - 173s 304ms/step - loss: 0.4167 - categorical_accuracy: 0.8983 - top-3: 0.9571 - ROC-AUC: 0.9919 - PR-AUC: 0.9612 - precision: 0.9609 - recall: 0.8698 - TP: 7891.0000 - TN: 99471.0000 - FP: 321.0000 - FN: 1181.0000 - val_loss: 0.0780 - val_categorical_accuracy: 0.9792 - val_top-3: 0.9896 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9969 - val_precision: 0.9940 - val_recall: 0.9648 - val_TP: 5835.0000 - val_TN: 66493.0000 - val_FP: 35.0000 - val_FN: 213.0000\n",
      "Epoch 22/50\n",
      "567/567 [==============================] - 173s 305ms/step - loss: 0.3712 - categorical_accuracy: 0.8943 - top-3: 0.9548 - ROC-AUC: 0.9918 - PR-AUC: 0.9594 - precision: 0.9625 - recall: 0.8603 - TP: 7805.0000 - TN: 99488.0000 - FP: 304.0000 - FN: 1267.0000 - val_loss: 0.0682 - val_categorical_accuracy: 0.9851 - val_top-3: 0.9957 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9967 - val_precision: 0.9938 - val_recall: 0.9729 - val_TP: 5884.0000 - val_TN: 66491.0000 - val_FP: 37.0000 - val_FN: 164.0000\n",
      "Epoch 23/50\n",
      "567/567 [==============================] - 173s 304ms/step - loss: 0.3640 - categorical_accuracy: 0.9035 - top-3: 0.9597 - ROC-AUC: 0.9922 - PR-AUC: 0.9627 - precision: 0.9641 - recall: 0.8700 - TP: 7893.0000 - TN: 99498.0000 - FP: 294.0000 - FN: 1179.0000 - val_loss: 0.1229 - val_categorical_accuracy: 0.9646 - val_top-3: 0.9899 - val_ROC-AUC: 0.9983 - val_PR-AUC: 0.9925 - val_precision: 0.9799 - val_recall: 0.9578 - val_TP: 5793.0000 - val_TN: 66409.0000 - val_FP: 119.0000 - val_FN: 255.0000\n",
      "Epoch 24/50\n",
      "567/567 [==============================] - 173s 304ms/step - loss: 0.3639 - categorical_accuracy: 0.8921 - top-3: 0.9552 - ROC-AUC: 0.9916 - PR-AUC: 0.9589 - precision: 0.9632 - recall: 0.8578 - TP: 7782.0000 - TN: 99495.0000 - FP: 297.0000 - FN: 1290.0000 - val_loss: 0.0818 - val_categorical_accuracy: 0.9782 - val_top-3: 0.9937 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9967 - val_precision: 0.9946 - val_recall: 0.9656 - val_TP: 5840.0000 - val_TN: 66496.0000 - val_FP: 32.0000 - val_FN: 208.0000\n",
      "Epoch 25/50\n",
      "567/567 [==============================] - 174s 307ms/step - loss: 0.2986 - categorical_accuracy: 0.9187 - top-3: 0.9665 - ROC-AUC: 0.9945 - PR-AUC: 0.9730 - precision: 0.9687 - recall: 0.8907 - TP: 8080.0000 - TN: 99531.0000 - FP: 261.0000 - FN: 992.0000 - val_loss: 0.0595 - val_categorical_accuracy: 0.9869 - val_top-3: 0.9955 - val_ROC-AUC: 0.9995 - val_PR-AUC: 0.9981 - val_precision: 0.9970 - val_recall: 0.9815 - val_TP: 5936.0000 - val_TN: 66510.0000 - val_FP: 18.0000 - val_FN: 112.0000\n",
      "Epoch 26/50\n",
      "567/567 [==============================] - 169s 299ms/step - loss: 0.3915 - categorical_accuracy: 0.8955 - top-3: 0.9538 - ROC-AUC: 0.9918 - PR-AUC: 0.9610 - precision: 0.9672 - recall: 0.8660 - TP: 7856.0000 - TN: 99526.0000 - FP: 266.0000 - FN: 1216.0000 - val_loss: 0.0665 - val_categorical_accuracy: 0.9777 - val_top-3: 0.9926 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9972 - val_precision: 0.9963 - val_recall: 0.9673 - val_TP: 5850.0000 - val_TN: 66506.0000 - val_FP: 22.0000 - val_FN: 198.0000\n",
      "Epoch 27/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.4264 - categorical_accuracy: 0.9022 - top-3: 0.9588 - ROC-AUC: 0.9926 - PR-AUC: 0.9644 - precision: 0.9634 - recall: 0.8744 - TP: 7933.0000 - TN: 99491.0000 - FP: 301.0000 - FN: 1139.0000 - val_loss: 0.1663 - val_categorical_accuracy: 0.9714 - val_top-3: 0.9899 - val_ROC-AUC: 0.9956 - val_PR-AUC: 0.9860 - val_precision: 0.9848 - val_recall: 0.9322 - val_TP: 5638.0000 - val_TN: 66441.0000 - val_FP: 87.0000 - val_FN: 410.0000\n",
      "Epoch 28/50\n",
      "567/567 [==============================] - 171s 302ms/step - loss: 0.3981 - categorical_accuracy: 0.8984 - top-3: 0.9578 - ROC-AUC: 0.9918 - PR-AUC: 0.9611 - precision: 0.9671 - recall: 0.8630 - TP: 7829.0000 - TN: 99526.0000 - FP: 266.0000 - FN: 1243.0000 - val_loss: 0.0893 - val_categorical_accuracy: 0.9788 - val_top-3: 0.9936 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9959 - val_precision: 0.9925 - val_recall: 0.9679 - val_TP: 5854.0000 - val_TN: 66484.0000 - val_FP: 44.0000 - val_FN: 194.0000\n",
      "Epoch 29/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.4138 - categorical_accuracy: 0.8893 - top-3: 0.9538 - ROC-AUC: 0.9909 - PR-AUC: 0.9585 - precision: 0.9656 - recall: 0.8603 - TP: 7805.0000 - TN: 99514.0000 - FP: 278.0000 - FN: 1267.0000 - val_loss: 0.0878 - val_categorical_accuracy: 0.9697 - val_top-3: 0.9914 - val_ROC-AUC: 0.9992 - val_PR-AUC: 0.9958 - val_precision: 0.9945 - val_recall: 0.9560 - val_TP: 5782.0000 - val_TN: 66496.0000 - val_FP: 32.0000 - val_FN: 266.0000\n",
      "Epoch 30/50\n",
      "567/567 [==============================] - 171s 302ms/step - loss: 0.3631 - categorical_accuracy: 0.8997 - top-3: 0.9561 - ROC-AUC: 0.9933 - PR-AUC: 0.9655 - precision: 0.9730 - recall: 0.8671 - TP: 7866.0000 - TN: 99574.0000 - FP: 218.0000 - FN: 1206.0000 - val_loss: 0.0808 - val_categorical_accuracy: 0.9812 - val_top-3: 0.9942 - val_ROC-AUC: 0.9988 - val_PR-AUC: 0.9960 - val_precision: 0.9943 - val_recall: 0.9735 - val_TP: 5888.0000 - val_TN: 66494.0000 - val_FP: 34.0000 - val_FN: 160.0000\n",
      "Epoch 31/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3600 - categorical_accuracy: 0.8912 - top-3: 0.9554 - ROC-AUC: 0.9935 - PR-AUC: 0.9631 - precision: 0.9658 - recall: 0.8550 - TP: 7757.0000 - TN: 99517.0000 - FP: 275.0000 - FN: 1315.0000 - val_loss: 0.0437 - val_categorical_accuracy: 0.9866 - val_top-3: 0.9960 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9988 - val_precision: 0.9980 - val_recall: 0.9800 - val_TP: 5927.0000 - val_TN: 66516.0000 - val_FP: 12.0000 - val_FN: 121.0000\n",
      "Epoch 32/50\n",
      "567/567 [==============================] - 173s 304ms/step - loss: 0.4023 - categorical_accuracy: 0.8945 - top-3: 0.9478 - ROC-AUC: 0.9922 - PR-AUC: 0.9612 - precision: 0.9714 - recall: 0.8660 - TP: 7856.0000 - TN: 99561.0000 - FP: 231.0000 - FN: 1216.0000 - val_loss: 0.0753 - val_categorical_accuracy: 0.9800 - val_top-3: 0.9902 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9981 - val_precision: 0.9976 - val_recall: 0.9673 - val_TP: 5850.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 198.0000\n",
      "Epoch 33/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.3304 - categorical_accuracy: 0.9024 - top-3: 0.9575 - ROC-AUC: 0.9934 - PR-AUC: 0.9665 - precision: 0.9669 - recall: 0.8705 - TP: 7897.0000 - TN: 99522.0000 - FP: 270.0000 - FN: 1175.0000 - val_loss: 0.0447 - val_categorical_accuracy: 0.9894 - val_top-3: 0.9969 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9988 - val_precision: 0.9981 - val_recall: 0.9780 - val_TP: 5915.0000 - val_TN: 66517.0000 - val_FP: 11.0000 - val_FN: 133.0000\n",
      "Epoch 34/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.3898 - categorical_accuracy: 0.8924 - top-3: 0.9482 - ROC-AUC: 0.9920 - PR-AUC: 0.9598 - precision: 0.9651 - recall: 0.8593 - TP: 7796.0000 - TN: 99510.0000 - FP: 282.0000 - FN: 1276.0000 - val_loss: 0.0930 - val_categorical_accuracy: 0.9686 - val_top-3: 0.9936 - val_ROC-AUC: 0.9991 - val_PR-AUC: 0.9956 - val_precision: 0.9824 - val_recall: 0.9507 - val_TP: 5750.0000 - val_TN: 66425.0000 - val_FP: 103.0000 - val_FN: 298.0000\n",
      "Epoch 35/50\n",
      "567/567 [==============================] - 172s 303ms/step - loss: 0.3751 - categorical_accuracy: 0.8922 - top-3: 0.9523 - ROC-AUC: 0.9927 - PR-AUC: 0.9614 - precision: 0.9675 - recall: 0.8555 - TP: 7761.0000 - TN: 99531.0000 - FP: 261.0000 - FN: 1311.0000 - val_loss: 0.0643 - val_categorical_accuracy: 0.9835 - val_top-3: 0.9927 - val_ROC-AUC: 0.9998 - val_PR-AUC: 0.9983 - val_precision: 0.9953 - val_recall: 0.9726 - val_TP: 5882.0000 - val_TN: 66500.0000 - val_FP: 28.0000 - val_FN: 166.0000\n",
      "Epoch 36/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.3311 - categorical_accuracy: 0.8956 - top-3: 0.9592 - ROC-AUC: 0.9934 - PR-AUC: 0.9651 - precision: 0.9644 - recall: 0.8664 - TP: 7860.0000 - TN: 99502.0000 - FP: 290.0000 - FN: 1212.0000 - val_loss: 0.0502 - val_categorical_accuracy: 0.9883 - val_top-3: 0.9960 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9988 - val_precision: 0.9980 - val_recall: 0.9762 - val_TP: 5904.0000 - val_TN: 66516.0000 - val_FP: 12.0000 - val_FN: 144.0000\n",
      "Epoch 37/50\n",
      "567/567 [==============================] - 171s 302ms/step - loss: 0.3434 - categorical_accuracy: 0.9000 - top-3: 0.9539 - ROC-AUC: 0.9927 - PR-AUC: 0.9648 - precision: 0.9655 - recall: 0.8705 - TP: 7897.0000 - TN: 99510.0000 - FP: 282.0000 - FN: 1175.0000 - val_loss: 0.0415 - val_categorical_accuracy: 0.9896 - val_top-3: 0.9969 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9984 - val_precision: 0.9977 - val_recall: 0.9863 - val_TP: 5965.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 83.0000\n",
      "Epoch 38/50\n",
      "567/567 [==============================] - 172s 303ms/step - loss: 0.3019 - categorical_accuracy: 0.9060 - top-3: 0.9597 - ROC-AUC: 0.9951 - PR-AUC: 0.9716 - precision: 0.9696 - recall: 0.8780 - TP: 7965.0000 - TN: 99542.0000 - FP: 250.0000 - FN: 1107.0000 - val_loss: 0.0702 - val_categorical_accuracy: 0.9851 - val_top-3: 0.9945 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9973 - val_precision: 0.9983 - val_recall: 0.9691 - val_TP: 5861.0000 - val_TN: 66518.0000 - val_FP: 10.0000 - val_FN: 187.0000\n",
      "Epoch 39/50\n",
      "567/567 [==============================] - 169s 299ms/step - loss: 0.2974 - categorical_accuracy: 0.9047 - top-3: 0.9606 - ROC-AUC: 0.9940 - PR-AUC: 0.9695 - precision: 0.9661 - recall: 0.8768 - TP: 7954.0000 - TN: 99513.0000 - FP: 279.0000 - FN: 1118.0000 - val_loss: 0.0569 - val_categorical_accuracy: 0.9879 - val_top-3: 0.9947 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9987 - val_precision: 0.9966 - val_recall: 0.9792 - val_TP: 5922.0000 - val_TN: 66508.0000 - val_FP: 20.0000 - val_FN: 126.0000\n",
      "Epoch 40/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3132 - categorical_accuracy: 0.9000 - top-3: 0.9587 - ROC-AUC: 0.9944 - PR-AUC: 0.9681 - precision: 0.9653 - recall: 0.8728 - TP: 7918.0000 - TN: 99507.0000 - FP: 285.0000 - FN: 1154.0000 - val_loss: 0.0439 - val_categorical_accuracy: 0.9838 - val_top-3: 0.9959 - val_ROC-AUC: 0.9999 - val_PR-AUC: 0.9992 - val_precision: 0.9976 - val_recall: 0.9759 - val_TP: 5902.0000 - val_TN: 66514.0000 - val_FP: 14.0000 - val_FN: 146.0000\n",
      "Epoch 41/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.3013 - categorical_accuracy: 0.9020 - top-3: 0.9589 - ROC-AUC: 0.9943 - PR-AUC: 0.9684 - precision: 0.9711 - recall: 0.8671 - TP: 7866.0000 - TN: 99558.0000 - FP: 234.0000 - FN: 1206.0000 - val_loss: 0.0659 - val_categorical_accuracy: 0.9876 - val_top-3: 0.9952 - val_ROC-AUC: 0.9994 - val_PR-AUC: 0.9974 - val_precision: 0.9964 - val_recall: 0.9689 - val_TP: 5860.0000 - val_TN: 66507.0000 - val_FP: 21.0000 - val_FN: 188.0000\n",
      "Epoch 42/50\n",
      "567/567 [==============================] - 170s 301ms/step - loss: 0.3834 - categorical_accuracy: 0.8873 - top-3: 0.9485 - ROC-AUC: 0.9913 - PR-AUC: 0.9562 - precision: 0.9591 - recall: 0.8528 - TP: 7737.0000 - TN: 99462.0000 - FP: 330.0000 - FN: 1335.0000 - val_loss: 0.0495 - val_categorical_accuracy: 0.9897 - val_top-3: 0.9962 - val_ROC-AUC: 0.9993 - val_PR-AUC: 0.9974 - val_precision: 0.9957 - val_recall: 0.9843 - val_TP: 5953.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 95.0000\n",
      "Epoch 43/50\n",
      "567/567 [==============================] - 170s 300ms/step - loss: 0.3631 - categorical_accuracy: 0.8952 - top-3: 0.9547 - ROC-AUC: 0.9929 - PR-AUC: 0.9627 - precision: 0.9628 - recall: 0.8673 - TP: 7868.0000 - TN: 99488.0000 - FP: 304.0000 - FN: 1204.0000 - val_loss: 0.0554 - val_categorical_accuracy: 0.9859 - val_top-3: 0.9955 - val_ROC-AUC: 0.9989 - val_PR-AUC: 0.9973 - val_precision: 0.9943 - val_recall: 0.9805 - val_TP: 5930.0000 - val_TN: 66494.0000 - val_FP: 34.0000 - val_FN: 118.0000\n",
      "Epoch 44/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3390 - categorical_accuracy: 0.9020 - top-3: 0.9610 - ROC-AUC: 0.9933 - PR-AUC: 0.9675 - precision: 0.9640 - recall: 0.8763 - TP: 7950.0000 - TN: 99495.0000 - FP: 297.0000 - FN: 1122.0000 - val_loss: 0.0572 - val_categorical_accuracy: 0.9820 - val_top-3: 0.9974 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9985 - val_precision: 0.9918 - val_recall: 0.9760 - val_TP: 5903.0000 - val_TN: 66479.0000 - val_FP: 49.0000 - val_FN: 145.0000\n",
      "Epoch 45/50\n",
      "567/567 [==============================] - 172s 303ms/step - loss: 0.3282 - categorical_accuracy: 0.9020 - top-3: 0.9594 - ROC-AUC: 0.9934 - PR-AUC: 0.9671 - precision: 0.9690 - recall: 0.8726 - TP: 7916.0000 - TN: 99539.0000 - FP: 253.0000 - FN: 1156.0000 - val_loss: 0.0473 - val_categorical_accuracy: 0.9889 - val_top-3: 0.9980 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9985 - val_precision: 0.9971 - val_recall: 0.9826 - val_TP: 5943.0000 - val_TN: 66511.0000 - val_FP: 17.0000 - val_FN: 105.0000\n",
      "Epoch 46/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3076 - categorical_accuracy: 0.9085 - top-3: 0.9594 - ROC-AUC: 0.9941 - PR-AUC: 0.9680 - precision: 0.9691 - recall: 0.8768 - TP: 7954.0000 - TN: 99538.0000 - FP: 254.0000 - FN: 1118.0000 - val_loss: 0.0826 - val_categorical_accuracy: 0.9797 - val_top-3: 0.9934 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9975 - val_precision: 0.9935 - val_recall: 0.9658 - val_TP: 5841.0000 - val_TN: 66490.0000 - val_FP: 38.0000 - val_FN: 207.0000\n",
      "Epoch 47/50\n",
      "567/567 [==============================] - 170s 299ms/step - loss: 0.3504 - categorical_accuracy: 0.9042 - top-3: 0.9601 - ROC-AUC: 0.9930 - PR-AUC: 0.9664 - precision: 0.9672 - recall: 0.8795 - TP: 7979.0000 - TN: 99521.0000 - FP: 271.0000 - FN: 1093.0000 - val_loss: 0.2368 - val_categorical_accuracy: 0.9529 - val_top-3: 0.9764 - val_ROC-AUC: 0.9944 - val_PR-AUC: 0.9857 - val_precision: 0.9787 - val_recall: 0.9428 - val_TP: 5702.0000 - val_TN: 66404.0000 - val_FP: 124.0000 - val_FN: 346.0000\n",
      "Epoch 48/50\n",
      "567/567 [==============================] - 171s 301ms/step - loss: 0.3980 - categorical_accuracy: 0.8951 - top-3: 0.9572 - ROC-AUC: 0.9918 - PR-AUC: 0.9609 - precision: 0.9568 - recall: 0.8706 - TP: 7898.0000 - TN: 99435.0000 - FP: 357.0000 - FN: 1174.0000 - val_loss: 0.0964 - val_categorical_accuracy: 0.9793 - val_top-3: 0.9914 - val_ROC-AUC: 0.9966 - val_PR-AUC: 0.9924 - val_precision: 0.9881 - val_recall: 0.9729 - val_TP: 5884.0000 - val_TN: 66457.0000 - val_FP: 71.0000 - val_FN: 164.0000\n",
      "Epoch 49/50\n",
      "567/567 [==============================] - 172s 303ms/step - loss: 0.3076 - categorical_accuracy: 0.9042 - top-3: 0.9594 - ROC-AUC: 0.9939 - PR-AUC: 0.9696 - precision: 0.9674 - recall: 0.8770 - TP: 7956.0000 - TN: 99524.0000 - FP: 268.0000 - FN: 1116.0000 - val_loss: 0.0360 - val_categorical_accuracy: 0.9902 - val_top-3: 0.9960 - val_ROC-AUC: 0.9997 - val_PR-AUC: 0.9991 - val_precision: 0.9957 - val_recall: 0.9864 - val_TP: 5966.0000 - val_TN: 66502.0000 - val_FP: 26.0000 - val_FN: 82.00000.9046 - top-3: 0.9597 - ROC-AUC: 0.9937 - PR-AUC: 0.9696 - \n",
      "Epoch 50/50\n",
      "567/567 [==============================] - 175s 308ms/step - loss: 0.3095 - categorical_accuracy: 0.9160 - top-3: 0.9660 - ROC-AUC: 0.9943 - PR-AUC: 0.9729 - precision: 0.9664 - recall: 0.8887 - TP: 8062.0000 - TN: 99512.0000 - FP: 280.0000 - FN: 1010.0000 - val_loss: 0.0393 - val_categorical_accuracy: 0.9916 - val_top-3: 0.9987 - val_ROC-AUC: 0.9996 - val_PR-AUC: 0.9987 - val_precision: 0.9965 - val_recall: 0.9863 - val_TP: 5965.0000 - val_TN: 66507.0000 - val_FP: 21.0000 - val_FN: 83.0000\n",
      "-----\n",
      "(8599533.01 ms) == (143m:19s)\n",
      "-----\n",
      "\n",
      "\n",
      "17\n",
      "['mobilenetv2_1.00_96-imagenet96-16-fc12.tensorboard',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.001_0.9573_0.1553.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.002_0.9689_0.1019.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.003_0.9807_0.1054.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.005.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.010.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.012_0.9909_0.0391.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.015.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.020.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.025.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.030.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.035.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.040.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.045.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.049_0.9902_0.0360.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.050.hdf5',\n",
      " 'mobilenetv2_1.00_96-imagenet96-16-fc12.weights.050_0.9916_0.0393.hdf5']\n",
      "3\n",
      "['history.mobilenetv2_1.00_96-imagenet96-16-fc12.csv',\n",
      " 'model.mobilenetv2_1.00_96-imagenet96-16-fc12.h5',\n",
      " 'weights.mobilenetv2_1.00_96-imagenet96-16-fc12.h5']\n",
      "\n",
      "\n",
      "all process done, please recheck before terminating runtime session\n",
      "\n",
      "don't forget to save the model.fit() verbose output\n",
      "\n",
      "\n",
      "Returned values using 232 bytes of memory now\n"
     ]
    }
   ],
   "source": [
    "# mobilenetv2_1.00_96-imagenet96-16-fc12\n",
    "model_10 = consecutiveModelTraining(\n",
    "    input_size=96,\n",
    "    batch_size=16,\n",
    "    weights='imagenet',\n",
    "    dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cde85bf-c905-461f-8204-ed6d4b49f085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T05:11:31.874081Z",
     "iopub.status.busy": "2021-06-10T05:11:31.874081Z",
     "iopub.status.idle": "2021-06-10T05:11:31.969087Z",
     "shell.execute_reply": "2021-06-10T05:11:31.968092Z",
     "shell.execute_reply.started": "2021-06-10T05:11:31.874081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>top-3</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>...</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_top-3</th>\n",
       "      <th>val_ROC-AUC</th>\n",
       "      <th>val_PR-AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_TP</th>\n",
       "      <th>val_TN</th>\n",
       "      <th>val_FP</th>\n",
       "      <th>val_FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.385921</td>\n",
       "      <td>0.893064</td>\n",
       "      <td>0.955825</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>0.957694</td>\n",
       "      <td>0.958878</td>\n",
       "      <td>0.860157</td>\n",
       "      <td>7803.340000</td>\n",
       "      <td>99460.54000</td>\n",
       "      <td>331.46000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974778</td>\n",
       "      <td>0.992229</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.960860</td>\n",
       "      <td>5811.280000</td>\n",
       "      <td>66473.280000</td>\n",
       "      <td>54.720000</td>\n",
       "      <td>236.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.097510</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.016727</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>328.867296</td>\n",
       "      <td>113.24368</td>\n",
       "      <td>113.24368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.025456</td>\n",
       "      <td>153.959714</td>\n",
       "      <td>39.131406</td>\n",
       "      <td>39.131406</td>\n",
       "      <td>153.959714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.297434</td>\n",
       "      <td>0.707011</td>\n",
       "      <td>0.871914</td>\n",
       "      <td>0.955243</td>\n",
       "      <td>0.804753</td>\n",
       "      <td>0.866166</td>\n",
       "      <td>0.622795</td>\n",
       "      <td>5650.000000</td>\n",
       "      <td>98919.00000</td>\n",
       "      <td>218.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877976</td>\n",
       "      <td>0.965939</td>\n",
       "      <td>0.992766</td>\n",
       "      <td>0.953789</td>\n",
       "      <td>0.976666</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>4983.000000</td>\n",
       "      <td>66390.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333054</td>\n",
       "      <td>0.892113</td>\n",
       "      <td>0.954723</td>\n",
       "      <td>0.990974</td>\n",
       "      <td>0.957690</td>\n",
       "      <td>0.958183</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>7770.000000</td>\n",
       "      <td>99453.75000</td>\n",
       "      <td>271.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969039</td>\n",
       "      <td>0.991030</td>\n",
       "      <td>0.998607</td>\n",
       "      <td>0.993638</td>\n",
       "      <td>0.986416</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>5756.500000</td>\n",
       "      <td>66447.000000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>144.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.369886</td>\n",
       "      <td>0.896715</td>\n",
       "      <td>0.958113</td>\n",
       "      <td>0.992068</td>\n",
       "      <td>0.961564</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>0.866237</td>\n",
       "      <td>7858.500000</td>\n",
       "      <td>99496.50000</td>\n",
       "      <td>295.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979001</td>\n",
       "      <td>0.993469</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>0.993038</td>\n",
       "      <td>0.965691</td>\n",
       "      <td>5840.500000</td>\n",
       "      <td>66487.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>207.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.415976</td>\n",
       "      <td>0.902943</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>0.993309</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.966901</td>\n",
       "      <td>0.873291</td>\n",
       "      <td>7922.500000</td>\n",
       "      <td>99520.50000</td>\n",
       "      <td>338.25000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985739</td>\n",
       "      <td>0.995660</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.996229</td>\n",
       "      <td>0.976149</td>\n",
       "      <td>5903.750000</td>\n",
       "      <td>66505.750000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>291.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.963861</td>\n",
       "      <td>0.918651</td>\n",
       "      <td>0.966490</td>\n",
       "      <td>0.995071</td>\n",
       "      <td>0.973012</td>\n",
       "      <td>0.973033</td>\n",
       "      <td>0.890653</td>\n",
       "      <td>8080.000000</td>\n",
       "      <td>99574.00000</td>\n",
       "      <td>873.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991567</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999249</td>\n",
       "      <td>0.998297</td>\n",
       "      <td>0.986442</td>\n",
       "      <td>5966.000000</td>\n",
       "      <td>66518.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>1065.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  categorical_accuracy      top-3    ROC-AUC     PR-AUC  \\\n",
       "count  50.000000             50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.385921              0.893064   0.955825   0.991078   0.957694   \n",
       "std     0.097510              0.028443   0.012780   0.005589   0.023404   \n",
       "min     0.297434              0.707011   0.871914   0.955243   0.804753   \n",
       "25%     0.333054              0.892113   0.954723   0.990974   0.957690   \n",
       "50%     0.369886              0.896715   0.958113   0.992068   0.961564   \n",
       "75%     0.415976              0.902943   0.959656   0.993309   0.966236   \n",
       "max     0.963861              0.918651   0.966490   0.995071   0.973012   \n",
       "\n",
       "       precision     recall           TP           TN         FP  ...  \\\n",
       "count  50.000000  50.000000    50.000000     50.00000   50.00000  ...   \n",
       "mean    0.958878   0.860157  7803.340000  99460.54000  331.46000  ...   \n",
       "std     0.016727   0.036251   328.867296    113.24368  113.24368  ...   \n",
       "min     0.866166   0.622795  5650.000000  98919.00000  218.00000  ...   \n",
       "25%     0.958183   0.856481  7770.000000  99453.75000  271.50000  ...   \n",
       "50%     0.964038   0.866237  7858.500000  99496.50000  295.50000  ...   \n",
       "75%     0.966901   0.873291  7922.500000  99520.50000  338.25000  ...   \n",
       "max     0.973033   0.890653  8080.000000  99574.00000  873.00000  ...   \n",
       "\n",
       "       val_categorical_accuracy  val_top-3  val_ROC-AUC  val_PR-AUC  \\\n",
       "count                 50.000000  50.000000    50.000000   50.000000   \n",
       "mean                   0.974778   0.992229     0.998685    0.994419   \n",
       "std                    0.017607   0.005750     0.001426    0.006917   \n",
       "min                    0.877976   0.965939     0.992766    0.953789   \n",
       "25%                    0.969039   0.991030     0.998607    0.993638   \n",
       "50%                    0.979001   0.993469     0.999134    0.996069   \n",
       "75%                    0.985739   0.995660     0.999592    0.998132   \n",
       "max                    0.991567   0.998677     0.999928    0.999249   \n",
       "\n",
       "       val_precision  val_recall       val_TP        val_TN      val_FP  \\\n",
       "count      50.000000   50.000000    50.000000     50.000000   50.000000   \n",
       "mean        0.990643    0.960860  5811.280000  66473.280000   54.720000   \n",
       "std         0.006688    0.025456   153.959714     39.131406   39.131406   \n",
       "min         0.976666    0.823909  4983.000000  66390.000000   10.000000   \n",
       "25%         0.986416    0.951802  5756.500000  66447.000000   22.250000   \n",
       "50%         0.993038    0.965691  5840.500000  66487.000000   41.000000   \n",
       "75%         0.996229    0.976149  5903.750000  66505.750000   81.000000   \n",
       "max         0.998297    0.986442  5966.000000  66518.000000  138.000000   \n",
       "\n",
       "            val_FN  \n",
       "count    50.000000  \n",
       "mean    236.720000  \n",
       "std     153.959714  \n",
       "min      82.000000  \n",
       "25%     144.250000  \n",
       "50%     207.500000  \n",
       "75%     291.500000  \n",
       "max    1065.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10['history_df'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c29ea-16e4-4b6b-8171-39b68ceb093c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}